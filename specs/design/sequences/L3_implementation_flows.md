# L3 å®Ÿè£…è©³ç´°ãƒ•ãƒ­ãƒ¼ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ - DAWAI

**éšå±¤ãƒ¬ãƒ™ãƒ«**: L3 (å®Ÿè£…è©³ç´°)
**å¯¾è±¡èª­è€…**: å®Ÿè£…æ‹…å½“è€…ã€æ–°è¦é–‹ç™ºè€…ã€ãƒ‡ãƒãƒƒã‚¬ãƒ¼
**ç›®çš„**: DAWAIä¸»è¦å®Ÿè£…ã®å†…éƒ¨å‡¦ç†ãƒ•ãƒ­ãƒ¼ã¨æŠ€è¡“è©³ç´°ã‚’ç†è§£ã™ã‚‹
**é–¢é€£æ–‡æ›¸**: å…·ä½“çš„å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ã€APIä»•æ§˜ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶

## ğŸ”§ Core Implementation Flows

### IF-001: unifiedAudioSystem.js å†…éƒ¨ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant App as App.jsx
    participant Unified as unifiedAudioSystem
    participant Tone as Tone.js Core
    participant Context as AudioContext
    participant Buffer as AudioBuffer

    Note over App, Buffer: çµ±åˆéŸ³å£°ã‚·ã‚¹ãƒ†ãƒ å†…éƒ¨å®Ÿè£… (230è¡Œ)

    App->>Unified: initializeAudio()
    Unified->>Tone: Tone.start()
    Tone->>Context: AudioContext ä½œæˆãƒ»èµ·å‹•
    Context->>Unified: context.state = "running"

    App->>Unified: createSynthesizer(type)
    Unified->>Tone: new Tone.Synth(options)
    Tone->>Context: OscillatorNode ä½œæˆ
    Context->>Buffer: ãƒãƒƒãƒ•ã‚¡å‰²ã‚Šå½“ã¦
    Buffer->>Unified: ã‚·ãƒ³ã‚» ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è¿”å´

    App->>Unified: playNote(note, duration)
    Unified->>Tone: synth.triggerAttackRelease()
    Tone->>Context: AudioNode ã‚°ãƒ©ãƒ•å‡¦ç†

    Context->>Context: DSP ãƒã‚§ãƒ¼ãƒ³å®Ÿè¡Œ
    Context->>Buffer: éŸ³å£°ãƒãƒƒãƒ•ã‚¡æ›¸ãè¾¼ã¿
    Buffer->>App: éŸ³å£°å‡ºåŠ› (~30msé…å»¶)

    Note over App, Buffer: ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ–éŸ³å£°å‡¦ç†
```

### IF-002: EnhancedMidiEditor.jsx Canvaså®Ÿè£…

```mermaid
sequenceDiagram
    participant User as ãƒ¦ãƒ¼ã‚¶ãƒ¼
    participant Editor as EnhancedMidiEditor
    participant Canvas as Canvas 2D API
    participant Events as Event Handlers
    participant State as Component State

    Note over User, State: MIDI ã‚¨ãƒ‡ã‚£ã‚¿ Canvas å®Ÿè£… (1100+è¡Œ)

    User->>Editor: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ ãƒã‚¦ãƒ³ãƒˆ
    Editor->>Canvas: canvas.getContext('2d')
    Canvas->>Editor: CanvasRenderingContext2D
    Editor->>Events: addEventListener('mousedown', ...)

    User->>Events: ãƒã‚¦ã‚¹ ã‚¯ãƒªãƒƒã‚¯ (x, y)
    Events->>Editor: calculateNoteFromPosition(x, y)
    Editor->>State: setState({ notes: [...notes, newNote] })
    State->>Canvas: drawPianoRoll()

    Canvas->>Canvas: clearRect() + fillRect()
    Canvas->>Canvas: drawGrid() + drawNotes()
    Canvas->>User: è¦–è¦šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯

    User->>Events: ãƒã‚¦ã‚¹ ãƒ‰ãƒ©ãƒƒã‚°
    Events->>Editor: handleNoteDrag(startX, endX)
    Editor->>State: updateNoteLength()
    State->>Canvas: requestAnimationFrame(redraw)
    Canvas->>User: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æç”»æ›´æ–°

    Note over User, State: 60FPS Canvas é«˜æ€§èƒ½æç”»
```

### IF-003: FastAPI Backend AIçµ±åˆå®Ÿè£…

```mermaid
sequenceDiagram
    participant Client as React Client
    participant FastAPI as main.py
    participant Router as API Router
    participant Claude as Claude Client
    participant OpenAI as OpenAI Client

    Note over Client, OpenAI: AIçµ±åˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å®Ÿè£…è©³ç´°

    Client->>FastAPI: POST /chat HTTP/1.1
    FastAPI->>Router: route_handler(@app.post)
    Router->>Router: validate_request_body()

    Router->>Router: determine_ai_provider(model)

    alt Claudeé¸æŠæ™‚
        Router->>Claude: anthropic.Anthropic(api_key)
        Claude->>Claude: client.messages.create()
        Claude->>Router: response.content[0].text
    else OpenAIé¸æŠæ™‚
        Router->>OpenAI: openai.OpenAI(api_key)
        OpenAI->>OpenAI: client.chat.completions.create()
        OpenAI->>Router: completion.choices[0].message
    end

    Router->>FastAPI: JSONResponse(response_data)
    FastAPI->>Client: HTTP 200 + JSON payload

    Note over Client, OpenAI: ãƒãƒ«ãƒAI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼æŠ½è±¡åŒ–
```

### IF-004: DiffSinger AIæ­Œå£°åˆæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```mermaid
sequenceDiagram
    participant Client as React Frontend
    participant API as FastAPI /synthesize
    participant Preprocess as Text Preprocessor
    participant Model as DiffSinger Model
    participant Postprocess as Audio Postprocessor

    Note over Client, Postprocess: DiffSinger æ­Œå£°åˆæˆå†…éƒ¨å®Ÿè£…

    Client->>API: POST /api/synthesize
    API->>Preprocess: normalize_lyrics(text)
    Preprocess->>Preprocess: phoneme_conversion()
    Preprocess->>Model: phoneme_sequence + midi_data

    Model->>Model: diffusion_process()
    Model->>Model: vocoder_synthesis()
    Model->>Postprocess: raw_audio_tensor

    Postprocess->>Postprocess: apply_effects()
    Postprocess->>Postprocess: normalize_audio()
    Postprocess->>API: final_wav_bytes

    API->>Client: multipart/form-data WAV
    Client->>Client: Audio.decodeAudioData()
    Client->>Client: æ­Œå£°ãƒˆãƒ©ãƒƒã‚¯çµ±åˆ

    Note over Client, Postprocess: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ­Œå£°åˆæˆå“è³ª
```

## ğŸ“Š State Management Implementation

### IF-005: useMidiPersistence Hookå®Ÿè£…

```mermaid
sequenceDiagram
    participant Component as React Component
    participant Hook as useMidiPersistence
    participant LocalStorage as window.localStorage
    participant Debounce as useDebounce
    participant Effect as useEffect

    Note over Component, Effect: MIDIæ°¸ç¶šåŒ– React Hook å®Ÿè£…

    Component->>Hook: const { save, load } = useMidiPersistence()
    Hook->>LocalStorage: localStorage.getItem('dawai_project')
    LocalStorage->>Hook: existing_project_data || null

    Component->>Hook: updateMidiData(newNotes)
    Hook->>Debounce: debounced_save(newNotes, 500ms)
    Debounce->>LocalStorage: localStorage.setItem()
    LocalStorage->>Hook: save_confirmation

    Hook->>Effect: useEffect([midiData], ...)
    Effect->>Hook: auto_save_interval = 30s
    Hook->>LocalStorage: incremental_backup()

    Component->>Hook: exportProject()
    Hook->>Hook: JSON.stringify(complete_project)
    Hook->>Component: downloadable_blob

    Note over Component, Effect: ãƒ‡ãƒ¼ã‚¿æå¤±ã‚¼ãƒ­è¨­è¨ˆ
```

### IF-006: AI Provider Switchingå®Ÿè£…

```mermaid
sequenceDiagram
    participant UI as ModelSelector.jsx
    participant Context as AIContext
    parameter State as useReducer
    participant API as Axios Instance
    participant Backend as FastAPI Router

    Note over UI, Backend: AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å‹•çš„åˆ‡ã‚Šæ›¿ãˆå®Ÿè£…

    UI->>Context: const { switchModel } = useAI()
    Context->>State: dispatch({ type: 'SWITCH_MODEL' })
    State->>State: aiReducer(state, action)

    State->>API: axios.post('/api/switch-model')
    API->>Backend: model_switch_request
    Backend->>Backend: update_active_provider()
    Backend->>API: switch_confirmation

    API->>State: response.data.success
    State->>Context: provider_switched_successfully
    Context->>UI: UIçŠ¶æ…‹æ›´æ–°ãƒ»è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ

    UI->>Context: sendMessage(text)
    Context->>API: axios.post('/api/chat', { model: active })
    API->>Backend: routed_to_correct_provider
    Backend->>UI: ai_response_from_active_model

    Note over UI, Backend: 0.5ç§’ä»¥ä¸‹ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ‡ã‚Šæ›¿ãˆ
```

## âš¡ Performance Critical Implementations

### IF-007: Audio Engine Real-time Processing

```mermaid
sequenceDiagram
    participant Browser as Web Browser
    participant Worker as Audio Worklet
    participant Buffer as Ring Buffer
    participant DSP as DSP Pipeline
    participant Output as Audio Output

    Note over Browser, Output: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†æœ€é©åŒ–

    Browser->>Worker: new AudioWorkletNode()
    Worker->>Buffer: allocate_ring_buffer(4096)
    Buffer->>DSP: initialize_processing_chain()

    Browser->>Worker: process(inputs, outputs)
    Worker->>Buffer: read_input_samples()
    Buffer->>DSP: apply_effects_chain()
    DSP->>Buffer: write_processed_samples()
    Buffer->>Output: commit_output_buffer()

    Output->>Browser: hardware_audio_callback()
    Browser->>Worker: next_process_cycle()

    loop 44.1kHz/128 samples
        Worker->>DSP: process_audio_block()
        DSP->>Output: 2.9ms processing_deadline
    end

    Note over Browser, Output: ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ– ä½é…å»¶å‡¦ç†
```

### IF-008: Canvas High-Performance Rendering

```mermaid
sequenceDiagram
    participant React as React Component
    participant RAF as requestAnimationFrame
    participant Canvas as OffscreenCanvas
    participant Worker as Canvas Worker
    participant GPU as WebGL Context

    Note over React, GPU: é«˜æ€§èƒ½ Canvas æç”»æœ€é©åŒ–

    React->>RAF: requestAnimationFrame(renderLoop)
    RAF->>Canvas: transferControlToOffscreen()
    Canvas->>Worker: postMessage(render_data)

    Worker->>GPU: gl.useProgram(shader)
    GPU->>GPU: vertex_buffer_upload()
    GPU->>GPU: fragment_shader_execution()
    GPU->>Worker: render_complete

    Worker->>Canvas: ImageBitmap transfer
    Canvas->>React: 60FPS smooth_rendering

    React->>RAF: next_animation_frame()
    RAF->>React: continuous_render_loop()

    Note over React, GPU: GPUåŠ é€Ÿ 60FPSæç”»ç¶­æŒ
```

## ğŸ”’ Security Implementation Details

### IF-009: API Key Management Implementation

```mermaid
sequenceDiagram
    participant Client as Frontend
    participant Env as Environment Variables
    participant Validation as Input Validator
    participant Encryption as API Key Handler
    participant Provider as AI Provider

    Note over Client, Provider: ã‚»ã‚­ãƒ¥ã‚¢API ã‚­ãƒ¼ç®¡ç†å®Ÿè£…

    Client->>Validation: validate_request()
    Validation->>Validation: sanitize_input()
    Validation->>Encryption: safe_api_call()

    Encryption->>Env: os.getenv('CLAUDE_API_KEY')
    Env->>Encryption: encrypted_key_value
    Encryption->>Provider: headers={'Authorization': f'Bearer {key}'}

    Provider->>Encryption: api_response
    Encryption->>Validation: filter_sensitive_data()
    Validation->>Client: safe_response_data

    Note over Client, Provider: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
```

### IF-010: CORS & Security Headerså®Ÿè£…

```mermaid
sequenceDiagram
    participant Browser as Web Browser
    participant Middleware as CORS Middleware
    participant Security as Security Headers
    participant API as FastAPI Router
    participant Response as HTTP Response

    Note over Browser, Response: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼å®Ÿè£… (è¦æ”¹å–„)

    Browser->>Middleware: OPTIONS preflight_request
    Middleware->>Middleware: validate_origin() # ç¾åœ¨ allow_origins=["*"]
    Middleware->>Security: add_security_headers()

    Security->>Security: X-Content-Type-Options: nosniff
    Security->>Security: X-Frame-Options: DENY
    Security->>API: secure_request_forwarding()

    API->>Response: process_api_request()
    Response->>Security: apply_response_headers()
    Security->>Browser: secure_http_response()

    Note over Browser, Response: âš ï¸ CORSè¨­å®šè¦ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–
```

---

**å®Ÿè£…æœ€é©åŒ–**: ã“ã®éšå±¤ã®è©³ç´°ã¯å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰å®Ÿè£…ã¨å¯†æ¥ã«é–¢é€£ã—ã¾ã™ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œç™ºç”Ÿæ™‚ã¯ã“ã®ãƒ¬ãƒ™ãƒ«ã§ã®åˆ†æãŒå¿…è¦ã§ã™ã€‚

**é–¢é€£å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- `frontend/src/utils/unifiedAudioSystem.js` - éŸ³å£°ã‚¨ãƒ³ã‚¸ãƒ³è©³ç´°å®Ÿè£…
- `frontend/src/components/EnhancedMidiEditor.jsx` - MIDIç·¨é›†å®Ÿè£…
- `backend/ai_agent/main.py` - AIçµ±åˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å®Ÿè£…
- `frontend/src/hooks/useMidiPersistence.js` - ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–å®Ÿè£…