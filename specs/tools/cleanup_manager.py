#!/usr/bin/env python3
"""
DAWAI ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã€ãƒ­ã‚°ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’æ¤œå‡ºãƒ»æ•´ç†
"""

from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List


class CleanupManager:
    """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ç®¡ç†"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.cleanup_targets = {
            'old_logs': [],
            'old_specs': [],
            'backup_files': [],
            'temp_files': [],
            'git_backups': [],
            'node_modules_duplicates': []
        }

    def scan_cleanup_targets(self) -> Dict:
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¯¾è±¡ã‚¹ã‚­ãƒ£ãƒ³"""
        self._find_old_logs()
        self._find_old_specs()
        self._find_backup_files()
        self._find_temp_files()
        self._find_git_backups()
        self._find_node_modules_duplicates()

        return self.cleanup_targets

    def _find_old_logs(self):
        """å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º"""
        print("  ğŸ” å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºä¸­...")

        log_patterns = ["*.log", "*.log.*", "*.out"]
        cutoff_date = datetime.now() - timedelta(days=30)

        for pattern in log_patterns:
            for log_file in self.project_root.rglob(pattern):
                # node_moduleså†…ã¯é™¤å¤–
                if 'node_modules' in log_file.parts:
                    continue

                try:
                    mtime = datetime.fromtimestamp(log_file.stat().st_mtime)
                    if mtime < cutoff_date:
                        size_kb = log_file.stat().st_size // 1024
                        self.cleanup_targets['old_logs'].append({
                            'file': str(log_file.relative_to(self.project_root)),
                            'age_days': (datetime.now() - mtime).days,
                            'size_kb': size_kb,
                            'size_mb': round(size_kb / 1024, 2)
                        })
                except Exception:
                    pass

        total_size_mb = sum(item['size_mb'] for item in self.cleanup_targets['old_logs'])
        print(f"    â„¹ï¸ æ¤œå‡º: {len(self.cleanup_targets['old_logs'])}å€‹ã®å¤ã„ãƒ­ã‚° (åˆè¨ˆ: {total_size_mb:.2f} MB)")

    def _find_old_specs(self):
        """å¤ã„ä»•æ§˜æ›¸æ¤œå‡º"""
        print("  ğŸ” å¤ã„ä»•æ§˜æ›¸æ¤œå‡ºä¸­...")

        # old_devs/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«
        old_docs_dir = self.project_root / "DAWAI_server" / "docs" / "development" / "old_devs"
        if old_docs_dir.exists():
            old_docs = list(old_docs_dir.rglob("*.md"))
            for doc in old_docs:
                try:
                    size_kb = doc.stat().st_size // 1024
                    self.cleanup_targets['old_specs'].append({
                        'file': str(doc.relative_to(self.project_root)),
                        'size_kb': size_kb
                    })
                except Exception:
                    pass

        # specs/old_*, specs/*_old.mdãªã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        specs_dir = self.project_root / "DAWAI_server" / "specs"
        if specs_dir.exists():
            for spec_file in specs_dir.rglob("*old*.md"):
                if spec_file.is_file():
                    try:
                        size_kb = spec_file.stat().st_size // 1024
                        self.cleanup_targets['old_specs'].append({
                            'file': str(spec_file.relative_to(self.project_root)),
                            'size_kb': size_kb
                        })
                    except Exception:
                        pass

        total_size_kb = sum(item['size_kb'] for item in self.cleanup_targets['old_specs'])
        print(f"    â„¹ï¸ æ¤œå‡º: {len(self.cleanup_targets['old_specs'])}å€‹ã®å¤ã„ä»•æ§˜æ›¸ (åˆè¨ˆ: {total_size_kb} KB)")

    def _find_backup_files(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º"""
        print("  ğŸ” ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºä¸­...")

        backup_patterns = ["*.bak", "*.old", "*.backup", "*~", "*.swp", "*.swo"]

        for pattern in backup_patterns:
            for backup_file in self.project_root.rglob(pattern):
                # node_modules, .gitå†…ã¯é™¤å¤–
                if 'node_modules' in backup_file.parts or '.git' in backup_file.parts:
                    continue

                try:
                    size_kb = backup_file.stat().st_size // 1024
                    self.cleanup_targets['backup_files'].append({
                        'file': str(backup_file.relative_to(self.project_root)),
                        'pattern': pattern,
                        'size_kb': size_kb
                    })
                except Exception:
                    pass

        total_size_kb = sum(item['size_kb'] for item in self.cleanup_targets['backup_files'])
        print(f"    â„¹ï¸ æ¤œå‡º: {len(self.cleanup_targets['backup_files'])}å€‹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ« (åˆè¨ˆ: {total_size_kb} KB)")

    def _find_temp_files(self):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º"""
        print("  ğŸ” ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡ºä¸­...")

        temp_patterns = ["*.tmp", "*.temp", ".DS_Store", "Thumbs.db", "desktop.ini"]

        for pattern in temp_patterns:
            for temp_file in self.project_root.rglob(pattern):
                # node_moduleså†…ã¯é™¤å¤–
                if 'node_modules' in temp_file.parts:
                    continue

                try:
                    size_kb = temp_file.stat().st_size // 1024
                    self.cleanup_targets['temp_files'].append({
                        'file': str(temp_file.relative_to(self.project_root)),
                        'pattern': pattern,
                        'size_kb': size_kb
                    })
                except Exception:
                    pass

        total_size_kb = sum(item['size_kb'] for item in self.cleanup_targets['temp_files'])
        print(f"    â„¹ï¸ æ¤œå‡º: {len(self.cleanup_targets['temp_files'])}å€‹ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ« (åˆè¨ˆ: {total_size_kb} KB)")

    def _find_git_backups(self):
        """Gitãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œå‡º"""
        print("  ğŸ” Gitãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œå‡ºä¸­...")

        # git_backup_*ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        for item in self.project_root.iterdir():
            if item.is_dir() and item.name.startswith('git_backup_'):
                try:
                    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºã‚’è¨ˆç®—
                    total_size = sum(f.stat().st_size for f in item.rglob('*') if f.is_file())
                    size_mb = total_size / (1024 * 1024)

                    self.cleanup_targets['git_backups'].append({
                        'directory': str(item.relative_to(self.project_root)),
                        'size_mb': round(size_mb, 2)
                    })
                except Exception:
                    pass

        total_size_mb = sum(item['size_mb'] for item in self.cleanup_targets['git_backups'])
        print(f"    â„¹ï¸ æ¤œå‡º: {len(self.cleanup_targets['git_backups'])}å€‹ã®Gitãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— (åˆè¨ˆ: {total_size_mb:.2f} MB)")

    def _find_node_modules_duplicates(self):
        """é‡è¤‡node_modulesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œå‡º"""
        print("  ğŸ” é‡è¤‡node_modulesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œå‡ºä¸­...")

        node_modules_dirs = list(self.project_root.rglob('node_modules'))

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ä»¥å¤–ã®node_modules
        for nm_dir in node_modules_dirs:
            # DAWAI_server/frontend/node_modulesä»¥å¤–ã¯é‡è¤‡ã®å¯èƒ½æ€§
            if nm_dir.parent.name != 'frontend' or 'DAWAI_server' not in str(nm_dir):
                try:
                    # ã‚µã‚¤ã‚ºè¨ˆç®—ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹ã®ã§æ¦‚ç®—ï¼‰
                    self.cleanup_targets['node_modules_duplicates'].append({
                        'directory': str(nm_dir.relative_to(self.project_root))
                    })
                except Exception:
                    pass

        print(f"    â„¹ï¸ æ¤œå‡º: {len(self.cleanup_targets['node_modules_duplicates'])}å€‹ã®æ½œåœ¨çš„é‡è¤‡node_modules")

    def get_total_cleanup_size(self) -> float:
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¯èƒ½ãªç·ã‚µã‚¤ã‚ºï¼ˆMBï¼‰"""
        total_mb = 0.0

        # å¤ã„ãƒ­ã‚°
        total_mb += sum(item.get('size_mb', 0) for item in self.cleanup_targets['old_logs'])

        # å¤ã„ä»•æ§˜æ›¸
        total_mb += sum(item.get('size_kb', 0) for item in self.cleanup_targets['old_specs']) / 1024

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«
        total_mb += sum(item.get('size_kb', 0) for item in self.cleanup_targets['backup_files']) / 1024

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
        total_mb += sum(item.get('size_kb', 0) for item in self.cleanup_targets['temp_files']) / 1024

        # Gitãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        total_mb += sum(item.get('size_mb', 0) for item in self.cleanup_targets['git_backups'])

        return round(total_mb, 2)

    def generate_cleanup_script(self, output_path: Path = None):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ"""
        if output_path is None:
            output_path = self.project_root / "cleanup_script.sh"

        script_lines = [
            "#!/bin/bash",
            "# DAWAI è‡ªå‹•ç”Ÿæˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ",
            f"# ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "echo 'ğŸ§¹ DAWAIã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹...'",
            ""
        ]

        # å¤ã„ãƒ­ã‚°ã®å‰Šé™¤
        if self.cleanup_targets['old_logs']:
            script_lines.append("# å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤")
            for item in self.cleanup_targets['old_logs']:
                script_lines.append(f"rm -f '{item['file']}'")
            script_lines.append("")

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
        if self.cleanup_targets['backup_files']:
            script_lines.append("# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤")
            for item in self.cleanup_targets['backup_files']:
                script_lines.append(f"rm -f '{item['file']}'")
            script_lines.append("")

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
        if self.cleanup_targets['temp_files']:
            script_lines.append("# ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤")
            for item in self.cleanup_targets['temp_files']:
                script_lines.append(f"rm -f '{item['file']}'")
            script_lines.append("")

        script_lines.append("echo 'âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†'")

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(script_lines))
            print(f"\nğŸ“ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ: {output_path}")
            print(f"    å®Ÿè¡Œæ–¹æ³•: bash {output_path}")
        except Exception as e:
            print(f"âš ï¸ ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆå¤±æ•—: {e}")


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="DAWAI ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼")
    parser.add_argument(
        "--project-root",
        type=Path,
        default=Path("."),
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ"
    )
    parser.add_argument(
        "--scan-only",
        action="store_true",
        help="ã‚¹ã‚­ãƒ£ãƒ³ã®ã¿ï¼ˆå‰Šé™¤ã¯è¡Œã‚ãªã„ï¼‰"
    )
    parser.add_argument(
        "--generate-script",
        action="store_true",
        help="ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆ"
    )

    args = parser.parse_args()

    print("ğŸ§¹ DAWAI ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼èµ·å‹•...")
    print("=" * 70)

    manager = CleanupManager(args.project_root)
    results = manager.scan_cleanup_targets()

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 70)
    print("ğŸ“Š ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¯¾è±¡ã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    print(f"\nğŸ“ˆ æ¤œå‡ºçµæœ:")
    print(f"  - å¤ã„ãƒ­ã‚°: {len(results['old_logs'])}å€‹")
    print(f"  - å¤ã„ä»•æ§˜æ›¸: {len(results['old_specs'])}å€‹")
    print(f"  - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«: {len(results['backup_files'])}å€‹")
    print(f"  - ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«: {len(results['temp_files'])}å€‹")
    print(f"  - Gitãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {len(results['git_backups'])}å€‹")
    print(f"  - é‡è¤‡node_modules: {len(results['node_modules_duplicates'])}å€‹")

    total_size = manager.get_total_cleanup_size()
    print(f"\nğŸ’¾ å‰Šæ¸›å¯èƒ½å®¹é‡: {total_size} MB")

    if args.generate_script:
        manager.generate_cleanup_script()

    print(f"\nğŸ“ ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
