# DAWAI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (L2)

**Document ID**: LA-L2-BACKEND-001
**Version**: 2.0.0
**Last Updated**: 2025-10-05
**Parent**: [L1: ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](../L1_system.md)
**Implementation Status**: âœ… Based on Current Codebase

## ğŸ—ï¸ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

DAWAIã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¯ã€FastAPIãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’åŸºç›¤ã¨ã—ãŸé«˜æ€§èƒ½Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼ã§ã™ã€‚AIçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€æ­Œå£°åˆæˆ(DiffSinger)ã€ãƒ†ã‚­ã‚¹ãƒˆè£œå®Œ(Ghost Text)ã®3ã¤ã®ä¸»è¦æ©Ÿèƒ½ã‚’æä¾›ã—ã€è¤‡æ•°ã®AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼(Claude/OpenAI/Gemini)ã¨ã®çµ±åˆã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚

### L2 ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æ§‹æˆå›³

```mermaid
graph TB
    subgraph "FastAPIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ (L2)"
        subgraph "APIã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤å±¤"
            FastAPI[FastAPI Application]
            CORS[CORS Middleware]
            Router[API Router]
            Validator[Request Validator]
        end

        subgraph "ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå±¤"
            ChatAPI[Chat API<br/>/api/chat<br/>/api/stream/chat]
            AgentAPI[Agent API<br/>/api/agent<br/>/api/stream/agent]
            GenerateAPI[Generate API<br/>/api/generate]
            HealthAPI[Health API<br/>/health<br/>/api/health]
        end

        subgraph "ã‚µãƒ¼ãƒ“ã‚¹å±¤"
            AIService[AIçµ±åˆã‚µãƒ¼ãƒ“ã‚¹<br/>StreamingAIModelManager]
            ModelManager[ãƒ¢ãƒ‡ãƒ«ç®¡ç†<br/>AIModelManager]
            PromptEngine[ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ³<br/>generate_agent_prompt]
            ResponseParser[ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ<br/>parse_agent_response]
        end

        subgraph "AIçµ±åˆå±¤"
            ClaudeClient[Claude Client<br/>stream_claude]
            OpenAIClient[OpenAI Client<br/>stream_openai]
            GeminiClient[Gemini Client<br/>stream_gemini]
            APIKeyManager[APIã‚­ãƒ¼ç®¡ç†]
        end

        subgraph "å¤–éƒ¨AI API"
            Claude[Claude API<br/>claude-3-sonnet]
            OpenAI[OpenAI API<br/>gpt-4]
            Gemini[Gemini API<br/>gemini-2.5-pro]
        end

        subgraph "DiffSingerå±¤ (è¨ˆç”»)"
            DiffAPI[DiffSinger API<br/>/diffsinger/synthesize]
            SynthService[æ­Œå£°åˆæˆã‚µãƒ¼ãƒ“ã‚¹]
            VocoderEngine[ãƒœã‚³ãƒ¼ãƒ€ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ³]
        end

        subgraph "Ghost Textå±¤ (è¨ˆç”»)"
            GhostAPI[Ghost Text API<br/>/ghost_text/complete]
            CompletionEngine[è£œå®Œã‚¨ãƒ³ã‚¸ãƒ³]
            LearningModel[å­¦ç¿’ãƒ¢ãƒ‡ãƒ«]
        end
    end

    FastAPI --> CORS
    CORS --> Router
    Router --> ChatAPI
    Router --> AgentAPI
    Router --> GenerateAPI
    Router --> HealthAPI

    ChatAPI --> AIService
    AgentAPI --> AIService
    GenerateAPI --> AIService

    AIService --> ClaudeClient
    AIService --> OpenAIClient
    AIService --> GeminiClient
    AIService --> APIKeyManager

    ClaudeClient --> Claude
    OpenAIClient --> OpenAI
    GeminiClient --> Gemini

    DiffAPI --> SynthService
    SynthService --> VocoderEngine
    GhostAPI --> CompletionEngine
    CompletionEngine --> LearningModel

    style FastAPI fill:#e1f5fe
    style AIService fill:#fff3e0
    style ClaudeClient fill:#e8f5e9
    style DiffAPI fill:#fce4ec
    style GhostAPI fill:#f3e5f5
```

## ğŸ¯ FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è©³ç´°æ§‹æˆ

### ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `backend/ai_agent/main.py` (1390è¡Œ)

```python
# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
app = FastAPI(
    title="Melodia Composer Copilot API",
    description="AI-powered music composition assistant API with streaming support",
    version="1.0.0"
)

# CORSè¨­å®š (âš ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦æ”¹å–„)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",  # Viteé–‹ç™ºã‚µãƒ¼ãƒãƒ¼
        "http://localhost:3000",  # ä»£æ›¿ãƒãƒ¼ãƒˆ
        "http://127.0.0.1:5173",
        "http://127.0.0.1:3000"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)
```

### æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

```yaml
ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯:
  - FastAPI: 0.112.0+ (é«˜æ€§èƒ½Webãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯)
  - Uvicorn: 0.30.0+ (ASGIã‚µãƒ¼ãƒãƒ¼)
  - Pydantic: 2.9.2+ (ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼)

HTTPãƒ»é€šä¿¡:
  - aiohttp: 3.10.10+ (éåŒæœŸHTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ)
  - requests: 2.32.3+ (åŒæœŸHTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ)
  - python-multipart: 0.0.9+ (ãƒãƒ«ãƒãƒ‘ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ å‡¦ç†)

AIãƒ»æ©Ÿæ¢°å­¦ç¿’:
  - google-generativeai: 0.7.2+ (Gemini API)
  - numpy: 2.1.0+ (æ•°å€¤è¨ˆç®—)
  - soundfile: 0.12.1+ (éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«I/O)
  - librosa: 0.10.1+ (éŸ³å£°è§£æ)
  - onnxruntime: 1.18.0+ (AIæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³)

ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£:
  - python-dotenv: 1.0.1+ (ç’°å¢ƒå¤‰æ•°ç®¡ç†)
  - PyYAML: 6.0.1+ (YAMLå‡¦ç†)
  - tqdm: 4.66.4+ (é€²æ—è¡¨ç¤º)
  - psutil: 5.9.0+ (ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–)
```

## ğŸ¤– AIçµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒãƒ«ãƒAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼çµ±åˆ

```mermaid
graph LR
    subgraph "AIçµ±åˆã‚·ã‚¹ãƒ†ãƒ "
        subgraph "ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†"
            Request[API Request]
            ModelSelection[ãƒ¢ãƒ‡ãƒ«é¸æŠ]
            KeyValidation[APIã‚­ãƒ¼æ¤œè¨¼]
        end

        subgraph "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç®¡ç†"
            StreamManager[Stream Manager]
            ChunkProcessor[Chunk Processor]
            SSEFormatter[SSE Formatter]
        end

        subgraph "ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥å®Ÿè£…"
            ClaudeStream[Claude Streaming<br/>stream_claude]
            OpenAIStream[OpenAI Streaming<br/>stream_openai]
            GeminiStream[Gemini Streaming<br/>stream_gemini]
        end

        subgraph "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"
            ErrorDetector[ã‚¨ãƒ©ãƒ¼æ¤œçŸ¥]
            Retry[ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯]
            Fallback[ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯]
        end
    end

    Request --> ModelSelection
    ModelSelection --> KeyValidation
    KeyValidation --> StreamManager

    StreamManager --> ClaudeStream
    StreamManager --> OpenAIStream
    StreamManager --> GeminiStream

    ClaudeStream --> ChunkProcessor
    OpenAIStream --> ChunkProcessor
    GeminiStream --> ChunkProcessor

    ChunkProcessor --> SSEFormatter
    ChunkProcessor --> ErrorDetector

    ErrorDetector --> Retry
    Retry --> Fallback

    style StreamManager fill:#e1f5fe
    style ChunkProcessor fill:#fff3e0
    style ErrorDetector fill:#ffebee
```

### AIçµ±åˆå®Ÿè£…è©³ç´°

#### A. StreamingAIModelManager ã‚¯ãƒ©ã‚¹

**å®Ÿè£…**: `backend/ai_agent/main.py:102-424`

```python
class StreamingAIModelManager:
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œAIçµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""

    def __init__(self):
        self.default_api_keys = DEFAULT_API_KEYS

    def get_api_key(self, provider: str, custom_keys: Optional[Dict[str, str]] = None) -> Optional[str]:
        """APIã‚­ãƒ¼å–å¾—ï¼ˆã‚«ã‚¹ã‚¿ãƒ ã‚­ãƒ¼å„ªå…ˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        if custom_keys and provider in custom_keys and custom_keys[provider]:
            return custom_keys[provider]
        return self.default_api_keys.get(provider)

    async def stream_claude(self, message: str, context: Any = "", api_key: str = None):
        """Claude APIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‘¼ã³å‡ºã—"""
        # éŸ³æ¥½åˆ¶ä½œç‰¹åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        # Anthropic Messages APIå‘¼ã³å‡ºã—
        # Server-Sent Eventså½¢å¼ã§ã‚¹ãƒˆãƒªãƒ¼ãƒ è¿”å´

    async def stream_openai(self, message: str, context: Any = "", api_key: str = None):
        """OpenAI APIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‘¼ã³å‡ºã—"""
        # GPT-4 Chat Completions APIå‘¼ã³å‡ºã—
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†

    async def stream_gemini(self, message: str, context: Any = "", api_key: str = None):
        """Gemini APIã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‘¼ã³å‡ºã—"""
        # Gemini Generative AI APIå‘¼ã³å‡ºã—
        # æ–‡å­—å˜ä½ç–‘ä¼¼ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° (APIåˆ¶é™ã®ãŸã‚)
```

#### B. éŸ³æ¥½åˆ¶ä½œå°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰

**å®Ÿè£…**: `backend/ai_agent/main.py:120-172`

```python
# éŸ³æ¥½åˆ¶ä½œå°‚ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
system_prompt = """ã‚ãªãŸã¯éŸ³æ¥½åˆ¶ä½œã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³æ¥½åˆ¶ä½œã«é–¢ã™ã‚‹è³ªå•ã‚„è¦æ±‚ã«å¯¾ã—ã¦ã€å°‚é–€çš„ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®åˆ†é‡ã«ã¤ã„ã¦è©³ã—ãå›ç­”ã§ãã¾ã™ï¼š
- ä½œæ›²ãƒ»ç·¨æ›²ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯
- æ¥½å™¨ã®æ¼”å¥æ–¹æ³•
- éŸ³æ¥½ç†è«–
- DAWã®ä½¿ã„æ–¹
- ãƒŸã‚­ã‚·ãƒ³ã‚°ãƒ»ãƒã‚¹ã‚¿ãƒªãƒ³ã‚°
- éŸ³æ¥½ã‚¸ãƒ£ãƒ³ãƒ«ã®ç‰¹å¾´
- MIDIç·¨é›†

å›ç­”ã¯æ—¥æœ¬èªã§ã€åˆ†ã‹ã‚Šã‚„ã™ãå…·ä½“çš„ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ±åˆ
context_info = f"""
ã€ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã€‘
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: {project.get('name', 'Unknown')}
ãƒ†ãƒ³ãƒ: {project.get('tempo', 'Unknown')} BPM
ã‚­ãƒ¼: {project.get('key', 'Unknown')}
æ‹å­: {project.get('timeSignature', 'Unknown')}
å†ç”Ÿæ™‚é–“: {project.get('currentTime', 0):.1f}s / {project.get('totalDuration', 0):.1f}s
å†ç”ŸçŠ¶æ…‹: {'å†ç”Ÿä¸­' if project.get('isPlaying') else 'åœæ­¢ä¸­'}
ãƒˆãƒ©ãƒƒã‚¯æ•°: {project.get('tracksCount', 0)}

ã€ç¾åœ¨é¸æŠä¸­ã®ãƒˆãƒ©ãƒƒã‚¯ã€‘
ãƒˆãƒ©ãƒƒã‚¯å: {track.get('name', 'Unknown')}
ã‚¿ã‚¤ãƒ—: {track.get('type', 'Unknown')}
ãƒãƒ¼ãƒˆæ•°: {track.get('notesCount', 0)}
éŸ³é‡: {track.get('volume', 100)}%
"""
```

#### C. Sense-Plan-Act ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

**å®Ÿè£…**: `backend/ai_agent/main.py:1093-1177`

```python
def generate_agent_prompt(user_prompt: str, context: dict) -> str:
    """Sense-Plan-Actã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ãAgent modeç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""

    prompt = f"""ã‚ãªãŸã¯éŸ³æ¥½åˆ¶ä½œã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚Sense-Plan-Actã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å¾“ã£ã¦ã€
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’ç†è§£ã—ã€é©åˆ‡ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

    ## Senseï¼ˆç†è§£ï¼‰æ®µéš
    ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ³ã‚’ç†è§£ã—ã¦ãã ã•ã„ï¼š
    {context_info}

    ## Planï¼ˆè¨ˆç”»ï¼‰æ®µéš
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’åˆ†æã—ã€å®Ÿè¡Œå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¨ˆç”»ã—ã¦ãã ã•ã„ï¼š
    - ãƒˆãƒ©ãƒƒã‚¯ã®è¿½åŠ /ç·¨é›†/å‰Šé™¤
    - MIDIãƒãƒ¼ãƒˆã®è¿½åŠ /ç·¨é›†/å‰Šé™¤
    - ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®é©ç”¨
    - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®šã®å¤‰æ›´

    ## Actï¼ˆå®Ÿè¡Œï¼‰æ®µéš
    è¨ˆç”»ã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
    {{
      "actions": [
        {{
          "type": "æ“ä½œã‚¿ã‚¤ãƒ—",
          "params": {{
            "trackId": "æ­£ç¢ºãªãƒˆãƒ©ãƒƒã‚¯ID",
            "notes": [
              {{
                "id": "note-123",
                "pitch": 60,        // MIDIãƒãƒ¼ãƒˆç•ªå·ï¼ˆ0-127ï¼‰
                "time": 0,          // é–‹å§‹æ™‚é–“ï¼ˆç§’ï¼‰
                "duration": 0.5,    // æŒç¶šæ™‚é–“ï¼ˆç§’ï¼‰
                "velocity": 0.8     // éŸ³é‡ï¼ˆ0-1ï¼‰
              }}
            ]
          }},
          "description": "å®Ÿè¡Œã™ã‚‹æ“ä½œã®èª¬æ˜"
        }}
      ],
      "summary": "å®Ÿè¡Œã—ãŸæ“ä½œã®è¦ç´„",
      "nextSteps": "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ææ¡ˆ"
    }}
    """
```

## ğŸ“¡ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¨­è¨ˆè©³ç´°

### ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæ§‹æˆå›³

```mermaid
graph TB
    subgraph "REST API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"
        subgraph "Health Check"
            Root[GET /<br/>ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±]
            Health[GET /health<br/>ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯]
            AIHealth[GET /ai/api/health<br/>AIçµ±åˆãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯]
        end

        subgraph "Chat API (éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)"
            ChatPost[POST /api/chat<br/>ã‚·ãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒƒãƒˆ]
            ChatAI[POST /ai/api/chat<br/>AIäº’æ›ãƒ‘ã‚¹]
        end

        subgraph "Chat API (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)"
            StreamChat[POST /api/stream/chat<br/>ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒƒãƒˆ]
            StreamChatAI[POST /ai/api/stream/chat<br/>AIäº’æ›ãƒ‘ã‚¹]
        end

        subgraph "Agent API (éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)"
            AgentPost[POST /api/agent<br/>Agent modeå®Ÿè¡Œ]
            AgentAI[POST /ai/api/agent<br/>AIäº’æ›ãƒ‘ã‚¹]
        end

        subgraph "Agent API (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)"
            StreamAgent[POST /api/stream/agent<br/>ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°Agent]
            StreamAgentAI[POST /ai/api/stream/agent<br/>AIäº’æ›ãƒ‘ã‚¹]
        end

        subgraph "Generate API"
            Generate[POST /api/generate<br/>éŸ³æ¥½ç”Ÿæˆ]
            GenerateAI[POST /ai/api/generate<br/>AIäº’æ›ãƒ‘ã‚¹]
        end

        subgraph "Utility API"
            UpdateSummary[POST /ai/api/update-summary<br/>MIDIæ¦‚è¦æ›´æ–°]
        end
    end

    subgraph "DiffSinger API (å®Ÿè£…äºˆå®š)"
        DiffSynth[POST /diffsinger/synthesize<br/>æ­Œå£°åˆæˆ]
        DiffModels[GET /diffsinger/models<br/>ãƒ¢ãƒ‡ãƒ«ä¸€è¦§]
        DiffCache[POST /diffsinger/cache/clear<br/>ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢]
        VoiceSynth[POST /ai/api/voice/synthesize<br/>æ­Œå£°åˆæˆäº’æ›]
        VoiceHealth[GET /ai/api/voice/health<br/>æ­Œå£°APIçŠ¶æ…‹]
    end

    subgraph "Ghost Text API (å®Ÿè£…äºˆå®š)"
        GhostComplete[POST /ghost_text/complete<br/>ãƒ†ã‚­ã‚¹ãƒˆè£œå®Œ]
        GhostAnalyze[POST /ghost_text/analyze<br/>ãƒ†ã‚­ã‚¹ãƒˆè§£æ]
    end

    style StreamChat fill:#e1f5fe
    style StreamAgent fill:#fff3e0
    style DiffSynth fill:#fce4ec
    style GhostComplete fill:#f3e5f5
```

### ä¸»è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä»•æ§˜

#### A. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒƒãƒˆAPI

**ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ**: `POST /api/stream/chat`
**å®Ÿè£…**: `backend/ai_agent/main.py:902-978`

```python
@app.post("/api/stream/chat")
async def stream_chat(request: StreamingChatRequest):
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""

    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
    class StreamingChatRequest(BaseModel):
        message: str
        context: Optional[Any] = ""
        model: str = "claude-3-sonnet"
        apiKeys: Optional[Dict[str, str]] = None

    # ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒãƒƒãƒ”ãƒ³ã‚°
    model_config = {
        "claude-3-sonnet": {"provider": "anthropic", "api_key_name": "anthropic"},
        "gpt-4": {"provider": "openai", "api_key_name": "openai"},
        "gemini-2.5-pro": {"provider": "google", "api_key_name": "google"},
    }

    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
    async def event_generator():
        if request.model.startswith("claude"):
            async for chunk in StreamingAIModelManager().stream_claude(...):
                yield chunk
        elif request.model.startswith("gpt"):
            async for chunk in StreamingAIModelManager().stream_openai(...):
                yield chunk
        elif request.model.startswith("gemini"):
            async for chunk in StreamingAIModelManager().stream_gemini(...):
                yield chunk

    return StreamingResponse(content=event_generator(), media_type="text/event-stream")
```

**ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ (Server-Sent Events)**:
```
data: {"type": "text", "content": "ã“ã‚“ã«ã¡ã¯"}

data: {"type": "text", "content": "éŸ³æ¥½åˆ¶ä½œã«"}

data: [DONE]
```

#### B. Agent Mode API

**ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ**: `POST /api/agent`
**å®Ÿè£…**: `backend/ai_agent/main.py:831-899`

```python
@app.post("/api/agent", response_model=AgentResponse)
async def agent_action(request: AgentRequest):
    """Agent modeå®Ÿè¡Œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""

    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
    class AgentRequest(BaseModel):
        prompt: str
        context: Optional[Any] = {}
        model: str = "claude-3-sonnet"
        apiKey: str = ""
        stream: bool = False

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
    class AgentResponse(BaseModel):
        actions: List[Dict[str, Any]]  # å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        summary: str                   # æ“ä½œè¦ç´„
        nextSteps: str                 # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ææ¡ˆ
        success: bool
        error: str = ""

    # Agentç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    agent_prompt = generate_agent_prompt(request.prompt, request.context)

    # AIå‘¼ã³å‡ºã—
    response_text = await ai_manager.call_claude(agent_prompt, request.context, api_key)

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
    parsed_response = parse_agent_response(response_text, request.context)

    return AgentResponse(
        actions=parsed_response.get("actions", []),
        summary=parsed_response.get("summary", "æ“ä½œãŒå®Œäº†ã—ã¾ã—ãŸ"),
        nextSteps=parsed_response.get("nextSteps", "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„"),
        success=True
    )
```

#### C. éŸ³æ¥½ç”ŸæˆAPI

**ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ**: `POST /api/generate`
**å®Ÿè£…**: `backend/ai_agent/main.py:705-776`

```python
@app.post("/api/generate", response_model=GenerateResponse)
async def generate_music(request: GenerateRequest):
    """éŸ³æ¥½ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ (Gemini Proä½¿ç”¨)"""

    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
    class GenerateRequest(BaseModel):
        prompt: str
        model: str = "gemini-2.5-pro"
        apiKey: str = ""

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
    class GenerateResponse(BaseModel):
        type: str           # "drum_pattern"|"bassline"|"chord_progression"|"melody"
        notes: list         # MIDIãƒãƒ¼ãƒˆé…åˆ—
        description: str    # ç”Ÿæˆç‰©èª¬æ˜
        suggestions: str = ""  # è¿½åŠ ææ¡ˆ

    # Gemini APIè¨­å®š
    genai.configure(api_key=api_key)
    temp_model = genai.GenerativeModel('gemini-2.5-flash')

    # éŸ³æ¥½ç”Ÿæˆç‰¹åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    music_prompt = f"""
    ã‚ãªãŸã¯éŸ³æ¥½åˆ¶ä½œAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æŒ‡ç¤ºã«åŸºã¥ã„ã¦ã€éŸ³æ¥½è¦ç´ ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

    [ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤º]
    {request.prompt}

    [å‡ºåŠ›å½¢å¼]
    {{
      "type": "drum_pattern"|"bassline"|"chord_progression"|"melody"|"harmony",
      "notes": [
        {{"pitch": 60, "start": 0.0, "duration": 0.25, "velocity": 100}},
        ...
      ],
      "description": "ç”Ÿæˆã—ãŸéŸ³æ¥½è¦ç´ ã®èª¬æ˜",
      "suggestions": "è¿½åŠ ã®ææ¡ˆã‚„ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³"
    }}
    """

    response = temp_model.generate_content(music_prompt)
    # JSONè§£æã—ã¦è¿”å´
```

## ğŸ¤ DiffSinger æ­Œå£°åˆæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ (å®Ÿè£…äºˆå®š)

### DiffSinger ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph "DiffSingeræ­Œå£°åˆæˆã‚·ã‚¹ãƒ†ãƒ "
        subgraph "å‰å‡¦ç†å±¤"
            LyricsInput[æ­Œè©å…¥åŠ›]
            MelodyInput[ãƒ¡ãƒ­ãƒ‡ã‚£å…¥åŠ›]
            PhonemeDictionary[éŸ³ç´ è¾æ›¸]
            Alignment[éŸ³ç´ ãƒ»ãƒ¡ãƒ­ãƒ‡ã‚£æ•´åˆ]
        end

        subgraph "éŸ³éŸ¿ãƒ¢ãƒ‡ãƒ«å±¤"
            AcousticModel[DiffSinger<br/>Acoustic Model]
            DiffusionProcess[Diffusion Process]
            FeatureExtraction[ç‰¹å¾´é‡æŠ½å‡º]
        end

        subgraph "ãƒœã‚³ãƒ¼ãƒ€ãƒ¼å±¤"
            Vocoder[HiFi-GAN<br/>Vocoder]
            WaveformGen[æ³¢å½¢ç”Ÿæˆ]
            QualityEnhance[å“è³ªå‘ä¸Šå‡¦ç†]
        end

        subgraph "å¾Œå‡¦ç†å±¤"
            AudioFX[éŸ³å£°ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ]
            Normalization[æ­£è¦åŒ–]
            Export[ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ]
        end

        subgraph "ç®¡ç†ãƒ»æœ€é©åŒ–å±¤"
            ModelManager[ãƒ¢ãƒ‡ãƒ«ç®¡ç†]
            CacheManager[ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†]
            ProgressTracker[é€²æ—è¿½è·¡]
            ResourceMonitor[ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–]
        end
    end

    LyricsInput --> PhonemeDictionary
    MelodyInput --> Alignment
    PhonemeDictionary --> Alignment

    Alignment --> AcousticModel
    AcousticModel --> DiffusionProcess
    DiffusionProcess --> FeatureExtraction

    FeatureExtraction --> Vocoder
    Vocoder --> WaveformGen
    WaveformGen --> QualityEnhance

    QualityEnhance --> AudioFX
    AudioFX --> Normalization
    Normalization --> Export

    ModelManager --> AcousticModel
    ModelManager --> Vocoder
    CacheManager --> DiffusionProcess
    ProgressTracker --> WaveformGen
    ResourceMonitor --> QualityEnhance

    style AcousticModel fill:#e1f5fe
    style Vocoder fill:#fff3e0
    style CacheManager fill:#e8f5e9
```

### å®Ÿè£…ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€  (è¨ˆç”»)

```
backend/diffsinger/
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ acoustic_inference.py     # éŸ³éŸ¿ãƒ¢ãƒ‡ãƒ«æ¨è«–
â”‚   â”œâ”€â”€ vocoder_inference.py      # ãƒœã‚³ãƒ¼ãƒ€ãƒ¼æ¨è«–
â”‚   â””â”€â”€ pipeline.py               # çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ acoustic_model.py         # DiffSingerå®Ÿè£…
â”‚   â”œâ”€â”€ vocoder_model.py          # HiFi-GANå®Ÿè£…
â”‚   â””â”€â”€ diffusion.py              # Diffusionå®Ÿè£…
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ phoneme_converter.py      # éŸ³ç´ å¤‰æ›
â”‚   â”œâ”€â”€ alignment.py              # éŸ³ç´ ãƒ»ãƒ¡ãƒ­ãƒ‡ã‚£æ•´åˆ
â”‚   â””â”€â”€ feature_extractor.py     # ç‰¹å¾´é‡æŠ½å‡º
â””â”€â”€ utils/
    â”œâ”€â”€ model_manager.py          # ãƒ¢ãƒ‡ãƒ«ç®¡ç†
    â”œâ”€â”€ cache_manager.py          # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
    â””â”€â”€ progress_tracker.py       # é€²æ—è¿½è·¡
```

### æŠ€è¡“ä»•æ§˜

```yaml
éŸ³éŸ¿ãƒ¢ãƒ‡ãƒ«:
  - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: DiffSinger (Diffusion-based Singing Voice Synthesis)
  - å…¥åŠ›: éŸ³ç´ ç³»åˆ— + ãƒ¡ãƒ­ãƒ‡ã‚£ + ãƒªã‚ºãƒ 
  - å‡ºåŠ›: Mel-spectrogram (éŸ³éŸ¿ç‰¹å¾´é‡)
  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: ~200MB

ãƒœã‚³ãƒ¼ãƒ€ãƒ¼:
  - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: HiFi-GAN (High-Fidelity Generative Adversarial Network)
  - å…¥åŠ›: Mel-spectrogram
  - å‡ºåŠ›: æ³¢å½¢ (Waveform)
  - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: 44.1kHz
  - ãƒ“ãƒƒãƒˆæ·±åº¦: 16bit

éŸ³ç´ è¾æ›¸:
  - æ—¥æœ¬èª: CMUè¾æ›¸ãƒ™ãƒ¼ã‚¹
  - è‹±èª: ARPABET
  - å¯¾å¿œè¨€èª: æ—¥æœ¬èªãƒ»è‹±èª

ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:
  - åˆæˆé€Ÿåº¦: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  x 5-10 (GPUä½¿ç”¨æ™‚)
  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 2-4GB (GPU VRAM)
  - å“è³ª: è‡ªç„¶åº¦ 85%+ (ä¸»è¦³è©•ä¾¡)
```

## âœ¨ Ghost Text ãƒ†ã‚­ã‚¹ãƒˆè£œå®Œã‚·ã‚¹ãƒ†ãƒ  (å®Ÿè£…äºˆå®š)

### Ghost Text ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph "Ghost Textãƒ†ã‚­ã‚¹ãƒˆè£œå®Œã‚·ã‚¹ãƒ†ãƒ "
        subgraph "å…¥åŠ›è§£æå±¤"
            TextInput[ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›<br/>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ]
            ContextExtraction[ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º]
            PatternAnalysis[ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ]
        end

        subgraph "äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³å±¤"
            LanguageModel[è»½é‡è¨€èªãƒ¢ãƒ‡ãƒ«<br/>Phi-2/TinyLlama]
            MusicVocabulary[éŸ³æ¥½å°‚ç”¨èªå½™]
            KnowledgeBase[éŸ³æ¥½çŸ¥è­˜ãƒ™ãƒ¼ã‚¹]
        end

        subgraph "å€™è£œç”Ÿæˆå±¤"
            CandidateGen[å€™è£œç”Ÿæˆ]
            Ranking[ãƒ©ãƒ³ã‚­ãƒ³ã‚°]
            Filtering[éŸ³æ¥½ç‰¹åŒ–ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°]
        end

        subgraph "å­¦ç¿’ãƒ»é©å¿œå±¤"
            UserProfile[ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«]
            FeedbackLoop[ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—]
            AdaptiveLearning[é©å¿œå­¦ç¿’]
        end

        subgraph "è¡¨ç¤ºåˆ¶å¾¡å±¤"
            GhostRenderer[Ghostè¡¨ç¤ºãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°]
            AcceptReject[æ¡ç”¨ãƒ»å´ä¸‹å‡¦ç†]
            UIIntegration[UIçµ±åˆ]
        end
    end

    TextInput --> ContextExtraction
    ContextExtraction --> PatternAnalysis
    PatternAnalysis --> LanguageModel

    LanguageModel --> MusicVocabulary
    MusicVocabulary --> KnowledgeBase
    KnowledgeBase --> CandidateGen

    CandidateGen --> Ranking
    Ranking --> Filtering
    Filtering --> GhostRenderer

    GhostRenderer --> AcceptReject
    AcceptReject --> FeedbackLoop
    FeedbackLoop --> UserProfile
    UserProfile --> AdaptiveLearning
    AdaptiveLearning --> LanguageModel

    style LanguageModel fill:#e1f5fe
    style KnowledgeBase fill:#fff3e0
    style GhostRenderer fill:#e8f5e9
```

### å®Ÿè£…ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€  (è¨ˆç”»)

```
backend/ghost_text/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ language_model.py         # è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ©ãƒƒãƒ‘ãƒ¼
â”‚   â”œâ”€â”€ music_vocabulary.py       # éŸ³æ¥½èªå½™ç®¡ç†
â”‚   â””â”€â”€ knowledge_base.py         # çŸ¥è­˜ãƒ™ãƒ¼ã‚¹
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ context_extractor.py      # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
â”‚   â”œâ”€â”€ pattern_analyzer.py       # ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
â”‚   â””â”€â”€ tokenizer.py              # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
â”œâ”€â”€ prediction/
â”‚   â”œâ”€â”€ candidate_generator.py    # å€™è£œç”Ÿæˆ
â”‚   â”œâ”€â”€ ranker.py                 # ãƒ©ãƒ³ã‚­ãƒ³ã‚°
â”‚   â””â”€â”€ filter.py                 # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
â”œâ”€â”€ learning/
â”‚   â”œâ”€â”€ user_profiler.py          # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
â”‚   â”œâ”€â”€ feedback_processor.py     # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å‡¦ç†
â”‚   â””â”€â”€ adaptive_learner.py       # é©å¿œå­¦ç¿’
â””â”€â”€ utils/
    â”œâ”€â”€ cache.py                  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
    â””â”€â”€ performance_monitor.py    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
```

### æŠ€è¡“ä»•æ§˜

```yaml
è¨€èªãƒ¢ãƒ‡ãƒ«:
  - ãƒ¢ãƒ‡ãƒ«: Microsoft Phi-2 ã¾ãŸã¯ TinyLlama
  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 2.7B (Phi-2) / 1.1B (TinyLlama)
  - æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³: ONNX Runtime (CPUæœ€é©åŒ–)
  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 512MB - 1GB

éŸ³æ¥½çŸ¥è­˜ãƒ™ãƒ¼ã‚¹:
  - ã‚³ãƒ¼ãƒ‰é€²è¡Œ: 1000+ ãƒ‘ã‚¿ãƒ¼ãƒ³
  - æ­Œè©ãƒ‘ã‚¿ãƒ¼ãƒ³: 500+ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
  - éŸ»å¾‹ã‚¹ã‚­ãƒ¼ãƒ : 100+ ãƒ‘ã‚¿ãƒ¼ãƒ³
  - ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥èªå½™: 10000+ å˜èª

ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:
  - äºˆæ¸¬é…å»¶: <300ms (å…¥åŠ›å¾Œ)
  - å€™è£œæ•°: ä¸Šä½3ä»¶
  - ç²¾åº¦: æ¡ç”¨ç‡ 85%+
  - å¯¾å¿œè¨€èª: æ—¥æœ¬èªãƒ»è‹±èª
```

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å±¤

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å±¤"
        subgraph "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£"
            CORS[CORSè¨­å®š<br/>âš ï¸ è¦æ”¹å–„]
            RateLimit[ãƒ¬ãƒ¼ãƒˆåˆ¶é™<br/>æœªå®Ÿè£…]
            IPFilter[IPãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°<br/>æœªå®Ÿè£…]
        end

        subgraph "èªè¨¼ãƒ»èªå¯"
            APIKeyMgmt[APIã‚­ãƒ¼ç®¡ç†<br/>ç’°å¢ƒå¤‰æ•°]
            TokenAuth[ãƒˆãƒ¼ã‚¯ãƒ³èªè¨¼<br/>æœªå®Ÿè£…]
            RoleAccess[ãƒ­ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹<br/>æœªå®Ÿè£…]
        end

        subgraph "å…¥åŠ›æ¤œè¨¼"
            Pydantic[Pydanticæ¤œè¨¼<br/>âœ… å®Ÿè£…æ¸ˆã¿]
            Sanitization[ã‚µãƒ‹ã‚¿ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³<br/>éƒ¨åˆ†å®Ÿè£…]
            XSSProtection[XSSå¯¾ç­–<br/>éƒ¨åˆ†å®Ÿè£…]
        end

        subgraph "ãƒ‡ãƒ¼ã‚¿ä¿è­·"
            SecretMgmt[ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†<br/>âœ… .env]
            Encryption[æš—å·åŒ–<br/>æœªå®Ÿè£…]
            AuditLog[ç›£æŸ»ãƒ­ã‚°<br/>æœªå®Ÿè£…]
        end

        subgraph "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"
            ErrorLogging[ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°<br/>éƒ¨åˆ†å®Ÿè£…]
            SecureError[ã‚»ã‚­ãƒ¥ã‚¢ã‚¨ãƒ©ãƒ¼<br/>éƒ¨åˆ†å®Ÿè£…]
            Monitoring[ç›£è¦–<br/>æœªå®Ÿè£…]
        end
    end

    CORS --> APIKeyMgmt
    RateLimit --> TokenAuth
    IPFilter --> RoleAccess

    APIKeyMgmt --> Pydantic
    TokenAuth --> Sanitization
    RoleAccess --> XSSProtection

    Pydantic --> SecretMgmt
    Sanitization --> Encryption
    XSSProtection --> AuditLog

    SecretMgmt --> ErrorLogging
    Encryption --> SecureError
    AuditLog --> Monitoring

    style CORS fill:#ffebee
    style APIKeyMgmt fill:#fff3e0
    style Pydantic fill:#e8f5e9
```

### ç¾åœ¨ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£çŠ¶æ³

#### ğŸ”´ HIGH: ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªå•é¡Œ

**1. CORSè¨­å®šã®éåº¦ãªè¨±å¯**

**å ´æ‰€**: `backend/ai_agent/main.py:29-40`

```python
# âš ï¸ å•é¡Œ: æœ¬ç•ªç’°å¢ƒã§ã¯ä¸é©åˆ‡
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",  # Viteé–‹ç™ºã‚µãƒ¼ãƒãƒ¼
        "http://localhost:3000",  # ä»£æ›¿ãƒãƒ¼ãƒˆ
        "http://127.0.0.1:5173",
        "http://127.0.0.1:3000"
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],  # âš ï¸ ã™ã¹ã¦ã®ãƒ˜ãƒƒãƒ€ãƒ¼è¨±å¯
)
```

**æ¨å¥¨æ”¹å–„ç­–**:
```python
# âœ… æ”¹å–„æ¡ˆ: ç’°å¢ƒåˆ¥CORSè¨­å®š
import os

ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "http://localhost:5173").split(",")

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],  # å¿…è¦ãªãƒ¡ã‚½ãƒƒãƒ‰ã®ã¿
    allow_headers=["Content-Type", "Authorization"],  # å¿…è¦ãªãƒ˜ãƒƒãƒ€ãƒ¼ã®ã¿
    max_age=3600,  # ãƒ—ãƒªãƒ•ãƒ©ã‚¤ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥
)
```

**2. ãƒ›ã‚¹ãƒˆè¨­å®šã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯**

**å ´æ‰€**: `backend/ai_agent/main.py:1388`

```python
# âš ï¸ å•é¡Œ: ã™ã¹ã¦ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§å¾…ã¡å—ã‘
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**æ¨å¥¨æ”¹å–„ç­–**:
```python
# âœ… æ”¹å–„æ¡ˆ: ç’°å¢ƒåˆ¥ãƒ›ã‚¹ãƒˆè¨­å®š
import os

HOST = os.getenv("API_HOST", "127.0.0.1")  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ›ã‚¹ãƒˆã®ã¿
PORT = int(os.getenv("API_PORT", "8000"))
RELOAD = os.getenv("ENV", "development") == "development"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app,
        host=HOST,
        port=PORT,
        reload=RELOAD,
        log_level="info"
    )
```

**3. APIã‚­ãƒ¼æœªè¨­å®šæ™‚ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**

**å ´æ‰€**: å„AIå‘¼ã³å‡ºã—ç®‡æ‰€

```python
# ç¾åœ¨ã®å®Ÿè£…
if not api_key:
    raise ValueError("Claude API key is required")  # âš ï¸ ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹éœ²å‡ºãƒªã‚¹ã‚¯
```

**æ¨å¥¨æ”¹å–„ç­–**:
```python
# âœ… æ”¹å–„æ¡ˆ: ã‚»ã‚­ãƒ¥ã‚¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
if not api_key:
    logger.warning(f"API key not configured for provider: {provider}")
    raise HTTPException(
        status_code=401,
        detail="API key not configured. Please set up your API key in settings."
    )
```

#### ğŸŸ¡ MEDIUM: æ”¹å–„æ¨å¥¨äº‹é …

**1. ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å®Ÿè£…**

```python
# âœ… æ¨å¥¨: SlowAPIã«ã‚ˆã‚‹ãƒ¬ãƒ¼ãƒˆåˆ¶é™
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/api/chat")
@limiter.limit("10/minute")  # 1åˆ†ã‚ãŸã‚Š10ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
async def chat(request: ChatRequest):
    ...
```

**2. å…¥åŠ›æ¤œè¨¼ã®å¼·åŒ–**

```python
# âœ… æ¨å¥¨: ã‚ˆã‚Šå³æ ¼ãªå…¥åŠ›æ¤œè¨¼
from pydantic import BaseModel, Field, validator

class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=2000)
    context: Optional[Any] = Field(default="", max_length=10000)
    model: str = Field(..., regex="^(claude|gpt|gemini)-.*$")

    @validator('message')
    def sanitize_message(cls, v):
        # XSSå¯¾ç­–: HTMLã‚¿ã‚°é™¤å»
        import html
        return html.escape(v)
```

**3. ç›£æŸ»ãƒ­ã‚°ã®å®Ÿè£…**

```python
# âœ… æ¨å¥¨: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ãƒ­ã‚°
import logging

security_logger = logging.getLogger("security")

@app.post("/api/agent")
async def agent_action(request: AgentRequest):
    security_logger.info(
        f"Agent action requested: model={request.model}, "
        f"prompt_length={len(request.prompt)}, "
        f"context_size={len(str(request.context))}"
    )
    ...
```

#### âœ… å®Ÿè£…æ¸ˆã¿ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½

- **Pydanticæ¤œè¨¼**: ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ãƒ‡ãƒ¼ã‚¿å‹ãƒ»æ§‹é€ æ¤œè¨¼
- **ç’°å¢ƒå¤‰æ•°ç®¡ç†**: `.env`ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ˆã‚‹ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†
- **FastAPIè‡ªå‹•æ¤œè¨¼**: è‡ªå‹•å…¥åŠ›æ¤œè¨¼ãƒ»ã‚µãƒ‹ã‚¿ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–"
        subgraph "éåŒæœŸå‡¦ç†"
            AsyncIO[Async I/O<br/>âœ… å®Ÿè£…æ¸ˆã¿]
            EventLoop[ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—]
            Concurrency[ä¸¦è¡Œå‡¦ç†]
        end

        subgraph "ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°"
            ResponseCache[ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥<br/>éƒ¨åˆ†å®Ÿè£…]
            ModelCache[ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥<br/>è¨ˆç”»ä¸­]
            CDN[CDNé…ä¿¡<br/>æœªå®Ÿè£…]
        end

        subgraph "ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°"
            SSE[Server-Sent Events<br/>âœ… å®Ÿè£…æ¸ˆã¿]
            ChunkedTransfer[ãƒãƒ£ãƒ³ã‚¯è»¢é€]
            Backpressure[ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼]
        end

        subgraph "ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†"
            MemoryMgmt[ãƒ¡ãƒ¢ãƒªç®¡ç†]
            ConnectionPool[æ¥ç¶šãƒ—ãƒ¼ãƒ«]
            LoadShedding[è² è·åˆ¶å¾¡]
        end
    end

    AsyncIO --> ResponseCache
    EventLoop --> ModelCache
    Concurrency --> CDN

    ResponseCache --> SSE
    ModelCache --> ChunkedTransfer
    CDN --> Backpressure

    SSE --> MemoryMgmt
    ChunkedTransfer --> ConnectionPool
    Backpressure --> LoadShedding

    style AsyncIO fill:#e8f5e9
    style SSE fill:#e1f5fe
    style ResponseCache fill:#fff3e0
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™

| é …ç›® | ç›®æ¨™å€¤ | ç¾çŠ¶ | çŠ¶æ…‹ |
|------|--------|------|------|
| **APIå¿œç­”æ™‚é–“ (ãƒãƒ£ãƒƒãƒˆ)** | <3ç§’ | ~2ç§’ | âœ… ç›®æ¨™é”æˆ |
| **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹é…å»¶** | <1ç§’ | ~0.8ç§’ | âœ… ç›®æ¨™é”æˆ |
| **ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†** | 100+ | ~50 | ğŸŸ¡ æ”¹å–„ä½™åœ° |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (å¾…æ©Ÿæ™‚)** | <500MB | ~300MB | âœ… ç›®æ¨™é”æˆ |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (DiffSinger)** | <4GB | æœªå®Ÿè£… | - |
| **APIæˆåŠŸç‡** | >95% | >98% | âœ… ç›®æ¨™é”æˆ |

### ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£æˆ¦ç•¥

```yaml
å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°:
  - CPU: 4ã‚³ã‚¢ â†’ 8ã‚³ã‚¢ (AIæ¨è«–è² è·å¯¾å¿œ)
  - RAM: 8GB â†’ 16GB (DiffSingerå¯¾å¿œ)
  - GPU: ã‚ªãƒ—ã‚·ãƒ§ãƒ³ (T4ä»¥ä¸Šæ¨å¥¨)

æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°:
  - ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼: Nginx/Traefik
  - ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹è¨­è¨ˆ: âœ… å®Ÿè£…æ¸ˆã¿
  - ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†: Redis (è¨ˆç”»ä¸­)
  - API Gateway: Kong/AWS API Gateway (å°†æ¥)

ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥:
  - AIå¿œç­”ã‚­ãƒ£ãƒƒã‚·ãƒ¥: Redis (è¨ˆç”»ä¸­)
  - ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥: ãƒ¡ãƒ¢ãƒª + ãƒ‡ã‚£ã‚¹ã‚¯
  - CDN: CloudFlare/AWS CloudFront (æœ¬ç•ªç’°å¢ƒ)
```

## ğŸ”— é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

### ä¸Šä½ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- **[L1: ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](../L1_system.md)** - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“æ§‹æˆ
- **[L0: ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦](../../../overview/index.md)** - ãƒ“ã‚¸ãƒã‚¹ãƒ»æŠ€è¡“æ¦‚è¦

### åŒãƒ¬ãƒ™ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- **[L2: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æ§‹æˆ](../L2_frontend/)** - Reactè©³ç´°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- **[L2: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼](../../flows/L2_component/)** - ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ•ãƒ­ãƒ¼

### é–¢é€£è¦ä»¶
- **[L2: AIçµ±åˆè¦ä»¶](../../../requirements/functional/L2_ai_integration/)** - AIæ©Ÿèƒ½è¦ä»¶è©³ç´°
- **[L2: éæ©Ÿèƒ½è¦ä»¶](../../../requirements/non-functional/)** - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶

### è¨­è¨ˆè©³ç´°
- **[L2: APIè¨­è¨ˆ](../../../design/api/L2_endpoints/)** - ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè©³ç´°è¨­è¨ˆ
- **[L2: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³](../../../design/sequences/L2_component/)** - å‡¦ç†ãƒ•ãƒ­ãƒ¼è©³ç´°

---

## ğŸ“‹ å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§

### ä¸»è¦å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | è¡Œæ•° | å½¹å‰² | å®Ÿè£…çŠ¶æ³ |
|---------|------|------|----------|
| `backend/ai_agent/main.py` | 1390 | AIçµ±åˆãƒãƒ–ãƒ»FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ | âœ… å®Œå…¨å®Ÿè£… |
| `backend/requirements.txt` | 16 | ä¾å­˜é–¢ä¿‚å®šç¾© | âœ… å®Œå…¨å®Ÿè£… |
| `backend/diffsinger/` | - | DiffSingeræ­Œå£°åˆæˆ (ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæœªä½œæˆ) | ğŸ”„ å®Ÿè£…äºˆå®š |
| `backend/ghost_text/` | - | Ghost Textãƒ†ã‚­ã‚¹ãƒˆè£œå®Œ (ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæœªä½œæˆ) | ğŸ”„ å®Ÿè£…äºˆå®š |

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€  (ç¾çŠ¶)

```
backend/
â”œâ”€â”€ ai_agent/
â”‚   â””â”€â”€ main.py (1390è¡Œ) - AIçµ±åˆãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ requirements.txt (16è¡Œ) - ä¾å­˜é–¢ä¿‚
â””â”€â”€ README.md (æ¨å¥¨)
```

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€  (å®Œå…¨å®Ÿè£…æ™‚)

```
backend/
â”œâ”€â”€ ai_agent/
â”‚   â”œâ”€â”€ main.py              - FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”œâ”€â”€ models.py            - Pydanticãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ config.py            - è¨­å®šç®¡ç†
â”‚   â””â”€â”€ utils.py             - ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”œâ”€â”€ diffsinger/
â”‚   â”œâ”€â”€ inference/           - æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
â”‚   â”œâ”€â”€ modules/             - ãƒ¢ãƒ‡ãƒ«å®Ÿè£…
â”‚   â”œâ”€â”€ preprocessing/       - å‰å‡¦ç†
â”‚   â””â”€â”€ utils/               - ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”œâ”€â”€ ghost_text/
â”‚   â”œâ”€â”€ models/              - è¨€èªãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ preprocessing/       - å‰å‡¦ç†
â”‚   â”œâ”€â”€ prediction/          - äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³
â”‚   â””â”€â”€ utils/               - ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”œâ”€â”€ common/
â”‚   â”œâ”€â”€ middleware.py        - ã‚«ã‚¹ã‚¿ãƒ ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
â”‚   â”œâ”€â”€ security.py          - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½
â”‚   â””â”€â”€ logging.py           - ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
â”œâ”€â”€ requirements.txt         - ä¾å­˜é–¢ä¿‚
â””â”€â”€ README.md                - ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰
```

---

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³å±¥æ­´**:
- 2.0.0 (2025-10-05): åˆç‰ˆä½œæˆ - ç¾åœ¨ã®å®Ÿè£…ã‚’æ­£ç¢ºã«åæ˜ 
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£èª²é¡Œã®æ˜ç¢ºåŒ–
- DiffSinger/Ghost Textå®Ÿè£…è¨ˆç”»ã®è©³ç´°åŒ–
