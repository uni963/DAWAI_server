/*
 * EnhancedMidiEditor - MIDI Editor Component
 * 
 * é‡è¦: ãƒ¡ãƒ‹ãƒ¥ãƒ¼è¡¨ç¤ºæ™‚ã®æ³¨æ„ç‚¹
 * - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆã‚³ãƒ”ãƒ¼/ã‚«ãƒƒãƒˆ/å‰Šé™¤ï¼‰ã¨Pasteãƒ¡ãƒ‹ãƒ¥ãƒ¼ã¯å¿…ãšsetTimeoutã§10msé…å»¶ã•ã›ã¦è¡¨ç¤ºã™ã‚‹
 * - ç†ç”±: setSelectedNotes()ãªã©ã®çŠ¶æ…‹æ›´æ–°ã®ç›´å¾Œã«ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹ã¨ã€å†æç”»å‡¦ç†ã§ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãŒéš ã•ã‚Œã‚‹
 * - ä¾‹: setTimeout(() => { showContextMenu(e, note, ids) }, 10)
 * - ä¾‹: setTimeout(() => { showPasteMenu(e, time, pitch) }, 10)
 * 
 * ãƒ¡ãƒ‹ãƒ¥ãƒ¼ä½œæˆæ™‚ã®å¿…é ˆè¨­å®š:
 * - menu.tabIndex = -1
 * - menu.addEventListener('mousedown', e => e.preventDefault())
 * - menu.addEventListener('mouseup', e => e.preventDefault())
 * - menu.addEventListener('contextmenu', e => e.preventDefault())
 */


import { useState, useEffect, useRef, useCallback, useMemo, memo } from 'react'
import { Badge } from './ui/badge.jsx'
import { Slider } from './ui/slider.jsx'
import { Button } from './ui/button.jsx'
import {
  Lightbulb,
  AlertTriangle
} from 'lucide-react'
import MidiEditorToolbar from './MIDIEditor/MidiEditorToolbar.jsx'
import MidiEditorStatusBar from './MIDIEditor/MidiEditorStatusBar.jsx'
import MidiEditorCanvas from './MIDIEditor/MidiEditorCanvas.jsx'
import MidiEditorEventHandlers from './MIDIEditor/MidiEditorEventHandlers.jsx'
import useMidiPersistence from '../hooks/useMidiPersistence.js'
import useMidiAudio from '../hooks/useMidiAudio.js'
import { useBassAudio } from '../hooks/useBassAudio.js'
import useMidiNoteOperations from '../hooks/useMidiNoteOperations.js'
import useMidiEditorState from '../hooks/useMidiEditorState.js'
import useGhostText from '../hooks/useGhostText.js'
import useInstrumentSettings from '../hooks/useInstrumentSettings.js'
import InstrumentSettingsPanel from './MIDIEditor/InstrumentSettingsPanel.jsx'
import { getMidiNoteFromKeyCode, calculateOptimalOctave } from '../utils/keyboardShortcuts.js'


// ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ å®šæ•°
const METRONOME_FREQUENCY = 800 // Hz
const METRONOME_DURATION = 0.1 // ç§’

const EnhancedMidiEditor = ({ 
  trackId, 
  trackType = 'piano',
  trackName = 'Unknown Track',
  trackColor = 'blue',
  midiData,
  onMidiDataUpdate,
  onNoteAdd,
  onNoteRemove,
  onNoteEdit,
  isActive = true,
  onOpenSettings,
  appSettings,
  globalTempo = 120,
  onGlobalTempoChange,
  trackVolume = 75,
  trackMuted = false,
  masterVolume = 100,
  musicTheorySettings = {
    scaleConstraintEnabled: false,
    selectedGenre: null,
    selectedScales: [],
    rootNote: 'C'
  },
  onMusicTheorySettingsChange
}) => {
  // éŸ³é‡æƒ…å ±ã®å—ã‘å–ã‚Šã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆé‡è¤‡ã‚’é˜²ããŸã‚æ¡ä»¶ä»˜ãã§å‡ºåŠ›ï¼‰
  const prevVolumeInfoRef = useRef({ trackVolume, trackMuted, masterVolume })
  if (prevVolumeInfoRef.current.trackVolume !== trackVolume || 
      prevVolumeInfoRef.current.trackMuted !== trackMuted || 
      prevVolumeInfoRef.current.masterVolume !== masterVolume) {
    console.log('ğŸµ Enhanced Midi Editor: Received volume props:', {
      trackId,
      trackVolume,
      trackMuted,
      masterVolume
    })
    prevVolumeInfoRef.current = { trackVolume, trackMuted, masterVolume }
  }
  // çŠ¶æ…‹ç®¡ç†ãƒ•ãƒƒã‚¯ã®ä½¿ç”¨
  const state = useMidiEditorState(trackId)
  
  // ã‚°ãƒ­ãƒ¼ãƒãƒ«BPMã‚’çŠ¶æ…‹ã«åæ˜ 
  useEffect(() => {
    console.log('ğŸµ Global tempo useEffect triggered:', {
      globalTempo,
      stateTempo: state.tempo
    })
    if (globalTempo !== state.tempo) {
      console.log('ğŸµ Updating tempo from', state.tempo, 'to', globalTempo)
      state.setTempo(globalTempo)
    }
  }, [globalTempo, state.tempo]) // ğŸ”§ ä¿®æ­£: stateå…¨ä½“ã§ã¯ãªãstate.tempoã®ã¿ä¾å­˜
  
  // ãƒˆãƒ©ãƒƒã‚¯åˆ¥ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–ç”¨Ref
  const trackDataRef = useRef({})
  const lastSavedRef = useRef({})
  const lastParentUpdateRef = useRef({}) // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¸ã®æœ€å¾Œã®æ›´æ–°æ™‚åˆ»ã‚’è¨˜éŒ²
  
  // åˆæœŸåŒ–æ™‚ã«å†ç”Ÿãƒ˜ãƒƒãƒ‰ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã€å¼·åˆ¶çš„ã«å†æç”»
  useEffect(() => {
    console.log('ğŸµ Redraw useEffect triggered')
    state.setNeedsRedraw(true)
  }, []) // ğŸ”§ ä¿®æ­£: åˆæœŸåŒ–æ™‚ã®ã¿å®Ÿè¡Œã€stateã‚’ä¾å­˜é–¢ä¿‚ã‹ã‚‰å‰Šé™¤
  
  // æ°¸ç¶šåŒ–ãƒ•ãƒƒã‚¯ã®ä½¿ç”¨
  const persistence = useMidiPersistence()
  
  // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ãƒƒã‚¯ã®ä½¿ç”¨ - trackTypeã«åŸºã¥ã„ã¦é©åˆ‡ãªéŸ³æºã‚’é¸æŠ
  const pianoAudio = useMidiAudio()
  const bassAudioHook = useBassAudio()

  // trackTypeã«åŸºã¥ã„ã¦éŸ³æºã‚’é¸æŠ
  const audio = useMemo(() => {
    if (trackType === 'bass') {
      return {
        // åŸºæœ¬å†ç”Ÿãƒ¡ã‚½ãƒƒãƒ‰
        playNote: (midiNote, velocity = 0.8, duration = 0.25) => {
          return bassAudioHook.playBassNote(midiNote, Math.round(velocity * 127))
        },
        playScheduledNote: async (midiNote, startTime, duration, velocity = 100) => {
          // BasséŸ³æºã¯å³åº§ã«å†ç”Ÿï¼ˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°æœªå¯¾å¿œï¼‰
          return bassAudioHook.playBassNote(midiNote, velocity)
        },
        noteOn: (midiNote, velocity = 0.8, duration = 2.0) => {
          return bassAudioHook.playBassNote(midiNote, Math.round(velocity * 127))
        },
        noteOff: (midiNote) => {
          bassAudioHook.stopBassNote(midiNote)
        },
        stopAllNotes: () => {
          bassAudioHook.stopAllBassNotes()
        },
        stopAllSounds: () => {
          bassAudioHook.stopAllBassNotes()
        },

        // åˆæœŸåŒ–ãƒ»åˆ¶å¾¡ãƒ¡ã‚½ãƒƒãƒ‰
        initializeAudio: async () => {
          // BasséŸ³æºã¯åˆæœŸåŒ–ä¸è¦ï¼ˆuseBassAudioã§è‡ªå‹•åˆæœŸåŒ–ï¼‰
          return bassAudioHook.isLoaded
        },
        stopAudio: () => {
          bassAudioHook.stopAllBassNotes()
        },
        cleanup: () => {
          bassAudioHook.stopAllBassNotes()
        },

        // éŸ³é‡ãƒ»è¨­å®šãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰
        setInstrument: (instrument) => {
          // BasséŸ³æºã§ã¯æ¥½å™¨å¤‰æ›´ã¯ä¸è¦
        },
        setVolume: (volume) => {
          bassAudioHook.setBassVolume(volume)
        },
        setMasterVolume: (volume) => {
          // ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¯çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†
        },
        setMetronomeVolume: (volume) => {
          // BasséŸ³æºã§ã¯ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ ä¸è¦
        },
        setExternalVolumeInfo: (trackVolume, trackMuted, masterVolume) => {
          if (trackMuted) {
            bassAudioHook.setBassVolume(0)
          } else {
            bassAudioHook.setBassVolume(trackVolume / 100)
          }
        },

        // ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ æ©Ÿèƒ½ï¼ˆãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰
        playMetronomeClick: () => {
          // BasséŸ³æºã§ã¯ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ ä¸è¦
        },
        startMetronome: (bpm) => {
          // BasséŸ³æºã§ã¯ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ ä¸è¦
        },
        stopMetronome: () => {
          // BasséŸ³æºã§ã¯ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ ä¸è¦
        },

        // çŠ¶æ…‹å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰
        getAudioState: () => {
          return {
            initialized: bassAudioHook.isLoaded,
            playing: false,
            volume: bassAudioHook.bassSettings?.volume || 0.8
          }
        },
        getCurrentTime: () => {
          return 0 // BasséŸ³æºã§ã¯æ™‚é–“ç®¡ç†ä¸è¦
        },
        isAudioContextAvailable: () => {
          return bassAudioHook.isLoaded
        },

        // å†…éƒ¨å‚ç…§ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
        isInitializedRef: { current: bassAudioHook.isLoaded },
        trackIdRef: { current: trackId }
      }
    } else {
      // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ”ã‚¢ãƒéŸ³æº
      return pianoAudio
    }
  }, [trackType, pianoAudio, bassAudioHook, trackId])
  
  // ãƒãƒ¼ãƒˆæ“ä½œãƒ•ãƒƒã‚¯ã®ä½¿ç”¨
  const noteOperations = useMidiNoteOperations(state.notes, state.setNotes, trackId, state.isInitialized, persistence, state.currentTime, state.selectedNotes, state.setSelectedNotes)
  
  // Ghost Textãƒ•ãƒƒã‚¯ã®ä½¿ç”¨
  const ghostText = useGhostText(trackId, appSettings)
  
  // éŸ³è‰²è¨­å®šãƒ•ãƒƒã‚¯ã®ä½¿ç”¨
  const instrumentSettings = useInstrumentSettings(trackId)

  // éŸ³æ¥½ç†è«–è¨­å®šå¤‰æ›´ãƒãƒ³ãƒ‰ãƒ©ï¼ˆApp.jsxã‹ã‚‰æ¸¡ã•ã‚ŒãŸé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
  const handleMusicTheorySettingsChange = useCallback((setting, value) => {
    console.log('ğŸ¼ Music Theory Setting Changed:', setting, value)
    if (onMusicTheorySettingsChange) {
      onMusicTheorySettingsChange(setting, value)
    }
  }, [onMusicTheorySettingsChange])

  // éŸ³æ¥½ç†è«–è¨­å®šã®åŒæœŸç¢ºèª
  useEffect(() => {
    console.log('ğŸ¼ EnhancedMidiEditor: Music Theory Settings Updated:', musicTheorySettings)
  }, [musicTheorySettings])

  // å…ƒã®MIDIãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
  const [originalMidiData, setOriginalMidiData] = useState(null)
  
  // å‰Šé™¤å‡¦ç†ã®é‡è¤‡å®Ÿè¡Œã‚’é˜²ããŸã‚ã®ãƒ•ãƒ©ã‚°
  const isDeletingRef = useRef(false)
  
  // å†ç”ŸçŠ¶æ…‹ã®ç®¡ç†ç”¨Refï¼ˆçŠ¶æ…‹ã®ä¸æ•´åˆã‚’é˜²ããŸã‚ï¼‰
  const isPlayingRef = useRef(false)
  
  // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãƒ”ã‚¢ãƒæ©Ÿèƒ½ç”¨ã®çŠ¶æ…‹
  const [activeKeys, setActiveKeys] = useState(new Set())
  const [manualOctaveOffset, setManualOctaveOffset] = useState(0) // æ‰‹å‹•ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–èª¿æ•´å€¤
  const [liveRecordingNotes, setLiveRecordingNotes] = useState(new Map()) // ãƒ©ã‚¤ãƒ–éŒ²éŸ³ä¸­ã®ãƒãƒ¼ãƒˆ
  
  // ç¾åœ¨ã®ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’å‚ç…§ã™ã‚‹ãŸã‚ã®Ref
  const currentNotesRef = useRef([])
  
  // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ç”¨ã®éŸ³ã®ç®¡ç†
  const keyboardAudioRef = useRef(new Map()) // keyCode -> { noteId, startTime }
  

  // ãƒ©ã‚¤ãƒ–éŒ²éŸ³ä¸­ã®ãƒãƒ¼ãƒˆã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
  useEffect(() => {
    if (!state.isPlaying || liveRecordingNotes.size === 0) return

    console.log(`ğŸ¹ Starting live recording update for ${liveRecordingNotes.size} notes`)

    const updateInterval = setInterval(() => {
      const currentTime = state.currentTime
      let hasUpdates = false
      
      // ç¾åœ¨ã®ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’å–å¾—
      const currentNotes = currentNotesRef.current
      
      // ãƒ©ã‚¤ãƒ–éŒ²éŸ³ä¸­ã®ãƒãƒ¼ãƒˆã®é•·ã•ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ›´æ–°
      const updatedNotes = currentNotes.map(note => {
        const recordingData = Array.from(liveRecordingNotes.values()).find(data => data.noteId === note.id)
        if (recordingData) {
          const newDuration = currentTime - recordingData.startTime
          if (newDuration > note.duration) {
            hasUpdates = true
            console.log(`ğŸ¹ Updating live note duration: ${note.id} (pitch: ${note.pitch}) -> ${newDuration.toFixed(2)}s`)
            return {
              ...note,
              duration: Math.max(0.1, newDuration)
            }
          }
        }
        return note
      })
      
      if (hasUpdates) {
        state.setNotes(updatedNotes)
        currentNotesRef.current = updatedNotes
        state.setNeedsRedraw(true) // å†æç”»ã‚’è¦æ±‚
      }
    }, 16) // 16msé–“éš”ã§æ›´æ–°ï¼ˆ60fpsï¼‰

    return () => {
      clearInterval(updateInterval)
      console.log('ğŸ¹ Stopped live recording update')
    }
  }, [state.isPlaying, state.currentTime, liveRecordingNotes])

  // ã‚·ãƒ³ãƒ—ãƒ«ãªã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ï¼ˆé‡è¤‡è¨­å®šã‚’é˜²ãï¼‰
  const keyboardListenersSetupRef = useRef(false)
  useEffect(() => {
    console.log('ğŸ¹ Keyboard useEffect triggered with dependencies:', {
      stateAudioEnabled: state.audioEnabled,
      audio: !!audio,
      manualOctaveOffset,
      onNoteAdd: !!onNoteAdd,
      onNoteEdit: !!onNoteEdit,
      trackId,
      keyboardListenersSetupRef: keyboardListenersSetupRef.current
    })
    
    if (keyboardListenersSetupRef.current) {
      console.log('ğŸ¹ Keyboard listeners already set up, skipping')
      return // æ—¢ã«è¨­å®šæ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    }
    console.log('ğŸ¹ Setting up simple keyboard listeners')
    keyboardListenersSetupRef.current = true
    
    const handleKeyDown = (event) => {
      console.log(`ğŸ¹ KeyDown: ${event.code}`)

      // Tab ã‚­ãƒ¼å°‚ç”¨ãƒ‡ãƒãƒƒã‚°
      if (event.code === 'Tab') {
        console.warn('ğŸš¨ğŸš¨ğŸš¨ TAB DEBUG: Tab key pressed in EnhancedMidiEditor ğŸš¨ğŸš¨ğŸš¨')
        console.warn('ğŸš¨ğŸš¨ğŸš¨ TAB DEBUG: isActive =', isActive, 'ğŸš¨ğŸš¨ğŸš¨')
      }

      // MIDIã‚¨ãƒ‡ã‚£ã‚¿ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ãªã„å ´åˆã¯å‡¦ç†ã—ãªã„
      if (!isActive) {
        console.log('ğŸ¹ MIDIã‚¨ãƒ‡ã‚£ã‚¿ãŒéã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã®ãŸã‚ã€ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã‚’ç„¡è¦–');
        if (event.code === 'Tab') {
          console.warn('ğŸš¨ğŸš¨ğŸš¨ TAB DEBUG: Early return - MIDI editor not active, Tab should work normally ğŸš¨ğŸš¨ğŸš¨')
        }
        return;
      }
      
      // Q/Rã‚­ãƒ¼ã§ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–èª¿æ•´
      if (event.code === 'KeyQ') {
        event.preventDefault(); // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å‹•ä½œã‚’é˜²ã
        setManualOctaveOffset(prev => Math.max(-2, prev - 1))
        return
      }
      if (event.code === 'KeyR') {
        event.preventDefault(); // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å‹•ä½œã‚’é˜²ã
        setManualOctaveOffset(prev => Math.min(2, prev + 1))
        return
      }
      
      // ã‚­ãƒ¼ãƒªãƒ”ãƒ¼ãƒˆã¯ç„¡è¦–
      if (event.repeat) return
      
      // æ—¢ã«æŠ¼ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ã¯ç„¡è¦–
      if (activeKeys.has(event.code)) return
      
      // MIDIãƒãƒ¼ãƒˆã«å¯¾å¿œã™ã‚‹ã‚­ãƒ¼ã®å ´åˆã®ã¿å‡¦ç†
      const octave = calculateOptimalOctave(
        state.scrollY, 
        state.currentTime, 
        [0, 9], 
        120, 
        20, 
        manualOctaveOffset
      )
      
      const midiNote = getMidiNoteFromKeyCode(event.code, octave)
      if (event.code === 'Tab') {
        console.warn('ğŸš¨ğŸš¨ğŸš¨ TAB DEBUG: getMidiNoteFromKeyCode result =', midiNote, 'ğŸš¨ğŸš¨ğŸš¨')
      }

      if (midiNote === null) {
        console.log(`ğŸ¹ ã‚­ãƒ¼ ${event.code} ã¯MIDIãƒãƒ¼ãƒˆã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“`);
        if (event.code === 'Tab') {
          console.warn('ğŸš¨ğŸš¨ğŸš¨ TAB DEBUG: Tab key not mapped to MIDI note - should exit early WITHOUT preventDefault ğŸš¨ğŸš¨ğŸš¨')
        }
        return;
      }

      // Tab ã‚­ãƒ¼ã¯ã“ã“ã¾ã§åˆ°é”ã—ãªã„ã¯ãš
      if (event.code === 'Tab') {
        console.error('ğŸš¨ğŸš¨ğŸš¨ TAB DEBUG: ERROR - Tab key reached preventDefault section! This should NOT happen! ğŸš¨ğŸš¨ğŸš¨')
      }

      // ã‚¤ãƒ™ãƒ³ãƒˆã®ä¼æ’­ã‚’åœæ­¢ï¼ˆä»–ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã¨ã®ç«¶åˆã‚’é˜²ãï¼‰
      event.preventDefault();
      event.stopPropagation();
      
      console.log(`ğŸ¹ Playing note: ${midiNote}`)
      
      // ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚­ãƒ¼ã«è¿½åŠ 
      setActiveKeys(prev => new Set([...prev, event.code]))
      
      // éŸ³ã‚’å†ç”Ÿï¼ˆå†ç”Ÿä¸­ã§ã‚‚å¸¸ã«éŸ³ã‚’é³´ã‚‰ã™ï¼‰
      if (state.audioEnabled && audio) {
        console.log(`ğŸ¹ Attempting to play note ${midiNote} with audio enabled: ${state.audioEnabled}`)
        
        // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã®éŸ³ã‚’è¨˜éŒ²
        keyboardAudioRef.current.set(event.code, {
          noteId: midiNote,
          startTime: Date.now()
        })
        
        // éŸ³ã‚’å†ç”Ÿï¼ˆuseMidiAudioã‚’ä½¿ç”¨ï¼‰
        const result = audio.playNote(midiNote, 0.8, 0.25); // useMidiAudioã‚’ä½¿ç”¨
        console.log(`ğŸ¹ NoteOn result for ${midiNote}:`, result)
        
        // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã®éŸ³ã‚’è¨˜éŒ²ï¼ˆnoteOffã§ç¢ºå®Ÿã«åœæ­¢ã™ã‚‹ãŸã‚ï¼‰
        if (result) {
          keyboardAudioRef.current.set(event.code, {
            noteId: midiNote,
            startTime: Date.now(),
            audioResult: result,
            isKeyboardInput: true // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã§ã‚ã‚‹ã“ã¨ã‚’ãƒãƒ¼ã‚¯
          })
        }
      } else {
        console.log(`ğŸ¹ Audio not enabled or audio not available. audioEnabled: ${state.audioEnabled}, audio: ${!!audio}`)
      }
      
      // å†ç”Ÿä¸­ã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰æŒ¿å…¥æ©Ÿèƒ½
      if (state.isPlaying) {
        const currentTime = state.currentTime
        const noteId = `live-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`
        
        // æ–°ã—ã„ãƒãƒ¼ãƒˆã‚’ä½œæˆ
        const newNote = {
          id: noteId,
          pitch: midiNote,
          time: currentTime,
          duration: 0.1, // æœ€åˆã¯å°ã•ãªé•·ã•ã‹ã‚‰é–‹å§‹
          velocity: 0.7
        }
        
        console.log(`ğŸ¹ Adding live note: ${noteId} at time ${currentTime}`)
        
        // ãƒãƒ¼ãƒˆã‚’è¿½åŠ 
        state.setNotes(prev => {
          const newNotes = [...prev, newNote]
          currentNotesRef.current = newNotes
          return newNotes
        })
        
        // ãƒ©ã‚¤ãƒ–éŒ²éŸ³ä¸­ã®ãƒãƒ¼ãƒˆã¨ã—ã¦è¨˜éŒ²
        setLiveRecordingNotes(prev => new Map(prev).set(event.code, {
          noteId: noteId,
          startTime: currentTime,
          keyCode: event.code
        }))
        
        // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«é€šçŸ¥
        if (onNoteAdd) {
          onNoteAdd(newNote, trackId)
        }
      }
      
      // è¦–è¦šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆè¤‡æ•°ã‚­ãƒ¼å¯¾å¿œï¼‰
      state.setPressedKey(prev => {
        if (prev === null) return midiNote
        if (Array.isArray(prev)) {
          return [...prev, midiNote]
        }
        return [prev, midiNote]
      })
      state.setNeedsRedraw(true)
    }
    
    const handleKeyUp = (event) => {
      console.log(`ğŸ¹ KeyUp: ${event.code}`)
      
      // MIDIã‚¨ãƒ‡ã‚£ã‚¿ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ãªã„å ´åˆã¯å‡¦ç†ã—ãªã„
      if (!isActive) {
        console.log('ğŸ¹ MIDIã‚¨ãƒ‡ã‚£ã‚¿ãŒéã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã®ãŸã‚ã€ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã‚’ç„¡è¦–');
        return;
      }
      
      // ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚­ãƒ¼ã‹ã‚‰å‰Šé™¤
      setActiveKeys(prev => {
        const newSet = new Set(prev)
        newSet.delete(event.code)
        return newSet
      })
      
      // MIDIãƒãƒ¼ãƒˆã«å¯¾å¿œã™ã‚‹ã‚­ãƒ¼ã®å ´åˆã®ã¿å‡¦ç†
      const octave = calculateOptimalOctave(
        state.scrollY, 
        state.currentTime, 
        [0, 9], 
        120, 
        20, 
        manualOctaveOffset
      )
      
      const midiNote = getMidiNoteFromKeyCode(event.code, octave)
      if (midiNote !== null) {
        // ã‚¤ãƒ™ãƒ³ãƒˆã®ä¼æ’­ã‚’åœæ­¢ï¼ˆä»–ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã¨ã®ç«¶åˆã‚’é˜²ãï¼‰
        event.preventDefault();
        event.stopPropagation();
        
        console.log(`ğŸ¹ Stopping note: ${midiNote}`)
        
        // éŸ³ã‚’åœæ­¢ï¼ˆçµ±ä¸€ã•ã‚ŒãŸéŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ã¯è‡ªå‹•çš„ã«ç®¡ç†ã•ã‚Œã‚‹ï¼‰
        if (state.audioEnabled && audio) {
          // useMidiAudioã®noteOffã‚’ä½¿ç”¨
          audio.noteOff(midiNote);
          // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã®éŸ³ã‚’è¨˜éŒ²ã‹ã‚‰å‰Šé™¤
          keyboardAudioRef.current.delete(event.code)
        }
        
        // å†ç”Ÿä¸­ã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰æŒ¿å…¥ã®çµ‚äº†å‡¦ç†
        const recordingData = liveRecordingNotes.get(event.code)
        if (recordingData && state.isPlaying) {
          const currentTime = state.currentTime
          const duration = Math.max(0.1, currentTime - recordingData.startTime)
          
          console.log(`ğŸ¹ Finalizing live note: ${recordingData.noteId} with duration ${duration}`)
          
          // ãƒãƒ¼ãƒˆã®é•·ã•ã‚’æ›´æ–°
          state.setNotes(prev => {
            const updatedNotes = prev.map(note => 
              note.id === recordingData.noteId 
                ? { ...note, duration: duration }
                : note
            )
            currentNotesRef.current = updatedNotes
            return updatedNotes
          })
          
          // ãƒ©ã‚¤ãƒ–éŒ²éŸ³ä¸­ã®ãƒãƒ¼ãƒˆã‹ã‚‰å‰Šé™¤
          setLiveRecordingNotes(prev => {
            const newMap = new Map(prev)
            newMap.delete(event.code)
            return newMap
          })
          
          // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«é€šçŸ¥
          if (onNoteEdit) {
            const updatedNote = state.notes.find(note => note.id === recordingData.noteId)
            if (updatedNote) {
              onNoteEdit(updatedNote, trackId)
            }
          }
        }
        
        // è¦–è¦šçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚¯ãƒªã‚¢ï¼ˆè¤‡æ•°ã‚­ãƒ¼å¯¾å¿œï¼‰
        state.setPressedKey(prev => {
          if (prev === null) return null
          if (Array.isArray(prev)) {
            const newPressedKeys = prev.filter(key => key !== midiNote)
            return newPressedKeys.length > 0 ? newPressedKeys : null
          }
          return prev === midiNote ? null : prev
        })
        state.setNeedsRedraw(true)
      }
    }
    
    document.addEventListener('keydown', handleKeyDown)
    document.addEventListener('keyup', handleKeyUp)
    
    return () => {
      console.log('ğŸ¹ Keyboard useEffect cleanup triggered')
      document.removeEventListener('keydown', handleKeyDown)
      document.removeEventListener('keyup', handleKeyUp)
      console.log('ğŸ¹ Keyboard listeners removed')
      keyboardListenersSetupRef.current = false
    }
  }, [state.audioEnabled, audio, manualOctaveOffset, onNoteAdd, onNoteEdit, trackId])

  // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªåˆæœŸåŒ–
  useEffect(() => {
    console.log('ğŸµ Audio initialization useEffect triggered:', {
      stateAudioEnabled: state.audioEnabled,
      audio: !!audio
    })
    if (state.audioEnabled) {
      console.log('ğŸµ Initializing audio...')
      audio.initializeAudio().then(result => {
        console.log('ğŸµ Audio initialization result:', result)
      })
    }
  }, [state.audioEnabled, audio])

  // éŸ³è‰²å¤‰æ›´æ™‚ã®å‡¦ç†ï¼ˆå®‰å®šã—ãŸé–¢æ•°ã‚’ä½¿ç”¨ï¼‰
  const lastInstrumentChangeRef = useRef({ instrument: null, settings: null })
  const handleInstrumentChange = useCallback(() => {
    // é‡è¤‡å®Ÿè¡Œã‚’é˜²ã
    const currentInstrument = instrumentSettings.instrument
    const currentSettings = JSON.stringify(instrumentSettings.settings)
    
    if (lastInstrumentChangeRef.current.instrument === currentInstrument && 
        lastInstrumentChangeRef.current.settings === currentSettings) {
      console.log('ğŸµ Instrument change skipped - no changes detected')
      return
    }
    
    console.log('ğŸµ Instrument change handler triggered:', {
      stateAudioEnabled: state.audioEnabled,
      audio: !!audio,
      instrumentSettings: !!instrumentSettings.settings,
      settingsKeys: instrumentSettings.settings ? Object.keys(instrumentSettings.settings).length : 0,
      stateIsPlaying: state.isPlaying,
      notesLength: state.notes.length
    })
    
    // å¤‰æ›´ã‚’è¨˜éŒ²
    lastInstrumentChangeRef.current = {
      instrument: currentInstrument,
      settings: currentSettings
    }
    
    if (state.audioEnabled && audio.isAudioContextAvailable() && instrumentSettings.settings && Object.keys(instrumentSettings.settings).length > 0) {
      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¨ãƒ³ã‚¸ãƒ³ã«éŸ³è‰²ã‚’è¨­å®š
      audio.setInstrument(instrumentSettings.instrument)
      
      // éŸ³é‡ã¨ãƒ‘ãƒ³ã‚’è¨­å®šï¼ˆå®‰å…¨ãªå€¤å¤‰æ›ï¼‰
      const volume = instrumentSettings.settings.volume
      if (typeof volume === 'number' && isFinite(volume)) {
        const normalizedVolume = Math.max(0, Math.min(1, volume / 100))
        audio.setVolume(normalizedVolume)
      } else {
        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®šï¼ˆè­¦å‘Šã¯é–‹ç™ºç’°å¢ƒã§ã®ã¿è¡¨ç¤ºï¼‰
        if (process.env.NODE_ENV === 'development') {
          console.warn('Invalid volume setting:', volume, 'using default volume')
        }
        audio.setVolume(0.7)
      }
      
      // ç¾åœ¨å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã‚’æ–°ã—ã„éŸ³è‰²ã§å†ç”Ÿæˆï¼ˆå†ç”Ÿä¸­ã®å ´åˆï¼‰
      if (state.isPlaying) {
        console.log('ğŸµ Stopping all notes due to instrument change')
        // éŸ³è‰²å¤‰æ›´æ™‚ã®ã¿å…¨éŸ³åœæ­¢ã‚’å®Ÿè¡Œï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’é˜²ããŸã‚ï¼‰
        const wasPlaying = state.isPlaying
        const currentPlaybackNotes = new Set(state.playbackNotes) // ç¾åœ¨ã®å†ç”Ÿä¸­ãƒãƒ¼ãƒˆã‚’ä¿å­˜
        
        audio.stopAllNotes()
        
        // å†ç”Ÿä¸­ã®å ´åˆã®ã¿ãƒãƒ¼ãƒˆã‚’å†ç”Ÿæˆ
        if (wasPlaying) {
          const currentNotes = currentNotesRef.current || state.notes
          currentNotes.forEach(note => {
            if (note.time <= state.currentTime && note.time + note.duration > state.currentTime) {
              // éŸ³é‡ã¯useMidiAudioãƒ•ãƒƒã‚¯å†…ã§å€‹åˆ¥ãƒˆãƒ©ãƒƒã‚¯éŸ³é‡ Ã— ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¨ã—ã¦å‡¦ç†ã•ã‚Œã‚‹
              audio.playScheduledNote(note.pitch, note.time, note.duration, note.velocity)
              
              // å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã¨ã—ã¦å†ç™»éŒ²
              currentPlaybackNotes.add(note.id)
            }
          })
          
          // å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’å¾©å…ƒ
          state.setPlaybackNotes(currentPlaybackNotes)
        }
      }
    }
  }, [state.audioEnabled, audio, instrumentSettings.instrument, instrumentSettings.settings, state.isPlaying, state.currentTime, state.notes])

  // éŸ³è‰²å¤‰æ›´æ™‚ã®å‡¦ç†
  useEffect(() => {
    handleInstrumentChange()
  }, [handleInstrumentChange])

  // Mixerã®éŸ³é‡æƒ…å ±ã‚’éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã«åæ˜ ï¼ˆé‡è¤‡å®Ÿè¡Œã‚’é˜²ãï¼‰
  const lastVolumeUpdateRef = useRef({ trackVolume, trackMuted, masterVolume })
  useEffect(() => {
    // éŸ³é‡æƒ…å ±ãŒå®Ÿéš›ã«å¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿å‡¦ç†
    if (lastVolumeUpdateRef.current.trackVolume === trackVolume && 
        lastVolumeUpdateRef.current.trackMuted === trackMuted && 
        lastVolumeUpdateRef.current.masterVolume === masterVolume) {
      return
    }
    
    console.log('ğŸµ Enhanced Midi Editor: Volume effect triggered:', {
      stateAudioEnabled: state.audioEnabled,
      hasAudio: !!audio,
      hasSetExternalVolumeInfo: !!(audio && audio.setExternalVolumeInfo),
      trackVolume,
      trackMuted,
      masterVolume
    })
    
    if (state.audioEnabled && audio && audio.setExternalVolumeInfo) {
      // å¤–éƒ¨éŸ³é‡æƒ…å ±ã‚’è¨­å®šï¼ˆå€‹åˆ¥ãƒˆãƒ©ãƒƒã‚¯éŸ³é‡ã€ãƒŸãƒ¥ãƒ¼ãƒˆçŠ¶æ…‹ã€ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼‰
      audio.setExternalVolumeInfo(trackVolume, trackMuted, masterVolume)
      
      console.log('ğŸµ Enhanced Midi Editor: External volume info set:', {
        trackVolume,
        trackMuted,
        masterVolume
      })
      
      // æ›´æ–°ã•ã‚ŒãŸéŸ³é‡æƒ…å ±ã‚’è¨˜éŒ²
      lastVolumeUpdateRef.current = { trackVolume, trackMuted, masterVolume }
    } else {
      console.warn('ğŸµ Enhanced Midi Editor: Cannot update volume info:', {
        stateAudioEnabled: state.audioEnabled,
        hasAudio: !!audio,
        hasSetExternalVolumeInfo: !!(audio && audio.setExternalVolumeInfo)
      })
    }
  }, [trackVolume, trackMuted, masterVolume, state.audioEnabled, audio])

  // ç¾åœ¨ã®ãƒˆãƒ©ãƒƒã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
  const saveCurrentTrackData = useCallback(() => {
    if (!trackId) return
    
    // ç¾åœ¨ã®ãƒãƒ¼ãƒˆã‚’å–å¾—
    const currentNotes = currentNotesRef.current || state.notes
    
    // Refã«ä¿å­˜
    trackDataRef.current[trackId] = [...currentNotes]
    lastSavedRef.current[trackId] = Date.now()
    
    // æ°¸ç¶šåŒ–ãƒ•ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ä¿å­˜
    persistence.saveNotes(currentNotes, trackId)
    

  }, [trackId, persistence])

  // åˆæœŸåŒ–å‡¦ç†
  useEffect(() => {
    console.log('ğŸµ Initialization useEffect triggered:', {
      stateIsInitialized: state.isInitialized,
      trackId,
      isActive,
      midiDataNotes: midiData?.notes?.length || 0
    })
    
    // åˆæœŸåŒ–æ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if (state.isInitialized || !trackId || !isActive) {
      console.log('ğŸµ Skipping initialization - already initialized or not active')
      return
    }
    
    // æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®ãƒˆãƒ©ãƒƒã‚¯ã®å ´åˆã§ã‚‚ã€midiDataãŒæ›´æ–°ã•ã‚ŒãŸå ´åˆã¯å†åˆæœŸåŒ–
    if (trackDataRef.current[trackId] !== undefined) {
      console.log('ğŸµ Track data already exists for trackId:', trackId)
      // midiDataãŒæ›´æ–°ã•ã‚ŒãŸå ´åˆã¯å†åˆæœŸåŒ–
      if (midiData?.notes && JSON.stringify(midiData.notes) !== JSON.stringify(trackDataRef.current[trackId])) {
        console.log('ğŸµ MIDI data changed, resetting initialization flag')
        // åˆæœŸåŒ–ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦å†åˆæœŸåŒ–ã‚’è¨±å¯
        state.setIsInitialized(false)
        return
      } else {
        console.log('ğŸµ MIDI data unchanged, setting initialized flag')
        state.setIsInitialized(true)
        return
      }
    }
    
    // åˆæœŸåŒ–ãƒ•ãƒ©ã‚°ã‚’è¨­å®šã—ã¦ä»–ã®useEffectã®å®Ÿè¡Œã‚’é˜²ã
    console.log('ğŸµ Setting initialization flag to true')
    state.setIsInitialized(true)
    

    
    let initialNotes = []
    
    // 1. ã¾ãšMIDIãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆæœŸåŒ–ï¼ˆè¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çŠ¶æ…‹ã‚’å„ªå…ˆï¼‰
    if (midiData?.notes) {
      // MIDIãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã€ç©ºã®é…åˆ—ã§ã‚‚ä½¿ç”¨ï¼ˆå…¨å‰Šé™¤å¾Œã®çŠ¶æ…‹ã‚’ä¿æŒï¼‰
      initialNotes = [...midiData.notes]

      setOriginalMidiData(midiData)
    }
    // 2. MIDIãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯æ°¸ç¶šåŒ–ãƒ•ãƒƒã‚¯ã‹ã‚‰èª­ã¿è¾¼ã¿
    else {
      const savedNotes = persistence.loadNotes(trackId)
      if (savedNotes.length > 0) {
        initialNotes = savedNotes

      }
      // 3. ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šã‚µãƒ³ãƒ—ãƒ«ãƒãƒ¼ãƒˆã‚’è¿½åŠ ï¼ˆé–‹ç™ºæ™‚ã®ã¿ã€ã‹ã¤åˆå›åˆæœŸåŒ–æ™‚ã®ã¿ï¼‰
      else if (process.env.NODE_ENV === 'development' && !trackDataRef.current[trackId]) {
        // ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ¼ãƒˆã‚’è¿½åŠ ã—ã¦è¡¨ç¤ºã‚’ãƒ†ã‚¹ãƒˆï¼ˆé–‹ç™ºç’°å¢ƒã§ã®ã¿ã€ã‹ã¤åˆå›ã®ã¿ï¼‰
        initialNotes = [
          { id: 'sample-1', pitch: 60, time: 0, duration: 0.5, velocity: 0.8 }, // C4
          { id: 'sample-2', pitch: 62, time: 0.5, duration: 0.5, velocity: 0.8 }, // D4
          { id: 'sample-3', pitch: 64, time: 1, duration: 0.5, velocity: 0.8 }, // E4
          { id: 'sample-4', pitch: 65, time: 1.5, duration: 0.5, velocity: 0.8 }, // F4
          { id: 'sample-5', pitch: 67, time: 2, duration: 1, velocity: 0.8 }, // G4
          { id: 'sample-6', pitch: 69, time: 3, duration: 0.25, velocity: 0.8 }, // A4
          { id: 'sample-7', pitch: 71, time: 3.25, duration: 0.25, velocity: 0.8 }, // B4
          { id: 'sample-8', pitch: 72, time: 3.5, duration: 0.5, velocity: 0.8 }, // C5
        ]

      }
    }
    
    // çŠ¶æ…‹ã‚’è¨­å®š
    console.log('ğŸµ Setting notes:', initialNotes.length)
    state.setNotes(initialNotes)
    currentNotesRef.current = initialNotes
    
    // Refã«ä¿å­˜
    trackDataRef.current[trackId] = [...initialNotes]
    lastSavedRef.current[trackId] = Date.now()
    
    // å±¥æ­´ã‚’åˆæœŸåŒ–
    persistence.initializeHistory()
    console.log('ğŸµ Initialization completed for trackId:', trackId)
    

  }, [trackId, midiData, isActive]) // state.isInitializedã¨persistenceã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤

  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
  useEffect(() => {
    console.log('ğŸµ Cleanup useEffect triggered for trackId:', trackId)
    return () => {
      console.log('ğŸµ Component cleanup - resetting initialization state')
      // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆã•ã‚ŒãŸæ™‚ã«åˆæœŸåŒ–çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      if (trackId) {

        // trackDataRefã‹ã‚‰ã¯å‰Šé™¤ã—ãªã„ï¼ˆä»–ã®ã‚¿ãƒ–ã§ä½¿ç”¨ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
        // åˆæœŸåŒ–çŠ¶æ…‹ã®ã¿ãƒªã‚»ãƒƒãƒˆ
        state.setIsInitialized(false)
      }
    }
  }, [trackId])

  // å‰å›ã®ãƒˆãƒ©ãƒƒã‚¯IDã‚’è¨˜éŒ²ã™ã‚‹Ref
  const previousTrackIdRef = useRef(null)

  // ãƒˆãƒ©ãƒƒã‚¯å¤‰æ›´æ™‚ã®å‡¦ç†
  useEffect(() => {
    console.log('ğŸµ Track change useEffect triggered:', {
      stateIsInitialized: state.isInitialized,
      trackId,
      isActive,
      previousTrackId: previousTrackIdRef.current
    })
    
    if (!state.isInitialized || !trackId || !isActive) {
      console.log('ğŸµ Skipping track change - not initialized or not active')
      return
    }
    
    // å‰å›ã®ãƒˆãƒ©ãƒƒã‚¯IDã¨æ¯”è¼ƒã—ã¦ã€å®Ÿéš›ã«ãƒˆãƒ©ãƒƒã‚¯ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿å‡¦ç†
    const previousTrackId = previousTrackIdRef.current
    if (previousTrackId === trackId) {
      console.log('ğŸµ Same track ID, skipping track change')
      return // åŒã˜ãƒˆãƒ©ãƒƒã‚¯ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
    }
    

    
    // å‰å›ã®ãƒˆãƒ©ãƒƒã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    if (previousTrackId) {
      console.log('ğŸµ Saving data for previous track:', previousTrackId)
      saveCurrentTrackData()
    }
    
    // ç¾åœ¨ã®ãƒˆãƒ©ãƒƒã‚¯IDã‚’è¨˜éŒ²
    previousTrackIdRef.current = trackId
    console.log('ğŸµ Track change completed, new trackId:', trackId)
  }, [trackId, isActive, saveCurrentTrackData]) // ğŸ”§ ä¿®æ­£: state.isInitializedã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤

  // ãƒãƒ¼ãƒˆå¤‰æ›´æ™‚ã®è‡ªå‹•ä¿å­˜
  useEffect(() => {
    console.log('ğŸµ Auto save useEffect triggered:', {
      stateIsInitialized: state.isInitialized,
      trackId,
      lastSaved: lastSavedRef.current[trackId] || 0
    })
    
    if (!state.isInitialized || !trackId) {
      console.log('ğŸµ Skipping auto save - not initialized or no trackId')
      return
    }
    
    // å‰å›ã®ä¿å­˜ã‹ã‚‰ä¸€å®šæ™‚é–“çµŒéã—ã¦ã„ã‚‹å ´åˆã®ã¿ä¿å­˜
    const lastSaved = lastSavedRef.current[trackId] || 0
    const now = Date.now()
    if (now - lastSaved > 1000) { // 1ç§’ä»¥ä¸ŠçµŒéã—ã¦ã„ã‚‹å ´åˆ
      console.log('ğŸµ Auto saving track data')
      saveCurrentTrackData()
    } else {
      console.log('ğŸµ Auto save skipped - too soon since last save')
    }
  }, [trackId, saveCurrentTrackData]) // ğŸ”§ ä¿®æ­£: state.isInitializedã¨state.notesã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤

  // midiDataã®å¤‰æ›´ã‚’ç›£è¦–ã—ã¦çŠ¶æ…‹ã‚’æ›´æ–°
  useEffect(() => {
    console.log('ğŸµ MIDI data sync useEffect triggered:', {
      trackId,
      isActive,
      stateIsInitialized: state.isInitialized,
      midiDataNotes: midiData?.notes?.length || 0,
      currentNotesLength: state.notes.length
    })
    
    if (!trackId || !isActive || !state.isInitialized) {
      console.log('ğŸµ Skipping MIDI data sync - not ready')
      return
    }
    
    // midiDataãŒæ›´æ–°ã•ã‚ŒãŸå ´åˆã€çŠ¶æ…‹ã‚’åŒæœŸ
    const currentNotes = currentNotesRef.current || state.notes
    if (midiData?.notes && JSON.stringify(midiData.notes) !== JSON.stringify(currentNotes)) {
      console.log('ğŸµ MIDI data changed, syncing notes')
      const newNotes = [...midiData.notes]
      state.setNotes(newNotes)
      currentNotesRef.current = newNotes
      trackDataRef.current[trackId] = newNotes
      setOriginalMidiData(midiData)
      
      // å¼·åˆ¶çš„ã«å†æç”»
      state.setNeedsRedraw(true)
    } else {
      console.log('ğŸµ MIDI data unchanged, no sync needed')
    }
  }, [midiData, trackId, isActive, trackName, state.setNotes, state.setNeedsRedraw]) // ğŸ”§ ä¿®æ­£: state.isInitializedã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤

  // AIãŒè¿½åŠ ã—ãŸãƒãƒ¼ãƒˆã®æ›´æ–°ã‚’ç›£è¦–
  useEffect(() => {
    const handleMidiDataUpdated = (event) => {
      const { trackId: updatedTrackId, noteId, type } = event.detail
      
      // ç¾åœ¨ã®ãƒˆãƒ©ãƒƒã‚¯ã®æ›´æ–°ã®å ´åˆã®ã¿å‡¦ç†
      if (updatedTrackId === trackId && isActive && state.isInitialized) {
        console.log('EnhancedMidiEditor: MIDI data updated by AI:', { trackId, noteId, type })
        
        // ç¾åœ¨ã®MIDIãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ã—ã¦çŠ¶æ…‹ã‚’æ›´æ–°
        const currentMidiData = midiData || { notes: [] }
        console.log('EnhancedMidiEditor: Current MIDI data:', currentMidiData)
        
        // AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ‰¿èªå¾…ã¡ãƒãƒ¼ãƒˆã‚‚å«ã‚ã¦è¡¨ç¤º
        let allNotes = [...currentMidiData.notes]
        
        // ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰æ‰¿èªå¾…ã¡ãƒãƒ¼ãƒˆã‚’å–å¾—
        if (window.aiAgentEngine && window.aiAgentEngine.getPendingChanges) {
          const pendingChanges = window.aiAgentEngine.getPendingChanges()
          const pendingNotes = pendingChanges.notes
            .filter(([noteId, change]) => change.trackId === trackId && change.type === 'add')
            .map(([noteId, change]) => change.newNote)
          
          if (pendingNotes.length > 0) {
            console.log('EnhancedMidiEditor: Found pending notes:', pendingNotes.length)
            allNotes = [...allNotes, ...pendingNotes]
          }
        }
        
        state.setNotes(allNotes)
        currentNotesRef.current = allNotes
        trackDataRef.current[trackId] = allNotes
        
        // å¼·åˆ¶çš„ã«å†æç”»
        state.setNeedsRedraw(true)
        console.log('EnhancedMidiEditor: State updated with new notes:', allNotes.length)
        console.log('EnhancedMidiEditor: Notes details:', allNotes.slice(0, 3)) // æœ€åˆã®3ã¤ã®ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
      }
    }

    const handleMidiDataRejected = (event) => {
      const { sessionId, trackCount, noteCount, trackId: rejectedTrackId, noteIds, remainingNotes } = event.detail
      
      // ç¾åœ¨ã®ãƒˆãƒ©ãƒƒã‚¯ã®æ‹’å¦ã®å ´åˆã®ã¿å‡¦ç†
      if (isActive && state.isInitialized && rejectedTrackId === trackId) {
        console.log('EnhancedMidiEditor: MIDI data rejected by AI:', { trackId, sessionId, noteCount, noteIds })
        
        // æ‹’å¦å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’è¨­å®šï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’é˜²ãï¼‰
        if (window.aiAgentEngine) {
          window.aiAgentEngine.isRejectingChanges = true
        }
        
        // ç¾åœ¨ã®MIDIãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ã—ã¦çŠ¶æ…‹ã‚’æ›´æ–°
        const currentMidiData = midiData || { notes: [] }
        console.log('EnhancedMidiEditor: Current MIDI data after rejection:', currentMidiData)
        
        // æ‰¿èªå¾…ã¡ãƒãƒ¼ãƒˆã‚’é™¤å¤–ã—ã¦è¡¨ç¤ºï¼ˆisPendingãƒ•ãƒ©ã‚°ã‚‚å«ã‚ã¦ï¼‰
        const filteredNotes = currentMidiData.notes.filter(note => {
          const isPendingNote = note.isPending || (noteIds && noteIds.includes(note.id))
          return !isPendingNote
        })
        
        console.log('EnhancedMidiEditor: Filtered out pending notes - before:', currentMidiData.notes.length, 'after:', filteredNotes.length)
        
        // çŠ¶æ…‹ã‚’æ›´æ–°
        state.setNotes(filteredNotes)
        currentNotesRef.current = filteredNotes
        trackDataRef.current[trackId] = filteredNotes
        
        // å¼·åˆ¶çš„ã«å†æç”»
        state.setNeedsRedraw(true)
        console.log('EnhancedMidiEditor: State updated after rejection with notes:', filteredNotes.length)
        
        // æ‹’å¦å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢ï¼ˆå°‘ã—é…å»¶ã•ã›ã¦ç¢ºå®Ÿã«å‡¦ç†ã‚’å®Œäº†ï¼‰
        setTimeout(() => {
          if (window.aiAgentEngine) {
            window.aiAgentEngine.isRejectingChanges = false
            console.log('EnhancedMidiEditor: Rejection processing flag cleared')
            
            // è¿½åŠ ã®å¼·åˆ¶æ›´æ–°
            state.setNeedsRedraw(true)
            console.log('EnhancedMidiEditor: Additional redraw triggered')
          }
        }, 100)
      }
    }

    const handleMidiDataApproved = (event) => {
      const { trackId: approvedTrackId, noteIds, approvedNotes } = event.detail
      
      // ç¾åœ¨ã®ãƒˆãƒ©ãƒƒã‚¯ã®æ‰¿èªã®å ´åˆã®ã¿å‡¦ç†
      if (isActive && state.isInitialized && approvedTrackId === trackId) {
        console.log('EnhancedMidiEditor: MIDI data approved by AI:', { trackId, noteIds, approvedNotes })
        
        // ç¾åœ¨ã®MIDIãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ã—ã¦çŠ¶æ…‹ã‚’æ›´æ–°
        const currentMidiData = midiData || { notes: [] }
        console.log('EnhancedMidiEditor: Current MIDI data after approval:', currentMidiData)
        
        // æ‰¿èªã•ã‚ŒãŸãƒãƒ¼ãƒˆã®isPendingãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢
        const updatedNotes = currentMidiData.notes.map(note => {
          if (noteIds && noteIds.includes(note.id)) {
            return { ...note, isPending: false }
          }
          return note
        })
        
        console.log('EnhancedMidiEditor: Updated notes after approval - before:', currentMidiData.notes.length, 'after:', updatedNotes.length)
        
        // çŠ¶æ…‹ã‚’æ›´æ–°
        state.setNotes(updatedNotes)
        currentNotesRef.current = updatedNotes
        trackDataRef.current[trackId] = updatedNotes
        
        // å¼·åˆ¶çš„ã«å†æç”»
        state.setNeedsRedraw(true)
        console.log('EnhancedMidiEditor: State updated after approval with notes:', updatedNotes.length)
      }
    }

    window.addEventListener('midiDataUpdated', handleMidiDataUpdated)
    window.addEventListener('midiDataRejected', handleMidiDataRejected)
    window.addEventListener('midiDataApproved', handleMidiDataApproved)
    
    return () => {
      window.removeEventListener('midiDataUpdated', handleMidiDataUpdated)
      window.removeEventListener('midiDataRejected', handleMidiDataRejected)
      window.removeEventListener('midiDataApproved', handleMidiDataApproved)
    }
  }, [trackId, isActive, midiData, state.setNotes, state.setNeedsRedraw]) // ğŸ”§ ä¿®æ­£: state.isInitializedã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤

  // ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã‚’è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«é€šçŸ¥
  useEffect(() => {
    if (!onMidiDataUpdate || !trackId || !state.isInitialized) return
    
    // è¤‡æ•°ãƒãƒ¼ãƒˆãƒ‰ãƒ©ãƒƒã‚°ä¸­ã¯å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆfinalizeMultiNoteDragã§å‡¦ç†æ¸ˆã¿ï¼‰
    if (state.isDraggingMultipleNotes) {
      
      return
    }
    

    
    // æœ€å¾Œã®æ›´æ–°æ™‚åˆ»ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦é‡è¤‡ã‚’é˜²ã
    const now = Date.now()
    const lastUpdateTime = lastParentUpdateRef.current[trackId] || 0
    if (now - lastUpdateTime < 50) { // 50msä»¥å†…ã®é‡è¤‡æ›´æ–°ã‚’é˜²ãï¼ˆçŸ­ç¸®ï¼‰
      
      return
    }
    

    
    // æ›´æ–°æ™‚åˆ»ã‚’è¨˜éŒ²
    lastParentUpdateRef.current[trackId] = now
    
    const updateData = {
      notes: Array.isArray(state.notes) ? state.notes : [],
      trackId: trackId,
      lastModified: new Date().toISOString(),
      metadata: {
        modified: new Date().toISOString(),
        noteCount: state.notes.length
      },
      settings: {
        channel: 0,
        octave: 0,
        transpose: 0,
        velocity: 100
      }
    }
    
    onMidiDataUpdate(updateData)
  }, [trackId, onMidiDataUpdate, state.isDraggingMultipleNotes]) // ğŸ”§ ä¿®æ­£: state.notesã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰



  // é¸æŠã•ã‚ŒãŸãƒãƒ¼ãƒˆã‚’ã‚«ãƒƒãƒˆï¼ˆdeleteSelectedNotesã®å®šç¾©å¾Œã«é…ç½®ï¼‰
  const cutSelectedNotes = useCallback((selectedNoteIds = null) => {
    const effectiveSelectedNotes = selectedNoteIds || Array.from(state.selectedNotes)
    if (effectiveSelectedNotes.length === 0) return
    
    // ã¾ãšã‚³ãƒ”ãƒ¼
    noteOperations.copySelectedNotes(effectiveSelectedNotes)
    
    // æ¬¡ã«å‰Šé™¤
    noteOperations.deleteSelectedNotes(effectiveSelectedNotes)
  }, [state.selectedNotes, noteOperations])

  // Refs
  const staticCanvasRef = useRef(null)
  const dynamicCanvasRef = useRef(null)
  const timelineCanvasRef = useRef(null)
  const containerRef = useRef(null)
  const animationFrameRef = useRef(null)
  const lastGhostPredictionsRef = useRef([])
  const longPressTimerRef = useRef(null)
  
  // å†ç”Ÿé–¢é€£ã®Refs
  const playbackRef = useRef(null)
  const metronomeRef = useRef(null)
  const scheduledNotesRef = useRef(new Map())
  const playbackStartTimeRef = useRef(0)
  
  // å†ç”Ÿä¸­ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã‚’ç®¡ç†ã™ã‚‹Ref
  const activeAudioNodesRef = useRef(new Map()) // noteId -> { oscillator, gainNode, filter }

  // å®šæ•°
  const GRID_HEIGHT = 20
  const GRID_WIDTH = 40
  const PIANO_WIDTH = 80
  const HEADER_HEIGHT = 40
  const NOTE_HEIGHT = 18
  const OCTAVE_RANGE = [1, 6] // C1 to C7
  const TOTAL_KEYS = (OCTAVE_RANGE[1] - OCTAVE_RANGE[0] + 1) * 12
  const FPS_LIMIT = 60
  const FRAME_TIME = 1000 / FPS_LIMIT
  const LONG_PRESS_THRESHOLD = 200
  
  // å†ç”Ÿé–¢é€£ã®å®šæ•°
  const PLAYBACK_UPDATE_INTERVAL = 16 // ms (60fps)
  
  // éŸ³ã®é•·ã•åˆ†é¡ã®å®šæ•°
  const NOTE_DURATION_THRESHOLDS = {
    SHORT: 0.5,    // 0.5ç§’ä»¥ä¸‹ = çŸ­ã„éŸ³
    MEDIUM: 2.0,   // 0.5ç§’ã€œ2ç§’ = ä¸­ç¨‹åº¦ã®éŸ³
    LONG: 2.0      // 2ç§’ä»¥ä¸Š = é•·ã„éŸ³
  }
  
  // çŸ­ã„éŸ³ã®å†ç”Ÿçµ‚äº†è¨­å®š
  const SHORT_NOTE_AUTO_STOP = true // çŸ­ã„éŸ³ã¯è‡ªå‹•çš„ã«çµ‚äº†ã™ã‚‹ã‹ã©ã†ã‹
  
  // éŸ³ã®é•·ã•åˆ†é¡ã®è¨­å®šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒèª¿æ•´å¯èƒ½ï¼‰
  const [noteDurationSettings, setNoteDurationSettings] = useState({
    shortThreshold: NOTE_DURATION_THRESHOLDS.SHORT,
    mediumThreshold: NOTE_DURATION_THRESHOLDS.MEDIUM,
    autoStopShortNotes: SHORT_NOTE_AUTO_STOP
  })

  // éŸ³ã®é•·ã•ã‚’åˆ†é¡ã™ã‚‹é–¢æ•°
  const classifyNoteDuration = useCallback((duration) => {
    if (duration <= noteDurationSettings.shortThreshold) {
      return 'SHORT'
    } else if (duration <= noteDurationSettings.mediumThreshold) {
      return 'MEDIUM'
    } else {
      return 'LONG'
    }
  }, [noteDurationSettings.shortThreshold, noteDurationSettings.mediumThreshold])
  
  // çŸ­ã„éŸ³ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
  const isShortNote = useCallback((duration) => {
    return duration <= noteDurationSettings.shortThreshold
  }, [noteDurationSettings.shortThreshold])
  
  // åº§æ¨™å¤‰æ›é–¢æ•°ï¼ˆãƒ¡ãƒ¢åŒ–ãƒ»ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾å¿œãƒ»ä¸‹é™è¨­å®šï¼‰
  const coordinateTransforms = useMemo(() => {
    // ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¸‹é™ã®è¨ˆç®—ï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã®ä¸‹å´ã«ä½™è£•ã‚’æŒãŸã›ã‚‹ï¼‰
    const maxScrollY = Math.max(0, (TOTAL_KEYS * GRID_HEIGHT) - 400) // 400pxã®è¡¨ç¤ºé ˜åŸŸã‚’ç¢ºä¿
    
    return {
      pitchToY: (pitch) => {
        // ãƒ”ãƒƒãƒã‚’æ­£ã—ã„Yåº§æ¨™ã«å¤‰æ›ï¼ˆç°¡ç•¥åŒ–ç‰ˆï¼‰
        const keyIndex = TOTAL_KEYS - 1 - (pitch - (OCTAVE_RANGE[0] * 12))
        const y = HEADER_HEIGHT + keyIndex * GRID_HEIGHT - state.scrollY
        return y
      },
      yToPitch: (y) => {
        // Yåº§æ¨™ã‚’ãƒ”ãƒƒãƒã«å¤‰æ›
        const keyIndex = Math.floor((y - HEADER_HEIGHT + state.scrollY) / GRID_HEIGHT)
        return (OCTAVE_RANGE[0] * 12) + (TOTAL_KEYS - 1 - keyIndex)
      },
      timeToX: (time) => {
        // æ™‚é–“ã‚’æ­£ã—ã„Xåº§æ¨™ã«å¤‰æ›ï¼ˆç°¡ç•¥åŒ–ç‰ˆï¼‰
        const x = PIANO_WIDTH + (time * GRID_WIDTH * state.zoom) - state.scrollX
        return x
      },
      xToTime: (x) => {
        // Xåº§æ¨™ã‚’æ™‚é–“ã«å¤‰æ›ï¼ˆã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã¨ã‚ºãƒ¼ãƒ ã‚’è€ƒæ…®ï¼‰
        return (x - PIANO_WIDTH + state.scrollX) / (GRID_WIDTH * state.zoom)
      },
      maxScrollY: maxScrollY
    }
  }, [state.zoom, state.scrollX, state.scrollY, TOTAL_KEYS, GRID_HEIGHT, GRID_WIDTH, PIANO_WIDTH, HEADER_HEIGHT, OCTAVE_RANGE])

  // Ghost Text Engineã®åˆæœŸåŒ–ã¯å°‚ç”¨ãƒ•ãƒƒã‚¯ã§å‡¦ç†

  // å†ç”Ÿæ©Ÿèƒ½ã®å®Ÿè£…
  const startPlayback = useCallback(async () => {
    console.log('ğŸµ EnhancedMidiEditor: Starting playback')
    console.log(`ğŸµ å†ç”Ÿé–‹å§‹æ™‚ã®éŸ³é‡è¨­å®š: trackVolume=${trackVolume}, trackMuted=${trackMuted}, masterVolume=${masterVolume}`);
    
    // æ—¢ã«å†ç”Ÿä¸­ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„ï¼ˆRefã§çŠ¶æ…‹ã‚’ç›´æ¥ç¢ºèªï¼‰
    if (isPlayingRef.current) {
      console.log('ğŸµ Already playing, skipping')
      return
    }
    
    // å†ç”Ÿé–‹å§‹å‰ã«ç¾åœ¨é³´ã£ã¦ã„ã‚‹éŸ³ã‚’ä¸€æ–‰ã«åœæ­¢
    if (window.unifiedAudioSystem) {
      console.log('ğŸµ å†ç”Ÿé–‹å§‹å‰ã«å…¨éŸ³ã‚’åœæ­¢ã—ã¾ã™')
      window.unifiedAudioSystem.stopAllSounds()
    }
    
    // AudioContextã®åˆæœŸåŒ–ã‚’ç¢ºå®Ÿã«è¡Œã†
    const audioInitialized = await audio.initializeAudio()
    if (!audioInitialized) {
      console.error('Failed to initialize audio context')
      return
    }
    
    if (state.notes.length === 0) {
      console.log('ğŸµ No notes to play')
      return
    }
    
    // å†ç”ŸçŠ¶æ…‹ã‚’å…ˆã«è¨­å®šï¼ˆRefã¨stateã®ä¸¡æ–¹ã‚’æ›´æ–°ï¼‰
    isPlayingRef.current = true
    state.setIsPlaying(true)
    
    // ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚¯ãƒªãƒƒã‚¯ä½ç½®ãŒã‚ã‚‹å ´åˆã¯ãã“ã‹ã‚‰å†ç”Ÿã€ãªã‘ã‚Œã°ç¾åœ¨ä½ç½®ã‹ã‚‰å†ç”Ÿ
    const startTime = state.timelineClickPosition !== null ? state.timelineClickPosition : state.currentTime
    state.setCurrentTime(startTime)
    
    // å†ç”Ÿé–‹å§‹æ™‚åˆ»ã‚’è¨ˆç®—ï¼ˆæŒ‡å®šä½ç½®ã‹ã‚‰å†ç”Ÿã™ã‚‹ãŸã‚ã€é–‹å§‹æ™‚åˆ»ã‚’éå»ã«è¨­å®šï¼‰
    const playbackStartTime = audio.getCurrentTime() - startTime
    
    state.setPlaybackStartTime(playbackStartTime)
    playbackStartTimeRef.current = playbackStartTime
    
    // å†ç”Ÿãƒ˜ãƒƒãƒ‰ã‚’å³åº§ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã€å¼·åˆ¶çš„ã«å†æç”»
    state.setNeedsRedraw(true)
    
    // ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚ŒãŸãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢
    scheduledNotesRef.current.clear()
    state.setPlaybackNotes(new Set())
    
    // å†ç”Ÿä¸­ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã‚‚ã‚¯ãƒªã‚¢ï¼ˆé‡è¤‡é˜²æ­¢ã®ãŸã‚ï¼‰
    activeAudioNodesRef.current.clear()
    
    console.log('ğŸµ Playback started:', {
      startTime,
      playbackStartTime,
      notesCount: state.notes.length,
      currentTime: audio.getCurrentTime()
    })
    
    // ãƒãƒ¼ãƒˆã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
    state.notes.forEach(note => {
      // ãƒãƒ¼ãƒˆã®æ™‚é–“ã¯ç§’å˜ä½ãªã®ã§ã€ãã®ã¾ã¾ä½¿ç”¨
      // é–‹å§‹æ™‚åˆ»ã‹ã‚‰ã®ç›¸å¯¾æ™‚é–“ã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
      const noteStartTime = playbackStartTimeRef.current + note.time
      const noteEndTime = noteStartTime + note.duration
      const delay = Math.max(0, (noteStartTime - audio.getCurrentTime()) * 1000)
      

      
      // ãƒãƒ¼ãƒˆé–‹å§‹ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
      const startTimeout = setTimeout(async () => {
        if (!isPlayingRef.current) return
        
        // æ—¢ã«å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡é˜²æ­¢ï¼‰
        if (activeAudioNodesRef.current.has(note.id)) {
          console.log(`ğŸµ ãƒãƒ¼ãƒˆ ${note.id} ã¯æ—¢ã«å†ç”Ÿä¸­ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—`);
          return;
        }
        
        // éŸ³ã®é•·ã•ã‚’åˆ†é¡
        const noteDurationType = classifyNoteDuration(note.duration)
        const isShort = isShortNote(note.duration)
        
        console.log(`ğŸµ ãƒãƒ¼ãƒˆåˆ†é¡: ${note.pitch} (${noteDurationType}) - é•·ã•: ${note.duration}ç§’, çŸ­ã„éŸ³: ${isShort}`)
        
        // éŸ³é‡ã¯useMidiAudioãƒ•ãƒƒã‚¯å†…ã§å€‹åˆ¥ãƒˆãƒ©ãƒƒã‚¯éŸ³é‡ Ã— ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¨ã—ã¦å‡¦ç†ã•ã‚Œã‚‹
        console.log(`ğŸµ åˆæœŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆ: ${note.pitch} (éŸ³é‡è¨­å®šåæ˜ ) - trackVolume=${trackVolume}, trackMuted=${trackMuted}, masterVolume=${masterVolume}`);
        
        // éåŒæœŸã§éŸ³ã‚’å†ç”Ÿï¼ˆãƒ‡ãƒãƒƒã‚°ã§æˆåŠŸã—ãŸæ–¹æ³•ã‚’æ¡ç”¨ï¼‰
        try {
          const result = await audio.playScheduledNote(note.pitch, noteStartTime, note.duration, note.velocity)
          if (result) {
            // å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã¨ã—ã¦è¨˜éŒ²ï¼ˆå³åº§ã«åæ˜ ï¼‰
            state.setPlaybackNotes(prev => {
              const newSet = new Set(prev)
              newSet.add(note.id)
              return newSet
            })
            
            // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰è¿”ã•ã‚Œã‚‹éŸ³ã®æƒ…å ±ã‚’ä¿å­˜
            const audioNodeInfo = {
              oscillator: result.oscillator || null,
              gainNode: result.gainNode || null,
              filter: result.filter || null,
              endTime: result.endTime || (noteStartTime + note.duration),
              isUnifiedSystem: true, // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ãƒãƒ¼ã‚¯
              durationType: noteDurationType, // éŸ³ã®é•·ã•åˆ†é¡ã‚’ä¿å­˜
              isShort: isShort, // çŸ­ã„éŸ³ã‹ã©ã†ã‹ã‚’ä¿å­˜
              soundId: result.soundId || null, // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã®éŸ³ID
              type: result.type || 'piano' // éŸ³ã®ã‚¿ã‚¤ãƒ—
            }
            
            activeAudioNodesRef.current.set(note.id, audioNodeInfo)
            
            console.log(`ğŸµ ãƒãƒ¼ãƒˆ ${note.id} ã‚’å†ç”Ÿä¸­ãƒãƒ¼ãƒˆã¨ã—ã¦ç™»éŒ²ã—ã¾ã—ãŸ (${noteDurationType}, éŸ³ID: ${result.soundId || 'N/A'})`)
          }
        } catch (error) {
          console.error(`âŒ ãƒãƒ¼ãƒˆ ${note.id} ã®å†ç”Ÿã«å¤±æ•—:`, error)
        }
      }, delay)
      
      // ãƒãƒ¼ãƒˆçµ‚äº†ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
      const endDelay = Math.max(0, (noteEndTime - audio.getCurrentTime()) * 1000)
      const endTimeout = setTimeout(() => {
        if (!isPlayingRef.current) return
        
        // çŸ­ã„éŸ³ã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†
        const audioNodeInfo = activeAudioNodesRef.current.get(note.id)
        if (audioNodeInfo && audioNodeInfo.isShort && noteDurationSettings.autoStopShortNotes) {
          console.log(`ğŸµ çŸ­ã„éŸ³ ${note.id} (${note.pitch}) ã®å†ç”Ÿã‚’è‡ªå‹•çµ‚äº†ã—ã¾ã™`)
          
          // çŸ­ã„éŸ³ã®å ´åˆã¯å³åº§ã«åœæ­¢
          if (audioNodeInfo.isUnifiedSystem) {
            // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯éŸ³IDã‚’ä½¿ç”¨ã—ã¦åœæ­¢
            if (audioNodeInfo.soundId && window.unifiedAudioSystem) {
              try {
                window.unifiedAudioSystem.stopSound(audioNodeInfo.soundId)
                console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹çŸ­ã„éŸ³ ${note.id} (éŸ³ID: ${audioNodeInfo.soundId}) ã‚’åœæ­¢ã—ã¾ã—ãŸ`)
              } catch (error) {
                console.error(`âŒ çŸ­ã„éŸ³ ${note.id} ã®åœæ­¢ã«å¤±æ•—:`, error)
              }
            } else {
              console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹çŸ­ã„éŸ³ ${note.id} ã¯è‡ªå‹•çš„ã«åœæ­¢ã•ã‚Œã¾ã™`)
            }
          } else {
            // å¾“æ¥ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã®å ´åˆã¯æ‰‹å‹•ã§åœæ­¢
            if (audioNodeInfo.oscillator) {
              audioNodeInfo.oscillator.stop()
            }
            if (audioNodeInfo.gainNode) {
              audioNodeInfo.gainNode.gain.cancelScheduledValues(0)
              audioNodeInfo.gainNode.gain.setValueAtTime(audioNodeInfo.gainNode.gain.value, 0)
              audioNodeInfo.gainNode.gain.linearRampToValueAtTime(0, 0.05) // çŸ­ã„éŸ³ã¯ç´ æ—©ããƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
            }
          }
        }
        
        state.setPlaybackNotes(prev => {
          const newSet = new Set(prev)
          newSet.delete(note.id)
          return newSet
        })
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        activeAudioNodesRef.current.delete(note.id)
      }, endDelay)
      
      scheduledNotesRef.current.set(note.id, { startTimeout, endTimeout })
    })
    
    // ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
    if (state.metronomeEnabled) {
      const beatsPerSecond = state.tempo / 60
      const secondsPerBeat = 1 / beatsPerSecond
      const totalBeats = Math.ceil(state.playbackDuration * beatsPerSecond)
      
      console.log('ğŸµ Scheduling metronome:', {
        beatsPerSecond,
        secondsPerBeat,
        totalBeats,
        playbackDuration: state.playbackDuration
      })
      
      for (let beat = 0; beat < totalBeats; beat++) {
        const metronomeTime = playbackStartTimeRef.current + (beat * secondsPerBeat)
        const metronomeDelay = Math.max(0, (metronomeTime - audio.getCurrentTime()) * 1000)
        setTimeout(async () => {
          if (isPlayingRef.current) {
            await audio.playMetronomeClick(false, metronomeTime)
          }
        }, metronomeDelay)
      }
    }
    
  }, [state.notes, state.tempo, state.metronomeEnabled, state.playbackDuration, state.audioEnabled, state.timelineClickPosition, state.currentTime, audio, trackVolume, trackMuted, masterVolume])

  const stopPlayback = useCallback(() => {
    console.log('ğŸµ EnhancedMidiEditor: Stopping playback')
    isPlayingRef.current = false
    state.setIsPlaying(false)
    state.setCurrentTime(0)
    
    // å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ï¼ˆå³åº§ã«åæ˜ ï¼‰
    const currentPlaybackNotes = new Set()
    state.setPlaybackNotes(currentPlaybackNotes)
    console.log('ğŸµ å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ')
    
    // ãƒ©ã‚¤ãƒ–éŒ²éŸ³ä¸­ã®ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢
    setLiveRecordingNotes(new Map())
    
    // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã®éŸ³ã‚’ã‚¯ãƒªã‚¢
    keyboardAudioRef.current.clear()
    
    // ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚ŒãŸã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    scheduledNotesRef.current.forEach(({ startTimeout, endTimeout }) => {
      clearTimeout(startTimeout)
      clearTimeout(endTimeout)
    })
    scheduledNotesRef.current.clear()
    
    // å†ç”Ÿä¸­ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã‚’åœæ­¢
    activeAudioNodesRef.current.forEach((audioNodes, noteId) => {
      if (audioNodes.isUnifiedSystem) {
        // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒ‰ã¯éŸ³IDã‚’ä½¿ç”¨ã—ã¦åœæ­¢
        if (audioNodes.soundId && window.unifiedAudioSystem) {
          try {
            window.unifiedAudioSystem.stopSound(audioNodes.soundId)
            console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒˆ ${noteId} (éŸ³ID: ${audioNodes.soundId}) ã‚’åœæ­¢ã—ã¾ã—ãŸ`);
          } catch (error) {
            console.error(`âŒ ãƒãƒ¼ãƒˆ ${noteId} ã®åœæ­¢ã«å¤±æ•—:`, error);
          }
        } else {
          console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒˆ ${noteId} ã¯è‡ªå‹•çš„ã«åœæ­¢ã•ã‚Œã¾ã™`);
        }
      } else {
        // å¾“æ¥ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã®å ´åˆã¯æ‰‹å‹•ã§åœæ­¢
        if (audioNodes.oscillator) {
          audioNodes.oscillator.stop()
        }
        if (audioNodes.gainNode) {
          audioNodes.gainNode.gain.cancelScheduledValues(0)
          audioNodes.gainNode.gain.setValueAtTime(audioNodes.gainNode.gain.value, 0)
          audioNodes.gainNode.gain.linearRampToValueAtTime(0, 0.1)
        }
      }
    })
    activeAudioNodesRef.current.clear()
    
    // å†ç”Ÿãƒ˜ãƒƒãƒ‰ã‚’å³åº§ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã€å¼·åˆ¶çš„ã«å†æç”»
    state.setNeedsRedraw(true)
    
    console.log('ğŸµ EnhancedMidiEditor: Playback stopped successfully')
  }, [])

  const pausePlayback = useCallback(() => {
    console.log('â¸ï¸ EnhancedMidiEditor: Pausing playback')
    isPlayingRef.current = false
    state.setIsPlaying(false)
    
    // å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ï¼ˆä¸€æ™‚åœæ­¢æ™‚ã‚‚ã‚¯ãƒªã‚¢ï¼‰
    const currentPlaybackNotes = new Set()
    state.setPlaybackNotes(currentPlaybackNotes)
    console.log('ğŸµ ä¸€æ™‚åœæ­¢æ™‚ã«å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ')
    
    // ãƒ©ã‚¤ãƒ–éŒ²éŸ³ä¸­ã®ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢
    setLiveRecordingNotes(new Map())
    
    // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã®éŸ³ã‚’ã‚¯ãƒªã‚¢
    keyboardAudioRef.current.clear()
    
    // ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚ŒãŸã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
    scheduledNotesRef.current.forEach(({ startTimeout, endTimeout }) => {
      clearTimeout(startTimeout)
      clearTimeout(endTimeout)
    })
    scheduledNotesRef.current.clear()
    
    // å†ç”Ÿä¸­ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã‚’åœæ­¢
    activeAudioNodesRef.current.forEach((audioNodes, noteId) => {
      if (audioNodes.isUnifiedSystem) {
        // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒ‰ã¯éŸ³IDã‚’ä½¿ç”¨ã—ã¦åœæ­¢
        if (audioNodes.soundId && window.unifiedAudioSystem) {
          try {
            window.unifiedAudioSystem.stopSound(audioNodes.soundId)
            console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒˆ ${noteId} (éŸ³ID: ${audioNodes.soundId}) ã‚’åœæ­¢ã—ã¾ã—ãŸ`);
          } catch (error) {
            console.error(`âŒ ãƒãƒ¼ãƒˆ ${noteId} ã®åœæ­¢ã«å¤±æ•—:`, error);
          }
        } else {
          console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒˆ ${noteId} ã¯è‡ªå‹•çš„ã«åœæ­¢ã•ã‚Œã¾ã™`);
        }
      } else {
        // å¾“æ¥ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã®å ´åˆã¯æ‰‹å‹•ã§åœæ­¢
        if (audioNodes.oscillator) {
          audioNodes.oscillator.stop()
        }
        if (audioNodes.gainNode) {
          audioNodes.gainNode.gain.cancelScheduledValues(0)
          audioNodes.gainNode.gain.setValueAtTime(audioNodes.gainNode.gain.value, 0)
          audioNodes.gainNode.gain.linearRampToValueAtTime(0, 0.1)
        }
      }
    })
    activeAudioNodesRef.current.clear()
    
    // å†ç”Ÿãƒ˜ãƒƒãƒ‰ã‚’å³åº§ã«è¡¨ç¤ºã™ã‚‹ãŸã‚ã€å¼·åˆ¶çš„ã«å†æç”»
    state.setNeedsRedraw(true)
    
    console.log('â¸ï¸ EnhancedMidiEditor: Playback paused successfully')
  }, [])

  // ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ç”¨ã®å†ç”Ÿ/åœæ­¢åˆ‡ã‚Šæ›¿ãˆé–¢æ•°
  const handlePlayPause = useCallback(() => {
    console.log('ğŸµ EnhancedMidiEditor handlePlayPause called:', {
      trackId,
      isPlayingRef: isPlayingRef.current,
      isPlaying: state.isPlaying,
      audioEnabled: state.audioEnabled
    })
    
    if (isPlayingRef.current) {
      console.log('â¸ï¸ Space key pressed while playing, pausing')
      pausePlayback()
    } else {
      console.log('â–¶ï¸ Space key pressed while paused, playing')
      startPlayback()
    }
  }, [startPlayback, pausePlayback, trackId, state.isPlaying, state.audioEnabled])

  // ã‚°ãƒ­ãƒ¼ãƒãƒ«é–¢æ•°ã¨ã—ã¦å…¬é–‹ï¼ˆApp.jsxã‹ã‚‰å‘¼ã³å‡ºã—å¯èƒ½ï¼‰
  useEffect(() => {

    if (!window.midiEditorPlayPause) {
      window.midiEditorPlayPause = {}
    }
    window.midiEditorPlayPause[trackId] = handlePlayPause
    return () => {
  
      if (window.midiEditorPlayPause && window.midiEditorPlayPause[trackId]) {
        delete window.midiEditorPlayPause[trackId]
      }
    }
  }, [handlePlayPause, trackId])

  // å†ç”Ÿãƒ˜ãƒƒãƒ‰ã®æ›´æ–°ï¼ˆæ”¹å–„ç‰ˆï¼‰
  useEffect(() => {
    if (!state.isPlaying) {
      // å†ç”Ÿåœæ­¢æ™‚ã¯å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢
      state.setPlaybackNotes(new Set())
      // ãƒ©ã‚¤ãƒ–éŒ²éŸ³ä¸­ã®ãƒãƒ¼ãƒˆã‚‚ã‚¯ãƒªã‚¢
      setLiveRecordingNotes(new Map())
      // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã®éŸ³ã‚‚ã‚¯ãƒªã‚¢
      keyboardAudioRef.current.clear()
      return
    }
    
    console.log('ğŸµ Starting playback head update')
    
    const updatePlaybackHead = async () => {
      if (!isPlayingRef.current) {
        return
      }
      
      try {
        const currentAudioTime = audio.getCurrentTime()
        const elapsedTime = currentAudioTime - playbackStartTimeRef.current
        
        // å†ç”Ÿãƒãƒ¼ã¯ç§’å˜ä½ã§å‹•ãï¼ˆãƒãƒ¼ãƒˆã®æ™‚é–“å˜ä½ã¨åˆã‚ã›ã‚‹ï¼‰
        const newTime = Math.max(0, elapsedTime)
        

        
        state.setCurrentTime(newTime)
        
        // å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã‚’æ›´æ–°
        const currentPlaybackNotes = new Set()
        
        // æ—¢å­˜ã®ãƒãƒ¼ãƒˆã¨æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸãƒãƒ¼ãƒˆã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
        const currentNotes = currentNotesRef.current || state.notes
        for (const note of currentNotes) {
          const noteStartTime = note.time
          const noteEndTime = note.time + note.duration
          
          // ãƒãƒ¼ãƒˆãŒå†ç”Ÿæ™‚é–“ç¯„å›²å†…ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
          if (newTime >= noteStartTime && newTime <= noteEndTime) {
            currentPlaybackNotes.add(note.id)
            
            // æ–°ã—ãå†ç”Ÿã‚’é–‹å§‹ã™ã‚‹ãƒãƒ¼ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå†ç”Ÿé–‹å§‹ã®ç¬é–“ï¼‰
            if (newTime >= noteStartTime && newTime < noteStartTime + 0.016) { // 16msä»¥å†…
              // ã¾ã ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãƒãƒ¼ãƒˆã®å ´åˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
              if (!scheduledNotesRef.current.has(note.id) && !activeAudioNodesRef.current.has(note.id)) {
                console.log('ğŸµ Real-time scheduling note:', note.id)
                
                const noteStartTime = playbackStartTimeRef.current + note.time
                const noteEndTime = noteStartTime + note.duration
                
                // ãƒãƒ¼ãƒˆé–‹å§‹ã‚’å³åº§ã«å®Ÿè¡Œ
                // éŸ³ã®é•·ã•ã‚’åˆ†é¡
                const noteDurationType = classifyNoteDuration(note.duration)
                const isShort = isShortNote(note.duration)
                
                console.log(`ğŸµ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ¼ãƒˆåˆ†é¡: ${note.pitch} (${noteDurationType}) - é•·ã•: ${note.duration}ç§’, çŸ­ã„éŸ³: ${isShort}`)
                
                // éŸ³é‡ã¯useMidiAudioãƒ•ãƒƒã‚¯å†…ã§å€‹åˆ¥ãƒˆãƒ©ãƒƒã‚¯éŸ³é‡ Ã— ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¨ã—ã¦å‡¦ç†ã•ã‚Œã‚‹
                console.log(`ğŸµ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆ: ${note.pitch} (éŸ³é‡è¨­å®šåæ˜ ) - trackVolume=${trackVolume}, trackMuted=${trackMuted}, masterVolume=${masterVolume}`);
                
                // éåŒæœŸã§éŸ³ã‚’å†ç”Ÿï¼ˆãƒ‡ãƒãƒƒã‚°ã§æˆåŠŸã—ãŸæ–¹æ³•ã‚’æ¡ç”¨ï¼‰
                try {
                  const result = await audio.playScheduledNote(note.pitch, noteStartTime, note.duration, note.velocity)
                  if (result) {
                    // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰è¿”ã•ã‚Œã‚‹éŸ³ã®æƒ…å ±ã‚’ä¿å­˜
                    const audioNodeInfo = {
                      oscillator: result.oscillator || null,
                      gainNode: result.gainNode || null,
                      filter: result.filter || null,
                      endTime: result.endTime || (noteStartTime + note.duration),
                      isUnifiedSystem: true, // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ãƒãƒ¼ã‚¯
                      durationType: noteDurationType, // éŸ³ã®é•·ã•åˆ†é¡ã‚’ä¿å­˜
                      isShort: isShort, // çŸ­ã„éŸ³ã‹ã©ã†ã‹ã‚’ä¿å­˜
                      soundId: result.soundId || null, // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã®éŸ³ID
                      type: result.type || 'piano' // éŸ³ã®ã‚¿ã‚¤ãƒ—
                    }
                    
                    activeAudioNodesRef.current.set(note.id, audioNodeInfo)
                    
                    // å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆã¨ã—ã¦å³åº§ã«ç™»éŒ²
                    currentPlaybackNotes.add(note.id)
                    console.log(`ğŸµ ãƒãƒ¼ãƒˆ ${note.id} ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å†ç”Ÿä¸­ãƒãƒ¼ãƒˆã¨ã—ã¦ç™»éŒ²ã—ã¾ã—ãŸ (${noteDurationType}, éŸ³ID: ${result.soundId || 'N/A'})`)
                  }
                } catch (error) {
                  console.error(`âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ¼ãƒˆ ${note.id} ã®å†ç”Ÿã«å¤±æ•—:`, error)
                }
                
                // ãƒãƒ¼ãƒˆçµ‚äº†ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆçµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ã¯è‡ªå‹•çš„ã«ç®¡ç†ã•ã‚Œã‚‹ãŒã€çŠ¶æ…‹ç®¡ç†ã®ãŸã‚ï¼‰
                const endDelay = Math.max(0, (noteEndTime - audio.getCurrentTime()) * 1000)
                const endTimeout = setTimeout(() => {
                  if (!isPlayingRef.current) return
                  
                  // çŸ­ã„éŸ³ã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†
                  const audioNodeInfo = activeAudioNodesRef.current.get(note.id)
                  if (audioNodeInfo && audioNodeInfo.isShort && noteDurationSettings.autoStopShortNotes) {
                    console.log(`ğŸµ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŸ­ã„éŸ³ ${note.id} (${note.pitch}) ã®å†ç”Ÿã‚’è‡ªå‹•çµ‚äº†ã—ã¾ã™`)
                    
                    // çŸ­ã„éŸ³ã®å ´åˆã¯å³åº§ã«åœæ­¢
                    if (audioNodeInfo.isUnifiedSystem) {
                      // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯éŸ³IDã‚’ä½¿ç”¨ã—ã¦åœæ­¢
                      if (audioNodeInfo.soundId && window.unifiedAudioSystem) {
                        try {
                          window.unifiedAudioSystem.stopSound(audioNodeInfo.soundId)
                          console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŸ­ã„éŸ³ ${note.id} (éŸ³ID: ${audioNodeInfo.soundId}) ã‚’åœæ­¢ã—ã¾ã—ãŸ`)
                        } catch (error) {
                          console.error(`âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŸ­ã„éŸ³ ${note.id} ã®åœæ­¢ã«å¤±æ•—:`, error)
                        }
                      } else {
                        console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çŸ­ã„éŸ³ ${note.id} ã¯è‡ªå‹•çš„ã«åœæ­¢ã•ã‚Œã¾ã™`)
                      }
                    } else {
                      // å¾“æ¥ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã®å ´åˆã¯æ‰‹å‹•ã§åœæ­¢
                      if (audioNodeInfo.oscillator) {
                        audioNodeInfo.oscillator.stop()
                      }
                      if (audioNodeInfo.gainNode) {
                        audioNodeInfo.gainNode.gain.cancelScheduledValues(0)
                        audioNodeInfo.gainNode.gain.setValueAtTime(audioNodeInfo.gainNode.gain.value, 0)
                        audioNodeInfo.gainNode.gain.linearRampToValueAtTime(0, 0.05) // çŸ­ã„éŸ³ã¯ç´ æ—©ããƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
                      }
                    }
                  }
                  
                  state.setPlaybackNotes(prev => {
                    const newSet = new Set(prev)
                    newSet.delete(note.id)
                    return newSet
                  })
                  // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆçµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ã¯è‡ªå‹•çš„ã«ç®¡ç†ã•ã‚Œã‚‹ï¼‰
                  activeAudioNodesRef.current.delete(note.id)
                }, endDelay)
                
                // ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚’ä¿å­˜ï¼ˆçµ‚äº†ã‚¿ã‚¤ãƒãƒ¼ã®ã¿ï¼‰
                scheduledNotesRef.current.set(note.id, { startTimeout: null, endTimeout })
              }
            }
          }
        }
        
        // å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’æ›´æ–°ï¼ˆå¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ï¼‰
        const currentPlaybackNotesArray = Array.from(currentPlaybackNotes)
        const statePlaybackNotesArray = Array.from(state.playbackNotes)
        
        if (currentPlaybackNotesArray.length !== statePlaybackNotesArray.length ||
            !currentPlaybackNotesArray.every(id => statePlaybackNotesArray.includes(id))) {
          state.setPlaybackNotes(currentPlaybackNotes)
          console.log('ğŸµ å†ç”Ÿä¸­ã®ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’æ›´æ–°:', {
            current: currentPlaybackNotesArray,
            previous: statePlaybackNotesArray
          })
        }
        
        // ãƒ«ãƒ¼ãƒ—å‡¦ç†
        if (state.loopEnabled && newTime >= state.playbackDuration) {
          state.setCurrentTime(0)
          state.setPlaybackStartTime(currentAudioTime)
          playbackStartTimeRef.current = currentAudioTime
          
          // ãƒ«ãƒ¼ãƒ—æ™‚ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚ŒãŸãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢
          scheduledNotesRef.current.forEach(({ startTimeout, endTimeout }) => {
            if (startTimeout) clearTimeout(startTimeout)
            if (endTimeout) clearTimeout(endTimeout)
          })
          scheduledNotesRef.current.clear()
          activeAudioNodesRef.current.clear()
        }
        
        // å†ç”Ÿçµ‚äº†å‡¦ç†
        if (!state.loopEnabled && newTime >= state.playbackDuration) {
          stopPlayback()
          return
        }
        
        // æ¬¡ã®æ›´æ–°ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
        playbackRef.current = setTimeout(updatePlaybackHead, 16) // 60fps
        
      } catch (error) {
        console.error('ğŸµ Error in playback head update:', error)
        // ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯å†ç”Ÿã‚’åœæ­¢
        stopPlayback()
      }
    }
    
    // åˆå›æ›´æ–°ã‚’é–‹å§‹
    playbackRef.current = setTimeout(updatePlaybackHead, 16)
    
    return () => {
      if (playbackRef.current) {
        clearTimeout(playbackRef.current)
        playbackRef.current = null
      }
    }
  }, [state.isPlaying, state.tempo, state.loopEnabled, state.playbackDuration, stopPlayback])

  // BPMå¤‰æ›´æ™‚ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èª¿æ•´
  const handleTempoChange = useCallback((newTempo) => {
    // å†ç”Ÿä¸­ã¯BPMå¤‰æ›´ã‚’ç„¡åŠ¹ã«ã™ã‚‹
    if (state.isPlaying && isPlayingRef.current) {
      return
    }
    
    // ã‚°ãƒ­ãƒ¼ãƒãƒ«BPMã‚’æ›´æ–°ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§å…¨ãƒˆãƒ©ãƒƒã‚¯ã®ãƒãƒ¼ãƒˆä½ç½®ãŒæ›´æ–°ã•ã‚Œã‚‹ï¼‰
    if (onGlobalTempoChange) {
      onGlobalTempoChange(newTempo)
    }
    
    // ãƒ­ãƒ¼ã‚«ãƒ«çŠ¶æ…‹ã‚‚æ›´æ–°
    state.setTempo(newTempo)
    
    // å†ç”Ÿæ™‚é–“ã¨å†ç”Ÿä½ç½®ã‚’èª¿æ•´
    const oldTempo = globalTempo
    const tempoRatio = oldTempo / newTempo
    
    // å†ç”Ÿæ™‚é–“ã‚‚èª¿æ•´
    const newPlaybackDuration = state.playbackDuration * tempoRatio
    state.setPlaybackDuration(newPlaybackDuration)
    
    // ç¾åœ¨ã®å†ç”Ÿä½ç½®ã‚‚èª¿æ•´
    if (state.currentTime > 0) {
      const newCurrentTime = state.currentTime * tempoRatio
      state.setCurrentTime(newCurrentTime)
    }
    
    // å¼·åˆ¶çš„ã«å†æç”»
    state.setNeedsRedraw(true)
    

  }, [state.isPlaying, globalTempo, onGlobalTempoChange, state.setTempo, state.setPlaybackDuration, state.setCurrentTime, state.setNeedsRedraw]) // ğŸ”§ ä¿®æ­£: state.playbackDurationã¨state.currentTimeã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰

  // ã‚³ãƒ³ãƒ†ãƒŠã®ãƒªã‚µã‚¤ã‚ºç›£è¦–
  useEffect(() => {
    const container = containerRef.current
    if (!container) return

    // ãƒªã‚µã‚¤ã‚ºç›£è¦–
    const resizeObserver = new ResizeObserver(() => {
      state.setNeedsRedraw(true)
    })

    // ãƒšãƒ¼ã‚¸ãƒ¬ãƒ™ãƒ«ã®æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«é˜²æ­¢ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã®æˆ»ã‚‹/é€²ã‚€ã‚’é˜²ãï¼‰
    const handlePageWheel = (e) => {
      // æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã®æˆ»ã‚‹/é€²ã‚€ã‚’é˜²ãï¼‰
      if (Math.abs(e.deltaX) > Math.abs(e.deltaY)) {
        try {
          e.preventDefault();
          e.stopPropagation();
        } catch (error) {
          // passiveã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–
          console.warn('preventDefault failed in passive event listener:', error);
        }
        return false;
      }
    }

    // passive: falseã§ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’è¿½åŠ 
    window.addEventListener('wheel', handlePageWheel, { passive: false })

    resizeObserver.observe(container)
    
    return () => {
      resizeObserver.disconnect()
      window.removeEventListener('wheel', handlePageWheel)
    }
  }, [])

  // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      if (playbackRef.current) {
        clearTimeout(playbackRef.current)
      }
      if (metronomeRef.current) {
        clearTimeout(metronomeRef.current)
      }
      scheduledNotesRef.current.forEach(({ startTimeout, endTimeout }) => {
        clearTimeout(startTimeout)
        clearTimeout(endTimeout)
      })
      
      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      activeAudioNodesRef.current.forEach((audioNodes, noteId) => {
          if (audioNodes.isUnifiedSystem) {
            // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒ‰ã¯è‡ªå‹•çš„ã«åœæ­¢ã•ã‚Œã‚‹
            console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒˆ ${noteId} ã¯è‡ªå‹•çš„ã«åœæ­¢ã•ã‚Œã¾ã™`);
          } else {
            // å¾“æ¥ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã®å ´åˆã¯æ‰‹å‹•ã§åœæ­¢
            if (audioNodes.oscillator) {
              audioNodes.oscillator.stop()
            }
            if (audioNodes.gainNode) {
              audioNodes.gainNode.gain.cancelScheduledValues(0)
              audioNodes.gainNode.gain.setValueAtTime(audioNodes.gainNode.gain.value, 0)
              audioNodes.gainNode.gain.linearRampToValueAtTime(0, 0.1)
            }
          }
      })
      activeAudioNodesRef.current.clear()
      
      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ãƒƒã‚¯ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      audio.cleanup()
    }
  }, [])

  // ãƒãƒ¼ãƒˆè¿½åŠ é–¢æ•°
  const addNote = useCallback(async (pitch, time, duration = 0.25, velocity = 0.8) => {
    if (!trackId || !state.isInitialized) return
    
    const newNote = {
      id: Date.now() + Math.random(),
      pitch,
      time,
      duration,
      velocity,
      trackId
    }
    
    state.setNotes(prev => {
      const updatedNotes = [...prev, newNote]
      
      // å±¥æ­´ã«ä¿å­˜ï¼ˆåŒæœŸçš„ã«å®Ÿè¡Œï¼‰
      persistence.addToHistory(updatedNotes, `Add note ${newNote.id}`)
      
      return updatedNotes
    })
    
    // éŸ³å£°å†ç”Ÿï¼ˆå³åº§ã«å†ç”Ÿï¼‰
    if (state.audioEnabled) {
      const result = await audio.playNote(pitch, velocity, Math.min(duration, 2))
    }
    
    // å†ç”Ÿä¸­ã®å ´åˆã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
    if (state.isPlaying && isPlayingRef.current) {
      const currentTime = state.currentTime
      const noteStartTime = newNote.time
      
      // ãƒãƒ¼ãƒˆãŒç¾åœ¨ã®å†ç”Ÿä½ç½®ã‚ˆã‚Šå¾Œã«ã‚ã‚‹å ´åˆã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
      if (noteStartTime > currentTime) {
        const playbackStartTime = playbackStartTimeRef.current
        const scheduledNoteStartTime = playbackStartTime + noteStartTime
        const scheduledNoteEndTime = scheduledNoteStartTime + newNote.duration
        
        // ãƒãƒ¼ãƒˆé–‹å§‹ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
        const startDelay = Math.max(0, (scheduledNoteStartTime - audio.getCurrentTime()) * 1000)
        const startTimeout = setTimeout(async () => {
          if (!isPlayingRef.current) return
          
          // éŸ³é‡ã¯useMidiAudioãƒ•ãƒƒã‚¯å†…ã§å€‹åˆ¥ãƒˆãƒ©ãƒƒã‚¯éŸ³é‡ Ã— ãƒã‚¹ã‚¿ãƒ¼ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¨ã—ã¦å‡¦ç†ã•ã‚Œã‚‹
          const result = await audio.playScheduledNote(newNote.pitch, scheduledNoteStartTime, newNote.duration, newNote.velocity)
          if (result) {
            state.setPlaybackNotes(prev => new Set([...prev, newNote.id]))
            activeAudioNodesRef.current.set(newNote.id, {
              oscillator: result.oscillator,
              gainNode: result.gainNode,
              filter: result.filter,
              endTime: result.endTime
            })
          }
        }, startDelay)
        
        // ãƒãƒ¼ãƒˆçµ‚äº†ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
        const endDelay = Math.max(0, (scheduledNoteEndTime - audio.getCurrentTime()) * 1000)
        const endTimeout = setTimeout(() => {
          if (!isPlayingRef.current) return
          
          state.setPlaybackNotes(prev => {
            const newSet = new Set(prev)
            newSet.delete(newNote.id)
            return newSet
          })
          activeAudioNodesRef.current.delete(newNote.id)
        }, endDelay)
        
        // ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚’ä¿å­˜
        scheduledNotesRef.current.set(newNote.id, { startTimeout, endTimeout })
      }
    }
    
    state.setLastInputTime(Date.now())
    
    // Ghost Textäºˆæ¸¬ã®å‡¦ç†
    ghostText.processMidiInput(newNote)
    
    // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å³åº§ã«é€šçŸ¥
    if (onNoteAdd) onNoteAdd(newNote)
    
    // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«MIDIãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚’é€šçŸ¥
    setTimeout(() => {
      if (onMidiDataUpdate) {
        const currentNotes = state.notes
        const updateData = {
          notes: [...currentNotes, newNote],
          trackId: trackId,
          lastModified: new Date().toISOString(),
          metadata: {
            modified: new Date().toISOString(),
            noteCount: currentNotes.length + 1
          },
          settings: {
            channel: 0,
            octave: 0,
            transpose: 0,
            velocity: 100
          }
        }
        onMidiDataUpdate(updateData)
      }
    }, 0)
  }, [trackId, state.audioEnabled, onNoteAdd, persistence, ghostText, state.isPlaying, audio]) // ğŸ”§ ä¿®æ­£: state.notesã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰

  // ãƒãƒ¼ãƒˆå‰Šé™¤é–¢æ•°
  const removeNote = useCallback((noteId) => {
    if (!trackId || !state.isInitialized) return
    
    state.setNotes(prev => {
      const updatedNotes = prev.filter(note => note.id !== noteId)
      
      // å±¥æ­´ã«ä¿å­˜ï¼ˆåŒæœŸçš„ã«å®Ÿè¡Œï¼‰
      persistence.addToHistory(updatedNotes, `Remove note ${noteId}`)
      
      return updatedNotes
    })
    
    // å†ç”Ÿä¸­ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¯ãƒªã‚¢
    if (scheduledNotesRef.current.has(noteId)) {
      const { startTimeout, endTimeout } = scheduledNotesRef.current.get(noteId)
      if (startTimeout) clearTimeout(startTimeout)
      if (endTimeout) clearTimeout(endTimeout)
      scheduledNotesRef.current.delete(noteId)
      
      console.log('ğŸµ Cleared scheduled note:', noteId)
    }
    
    // å†ç”Ÿä¸­ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã‚’åœæ­¢
    if (activeAudioNodesRef.current.has(noteId)) {
      const audioNodes = activeAudioNodesRef.current.get(noteId)
      if (audioNodes.isUnifiedSystem) {
        // çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒ‰ã¯è‡ªå‹•çš„ã«åœæ­¢ã•ã‚Œã‚‹
        console.log(`ğŸµ çµ±ä¸€éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹ãƒãƒ¼ãƒˆ ${noteId} ã¯è‡ªå‹•çš„ã«åœæ­¢ã•ã‚Œã¾ã™`);
      } else {
        // å¾“æ¥ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ¼ãƒ‰ã®å ´åˆã¯æ‰‹å‹•ã§åœæ­¢
        if (audioNodes.oscillator) {
          audioNodes.oscillator.stop()
        }
        if (audioNodes.gainNode) {
          audioNodes.gainNode.gain.cancelScheduledValues(0)
          audioNodes.gainNode.gain.setValueAtTime(audioNodes.gainNode.gain.value, 0)
          audioNodes.gainNode.gain.linearRampToValueAtTime(0, 0.1)
        }
      }
      activeAudioNodesRef.current.delete(noteId)
      
      console.log('ğŸµ Stopped playing note:', noteId)
    }
    
    // é¸æŠçŠ¶æ…‹ã‹ã‚‰ã‚‚å‰Šé™¤
    state.setSelectedNotes(prev => {
      const newSet = new Set(prev)
      newSet.delete(noteId)
      return newSet
    })
    state.setNeedsRedraw(true)
    
    // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å³åº§ã«é€šçŸ¥
    if (onNoteRemove) onNoteRemove(noteId)
    
    // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«MIDIãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚’é€šçŸ¥
    setTimeout(() => {
      if (onMidiDataUpdate) {
        const currentNotes = state.notes.filter(note => note.id !== noteId)
        const updateData = {
          notes: currentNotes,
          trackId: trackId,
          lastModified: new Date().toISOString(),
          metadata: {
            modified: new Date().toISOString(),
            noteCount: currentNotes.length
          },
          settings: {
            channel: 0,
            octave: 0,
            transpose: 0,
            velocity: 100
          }
        }
        onMidiDataUpdate(updateData)
      }
    }, 0)
  }, [trackId, onNoteRemove, persistence]) // ğŸ”§ ä¿®æ­£: state.isInitializedã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤

  // ãƒãƒ¼ãƒˆç·¨é›†é–¢æ•°
  const editNote = useCallback((noteId, changes) => {
    if (!trackId || !state.isInitialized) return
    

    
    state.setNotes(prev => {
      const updatedNotes = prev.map(note => 
        note.id === noteId ? { ...note, ...changes } : note
      )
      
      // å±¥æ­´ã«ä¿å­˜ï¼ˆåŒæœŸçš„ã«å®Ÿè¡Œï¼‰
      persistence.addToHistory(updatedNotes, `Edit note ${noteId}`)
      
      return updatedNotes
    })
    
    // ç·¨é›†å¾Œã®ãƒãƒ¼ãƒˆã‚’Magentaã«é€ä¿¡
    const editedNote = state.notes.find(note => note.id === noteId)
    if (editedNote) {
      ghostText.processMidiInput({ ...editedNote, ...changes })
    }
    
    // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å³åº§ã«é€šçŸ¥
    if (onNoteEdit) onNoteEdit(noteId, changes)
    
    // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«MIDIãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚’é€šçŸ¥
    setTimeout(() => {
      if (onMidiDataUpdate) {
        const currentNotes = state.notes.map(note => 
          note.id === noteId ? { ...note, ...changes } : note
        )
        const updateData = {
          notes: currentNotes,
          trackId: trackId,
          lastModified: new Date().toISOString(),
          metadata: {
            modified: new Date().toISOString(),
            noteCount: currentNotes.length
          },
          settings: {
            channel: 0,
            octave: 0,
            transpose: 0,
            velocity: 100
          }
        }
        onMidiDataUpdate(updateData)
      }
    }, 0)
  }, [trackId, onNoteEdit, persistence, ghostText]) // ğŸ”§ ä¿®æ­£: state.notesã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰

  // ãƒãƒ¼ãƒˆãƒ‰ãƒ©ãƒƒã‚°çµ‚äº†å‡¦ç†
  const finalizeNoteDrag = useCallback((noteId, changes) => {
    if (!trackId || !state.isInitialized) return
    

    
    state.setNotes(prev => {
      const updatedNotes = prev.map(note => 
        note.id === noteId ? { ...note, ...changes } : note
      )
      
      // å±¥æ­´ã«ä¿å­˜ï¼ˆåŒæœŸçš„ã«å®Ÿè¡Œï¼‰
      persistence.addToHistory(updatedNotes, `Drag note ${noteId}`)
      
      return updatedNotes
    })
    
    // ãƒ‰ãƒ©ãƒƒã‚°å¾Œã®ãƒãƒ¼ãƒˆã‚’Magentaã«é€ä¿¡
    const draggedNote = state.notes.find(note => note.id === noteId)
    if (draggedNote) {
      ghostText.processMidiInput({ ...draggedNote, ...changes })
    }
    
    if (onNoteEdit) onNoteEdit(noteId, changes)
  }, [trackId, onNoteEdit, persistence, ghostText]) // ğŸ”§ ä¿®æ­£: state.notesã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢ï¼‰

  // è¤‡æ•°ãƒãƒ¼ãƒˆãƒ‰ãƒ©ãƒƒã‚°çµ‚äº†å‡¦ç†
  const finalizeMultiNoteDrag = useCallback((updatedNotes) => {
    if (!trackId || !state.isInitialized) return
    

    
    // Magentaã«å…¨ãƒãƒ¼ãƒˆã®æœ€æ–°çŠ¶æ…‹ã‚’é€ä¿¡ï¼ˆä»£è¡¨çš„ãªãƒãƒ¼ãƒˆã‚’ä½¿ã†ï¼‰
    if (updatedNotes.length > 0) {
      ghostText.processMidiInput(updatedNotes[updatedNotes.length - 1])
    }
    
    // åŒæœŸçš„ã«ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’æ›´æ–°ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
    state.setNotes(prev => {
      // æ—¢ã«åŒã˜çŠ¶æ…‹ã®å ´åˆã¯æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—
      const updatedNotesMap = new Map(updatedNotes.map(note => [note.id, note]))
      const newNotes = prev.map(note => 
        updatedNotesMap.has(note.id) ? updatedNotesMap.get(note.id) : note
      )
      
      // çŠ¶æ…‹ãŒå®Ÿéš›ã«å¤‰æ›´ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ˆã‚Šå³å¯†ãªæ¯”è¼ƒï¼‰
      const hasChanges = updatedNotes.some(updatedNote => {
        const prevNote = prev.find(note => note.id === updatedNote.id)
        if (!prevNote) return true // æ–°ã—ã„ãƒãƒ¼ãƒˆ
        return prevNote.time !== updatedNote.time || 
               prevNote.pitch !== updatedNote.pitch ||
               prevNote.duration !== updatedNote.duration ||
               prevNote.velocity !== updatedNote.velocity
      })
      
      if (!hasChanges) {

        return prev
      }
      

      
              // çŠ¶æ…‹æ›´æ–°å¾Œã«è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«é€šçŸ¥
        setTimeout(() => {
          if (onMidiDataUpdate) {

              // æ›´æ–°æ™‚åˆ»ã‚’è¨˜éŒ²
              lastParentUpdateRef.current[trackId] = Date.now()
              
              onMidiDataUpdate({
                notes: newNotes,
                trackId: trackId,
                lastModified: new Date().toISOString(),
                metadata: {
                  modified: new Date().toISOString(),
                  noteCount: newNotes.length,
                  type: 'multi-note-drag'
                },
                settings: {
                  channel: 0,
                  octave: 0,
                  transpose: 0,
                  velocity: 100
                }
              })
          } else {
            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å€‹åˆ¥ã®onNoteEditã‚’å‘¼ã³å‡ºã™ï¼ˆå¾“æ¥ã®å‹•ä½œï¼‰
            updatedNotes.forEach(note => {
              if (onNoteEdit) onNoteEdit(note.id, { time: note.time, pitch: note.pitch })
            })
          }
          

          

        }, 50) // çŠ¶æ…‹æ›´æ–°ã®å®Œäº†ã‚’å¾…ã¤æ™‚é–“ã‚’å¢—åŠ 
      
      return newNotes
    })
    
    // å±¥æ­´ã«ä¿å­˜ï¼ˆçŠ¶æ…‹æ›´æ–°å¾Œã«å®Ÿè¡Œï¼‰
    setTimeout(() => {
      // è¤‡æ•°ãƒãƒ¼ãƒˆãƒ‰ãƒ©ãƒƒã‚°ä¸­ã¯å±¥æ­´ä¿å­˜ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆfinalizeMultiNoteDragã§å‡¦ç†æ¸ˆã¿ï¼‰
      if (!state.isDraggingMultipleNotes) {
        persistence.addToHistory(updatedNotes, `Multi-drag ${updatedNotes.length} notes`)
      }
    }, 10)
  }, [trackId, onMidiDataUpdate, onNoteEdit, persistence]) // ğŸ”§ ä¿®æ­£: state.isInitializedã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤







  // ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®åˆæœŸåŒ–
  const eventHandlers = MidiEditorEventHandlers({
    state,
    coordinateTransforms,
    GRID_HEIGHT,
    GRID_WIDTH,
    PIANO_WIDTH,
    HEADER_HEIGHT,
    NOTE_HEIGHT,
    OCTAVE_RANGE,
    LONG_PRESS_THRESHOLD,
    dynamicCanvasRef,
    containerRef,
    longPressTimerRef,
    audio,
    addNote,
    finalizeNoteDrag,
    finalizeMultiNoteDrag,
    noteOperations,
    startPlayback,
    pausePlayback,
    isActive,
    trackId
  })













  // Ghost Textäºˆæ¸¬ã®å—ã‘å…¥ã‚Œã¯å°‚ç”¨ãƒ•ãƒƒã‚¯ã§å‡¦ç†
  const acceptGhostPrediction = useCallback((predictionIndex = 0) => {
    ghostText.acceptGhostPrediction(predictionIndex, state.notes, addNote)
  }, [ghostText, state.notes, addNote])

  // Ghost Textäºˆæ¸¬ã®å…¨é©ç”¨ã¯å°‚ç”¨ãƒ•ãƒƒã‚¯ã§å‡¦ç†
  const acceptAllGhostPredictions = useCallback(() => {
    ghostText.acceptAllGhostPredictions(state.notes, addNote)
  }, [ghostText, state.notes, addNote])

  // Ghost Textã®ãƒˆã‚°ãƒ«ã¯å°‚ç”¨ãƒ•ãƒƒã‚¯ã§å‡¦ç†
  const toggleGhostText = useCallback(() => {
    ghostText.toggleGhostText()
  }, [ghostText])
  // å·»ãæˆ»ã—æ©Ÿèƒ½ï¼ˆæ°¸ç¶šåŒ–ãƒ•ãƒƒã‚¯ä½¿ç”¨ï¼‰
  const undoLastAction = useCallback(() => {
    if (!trackId || !state.isInitialized) return
    

    
    const previousState = persistence.restoreFromHistory('undo')
    
    if (previousState) {

      
      // ãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼ã§ç¢ºå®Ÿã«åˆ†é›¢
      const previousStateCopy = previousState.map(note => ({ ...note }))
      state.setNotes(previousStateCopy)
      
      // ãƒ‡ãƒ¼ã‚¿ã‚’æ°¸ç¶šåŒ–
      trackDataRef.current[trackId] = [...previousStateCopy]
      lastSavedRef.current[trackId] = Date.now()
      persistence.saveNotes(previousStateCopy, trackId)
      
      state.setSelectedNotes(new Set())
      state.setNeedsRedraw(true)
    }
  }, [trackId, persistence]) // ğŸ”§ ä¿®æ­£: state.isInitializedã‚’ä¾å­˜é…åˆ—ã‹ã‚‰å‰Šé™¤
  






  
  // é¸æŠã•ã‚ŒãŸãƒãƒ¼ãƒˆã‚’ã‚³ãƒ”ãƒ¼

  return (
    <div 
      className="flex flex-col bg-gray-900 text-white midi-editor-container h-full"
      style={{ 
        overscrollBehavior: 'none'
      }}
    >
      {/* ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ */}
      <MidiEditorToolbar
        // å†ç”Ÿé–¢é€£
        isPlaying={state.isPlaying}
        onPlayPause={async (e) => {
          e.preventDefault()
          e.stopPropagation()
          
          console.log('ğŸµ Play/Pause button clicked:', {
            isPlaying: state.isPlaying,
            isPlayingRef: isPlayingRef.current,
            notesLength: state.notes.length,
            audioEnabled: state.audioEnabled
          })
          
          try {
            if (isPlayingRef.current) {
              console.log('ğŸµ Pausing playback...')
              pausePlayback()
            } else {
              console.log('ğŸµ Starting playback...')
              await startPlayback()
            }
          } catch (error) {
            console.error('âŒ Playback error:', error)
          }
        }}
        onStop={() => {
          console.log('ğŸµ Stop button clicked')
          stopPlayback()
        }}
        notesLength={state.notes.length}
        
        // æ“ä½œé–¢é€£
        onUndo={undoLastAction}
        canUndo={state.isInitialized && persistence.getHistoryInfo().canUndo}
        onShowDeleteConfirm={() => state.setShowDeleteConfirm(true)}
        
        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªé–¢é€£
        audioEnabled={state.audioEnabled}
        onToggleAudio={() => {
          console.log('ğŸµ Toggling audio:', !state.audioEnabled)
          state.setAudioEnabled(!state.audioEnabled)
        }}
        
        // ãƒ†ãƒ³ãƒé–¢é€£
        tempo={globalTempo}
        onTempoChange={handleTempoChange}
        
        // ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ¡ãƒˆãƒ­ãƒãƒ¼ãƒ é–¢é€£
        loopEnabled={state.loopEnabled}
        onToggleLoop={() => {
          console.log('ğŸµ Toggling loop:', !state.loopEnabled)
          state.setLoopEnabled(!state.loopEnabled)
        }}
        metronomeEnabled={state.metronomeEnabled}
        onToggleMetronome={() => {
          console.log('ğŸµ Toggling metronome:', !state.metronomeEnabled)
          state.setMetronomeEnabled(!state.metronomeEnabled)
        }}
        
        // ã‚ºãƒ¼ãƒ é–¢é€£
        zoom={state.zoom}
        onZoomChange={(value) => state.setZoom(value)}
        
        // Ghost Texté–¢é€£
        ghostTextEnabled={ghostText.ghostTextEnabled}
        onToggleGhostText={ghostText.toggleGhostText}
        showGhostText={ghostText.showGhostText}
        onToggleShowGhostText={ghostText.toggleShowGhostText}
        
        // è¨­å®šé–¢é€£
        showSettings={false}
        onToggleSettings={onOpenSettings}
        
        // éŸ³è‰²é–¢é€£
        currentInstrument={instrumentSettings.instrument}
        onInstrumentChange={instrumentSettings.handleInstrumentChange}
        onOpenInstrumentSettings={instrumentSettings.openSettingsPanel}
      />



      {/* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ */}
      {appSettings?.midiEditor?.developerMode && (
        <MidiEditorStatusBar
          // ãƒˆãƒ©ãƒƒã‚¯æƒ…å ±
          trackName={trackName}
          trackType={trackType}
          trackColor={trackColor}
          
          // Ghost Texté–¢é€£
          ghostTextStatus={ghostText.ghostTextStatus}
          currentModel={ghostText.currentModel}
          
          // ãƒãƒ¼ãƒˆæƒ…å ±
          notesCount={state.notes.length}
          
          // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ»å†ç”ŸçŠ¶æ…‹
          audioEnabled={state.audioEnabled}
          isPlaying={state.isPlaying}
          tempo={globalTempo}
          loopEnabled={state.loopEnabled}
          metronomeEnabled={state.metronomeEnabled}
          
          // æ™‚é–“æƒ…å ±
          currentTime={state.currentTime}
          playbackDuration={state.playbackDuration}
          
          // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
          performanceMetrics={ghostText.performanceMetrics}
        />
      )}



      {/* MIDIã‚¨ãƒ‡ã‚£ã‚¿ã‚­ãƒ£ãƒ³ãƒã‚¹ */}
      <MidiEditorCanvas
        // ã‚­ãƒ£ãƒ³ãƒã‚¹é–¢é€£
        staticCanvasRef={staticCanvasRef}
        dynamicCanvasRef={dynamicCanvasRef}
        timelineCanvasRef={timelineCanvasRef}
        containerRef={containerRef}
        
        // çŠ¶æ…‹ç®¡ç†
        state={state}
        
        // åº§æ¨™å¤‰æ›
        coordinateTransforms={coordinateTransforms}
        
        // å®šæ•°
        GRID_HEIGHT={GRID_HEIGHT}
        GRID_WIDTH={GRID_WIDTH}
        PIANO_WIDTH={PIANO_WIDTH}
        HEADER_HEIGHT={HEADER_HEIGHT}
        NOTE_HEIGHT={NOTE_HEIGHT}
        OCTAVE_RANGE={OCTAVE_RANGE}
        TOTAL_KEYS={TOTAL_KEYS}
        
        // Ghost Texté–¢é€£
        ghostPredictions={ghostText.ghostPredictions}
        showGhostText={ghostText.showGhostText}
        onAcceptPrediction={acceptGhostPrediction}
        onAcceptAllPredictions={acceptAllGhostPredictions}
        
        // ãƒ©ã‚¤ãƒ–éŒ²éŸ³é–¢é€£
        liveRecordingNotes={liveRecordingNotes}
        
        // ã‚ªã‚¯ã‚¿ãƒ¼ãƒ–èª¿æ•´é–¢é€£
        manualOctaveOffset={manualOctaveOffset}
        
        // ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼
        onMouseDown={eventHandlers.handleMouseDown}
        onMouseMove={eventHandlers.handleMouseMove}
        onMouseUp={eventHandlers.handleMouseUp}
        onContextMenu={eventHandlers.handleCanvasRightClick}
        onWheel={() => {}} // Reactã®onWheelã¯ä½¿ç”¨ã—ãªã„
        onTimelineClick={eventHandlers.handleTimelineClick}
        onPianoRollClick={async (pitch) => {
          // ãƒ”ã‚¢ãƒãƒ­ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯æ™‚ã®éŸ³å†ç”Ÿï¼ˆã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¨åŒã˜æ–¹æ³•ï¼‰
          if (state.audioEnabled && window.unifiedAudioSystem) {
            console.log(`ğŸ¹ ãƒ”ã‚¢ãƒãƒ­ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯: ã‚­ãƒ¼ ${pitch} ã‚’å†ç”Ÿ`);
            await window.unifiedAudioSystem.playPianoNote(pitch, 0.24); // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¨åŒã˜éŸ³é‡0.24
          }
        }}
      />

      {/* å‰Šé™¤ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚° */}
      {state.showDeleteConfirm && (
        <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
          <div className="bg-gray-800 border border-gray-600 rounded-lg p-6 max-w-md w-full mx-4">
            <div className="flex items-center space-x-3 mb-4">
              <AlertTriangle className="h-6 w-6 text-red-400" />
              <h3 className="text-lg font-semibold text-white">å…¨å‰Šé™¤ã®ç¢ºèª</h3>
            </div>
            <p className="text-gray-300 mb-6">
                              ã“ã®ãƒˆãƒ©ãƒƒã‚¯ã®ã™ã¹ã¦ã®ãƒãƒ¼ãƒˆï¼ˆ{state.notes.length}å€‹ï¼‰ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ<br />
              ã“ã®æ“ä½œã¯å…ƒã«æˆ»ã›ã¾ã›ã‚“ã€‚<br />
              ã€Œãƒ­ãƒ¼ãƒ‰ã€ãƒœã‚¿ãƒ³ã§å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒã§ãã¾ã™ã€‚
            </p>
            <div className="flex justify-end space-x-3">
              <Button
                variant="outline"
                onClick={() => state.setShowDeleteConfirm(false)}
                className="border-gray-600 text-gray-300 hover:bg-gray-700"
              >
                ã‚­ãƒ£ãƒ³ã‚»ãƒ«
              </Button>
              <Button
                variant="outline"
                onClick={() => {
                  noteOperations.reloadTrack()
                  state.setShowDeleteConfirm(false)
                }}
                className="border-blue-600 text-blue-300 hover:bg-blue-700"
              >
                ãƒ­ãƒ¼ãƒ‰
              </Button>
              <Button
                variant="destructive"
                onClick={() => {
                  if (trackId && state.isInitialized) {
                    // ãƒ¡ãƒ¢ãƒªä¸Šã®ãƒãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢
                    state.setNotes([])
                    
                    // Refãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ï¼ˆã‚¯ãƒªã‚¢ã§ã¯ãªãæ›´æ–°ï¼‰
                    trackDataRef.current[trackId] = []
                    lastSavedRef.current[trackId] = Date.now()
                    
                    // æ°¸ç¶šåŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                    persistence.saveNotes([], trackId)
                    
                    // å±¥æ­´ã‚’ã‚¯ãƒªã‚¢
                    persistence.clearHistory()
                    
                    // è¦ªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ç©ºã®çŠ¶æ…‹ã‚’é€šçŸ¥
                    if (onMidiDataUpdate) {
                      const updateData = {
                        notes: [],
                        trackId: trackId,
                        lastModified: new Date().toISOString(),
                        metadata: {
                          modified: new Date().toISOString(),
                          noteCount: 0
                        },
                        settings: {
                          channel: 0,
                          octave: 0,
                          transpose: 0,
                          velocity: 100
                        }
                      }
                      onMidiDataUpdate(updateData)
                    }
                    
  
                  }
                  state.setSelectedNotes(new Set())
                  state.setShowDeleteConfirm(false)
                }}
                className="bg-red-600 hover:bg-red-700"
              >
                å…¨å‰Šé™¤
              </Button>
            </div>
          </div>
        </div>
      )}

      {/* éŸ³è‰²è¨­å®šãƒ‘ãƒãƒ« */}
      {instrumentSettings.showSettingsPanel && (
        <InstrumentSettingsPanel
          instrument={instrumentSettings.instrument}
          settings={instrumentSettings.settings}
          onSettingsChange={instrumentSettings.handleSettingsChange}
          onClose={instrumentSettings.closeSettingsPanel}
          onSave={instrumentSettings.handleSaveSettings}
          onReset={instrumentSettings.handleResetSettings}
          // Ghost Texté–¢é€£ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
          ghostTextEnabled={ghostText.ghostTextEnabled}
          aiModel={ghostText.currentModel}
          onAiModelChange={ghostText.changeModel}
          onGhostTextToggle={ghostText.toggleGhostText}
          // éŸ³æ¥½ç†è«–è¨­å®šãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
          musicTheorySettings={musicTheorySettings}
          onMusicTheorySettingsChange={handleMusicTheorySettingsChange}
        />
      )}



      {/* ãƒ©ã‚¤ãƒ–éŒ²éŸ³çŠ¶æ…‹è¡¨ç¤º */}
      {state.isPlaying && (
        <div className="fixed top-4 left-4 z-50">
          <div className="bg-red-500 text-white px-3 py-2 rounded-lg shadow-lg text-sm font-medium animate-pulse">
            ğŸ¹ Live Recording
            <div className="text-xs mt-1 opacity-80">
              Press keys to record notes
            </div>
          </div>
        </div>
      )}
    </div>
  )
}

export default memo(EnhancedMidiEditor)

