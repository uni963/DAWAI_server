# å®Ÿè£…ã‚¬ã‚¤ãƒ‰ãƒ»çµ±åˆãƒ‘ã‚¹

**æœ€çµ‚æ›´æ–°**: 2025-10-05
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0

---

## ğŸ“‹ ç›®æ¬¡

1. [æ–°è¨€èªè¿½åŠ æ‰‹é †](#æ–°è¨€èªè¿½åŠ æ‰‹é †)
2. [ã‚³ãƒ¼ãƒ‰è¦ç´„](#ã‚³ãƒ¼ãƒ‰è¦ç´„)
3. [ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª](#ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª)
4. [ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ](#ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ)
5. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## æ–°è¨€èªè¿½åŠ æ‰‹é †

### æ—¥æœ¬èªè¿½åŠ ä¾‹ï¼ˆå®Œå…¨ã‚¬ã‚¤ãƒ‰ï¼‰

#### Step 1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
cd backend/diffsinger_engine

# æ—¥æœ¬èªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p languages/ja_JP/{checkpoints/{acoustic,vocoder,pe},tests}

# æ§‹é€ ç¢ºèª
tree languages/ja_JP
# languages/ja_JP/
# â”œâ”€â”€ checkpoints/
# â”‚   â”œâ”€â”€ acoustic/
# â”‚   â”œâ”€â”€ vocoder/
# â”‚   â””â”€â”€ pe/
# â””â”€â”€ tests/
```

#### Step 2: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

`languages/ja_JP/config.yaml`:
```yaml
language:
  code: "ja_JP"
  display_name: "æ—¥æœ¬èª"
  native_name: "æ—¥æœ¬èª"
  iso_639_1: "ja"

phoneme_system:
  type: "romaji"  # ãƒ­ãƒ¼ãƒå­—éŸ³ç´ 
  separator: " "
  use_tone: false  # æ—¥æœ¬èªã¯å£°èª¿ãªã—

text_processor:
  class: "languages.ja_JP.processor.JapaneseTextProcessor"
  dependencies:
    - mecab-python3>=1.0.6
    - unidic-lite>=1.0.8
    - pykakasi>=2.2.1
    - romkan>=0.2.1

model:
  acoustic: "languages/ja_JP/checkpoints/acoustic"
  vocoder: "languages/ja_JP/checkpoints/vocoder"
  pitch_extractor: "languages/ja_JP/checkpoints/pe"

audio:
  sample_rate: 24000
  mel_bins: 80
  hop_size: 128
  win_size: 512
  fmin: 30
  fmax: 12000

features:
  supports_tone: false
  supports_slur: true
  max_phoneme_length: 2  # æ—¥æœ¬èªéŸ³ç´ ã¯æœ€å¤§2æ–‡å­—ï¼ˆch, shç­‰ï¼‰

inference:
  timesteps: 100
  K_step: 100
  diff_loss_type: "l1"
```

#### Step 3: éŸ³ç´ è¾æ›¸ä½œæˆ

`languages/ja_JP/phoneme_dict.json`:
```json
{
  "phonemes": [
    "SP", "AP",
    "a", "i", "u", "e", "o",
    "ka", "ki", "ku", "ke", "ko",
    "sa", "shi", "su", "se", "so",
    "ta", "chi", "tsu", "te", "to",
    "na", "ni", "nu", "ne", "no",
    "ha", "hi", "fu", "he", "ho",
    "ma", "mi", "mu", "me", "mo",
    "ya", "yu", "yo",
    "ra", "ri", "ru", "re", "ro",
    "wa", "wo", "n",
    "ga", "gi", "gu", "ge", "go",
    "za", "ji", "zu", "ze", "zo",
    "da", "di", "du", "de", "do",
    "ba", "bi", "bu", "be", "bo",
    "pa", "pi", "pu", "pe", "po",
    "kya", "kyu", "kyo",
    "sha", "shu", "sho",
    "cha", "chu", "cho",
    "nya", "nyu", "nyo",
    "hya", "hyu", "hyo",
    "mya", "myu", "myo",
    "rya", "ryu", "ryo",
    "gya", "gyu", "gyo",
    "ja", "ju", "jo",
    "bya", "byu", "byo",
    "pya", "pyu", "pyo"
  ],
  "special_tokens": ["SP", "AP"],
  "vowels": ["a", "i", "u", "e", "o"],
  "sokuon": "q",
  "hatsuon": "N"
}
```

#### Step 4: ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ã‚»ãƒƒã‚µå®Ÿè£…

`languages/ja_JP/processor.py`:
```python
"""
æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ã‚»ãƒƒã‚µ

è²¬å‹™:
- æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ â†’ ãƒ­ãƒ¼ãƒå­—éŸ³ç´ å¤‰æ›
- MeCabå½¢æ…‹ç´ è§£æ
- ã‹ãª-ãƒ­ãƒ¼ãƒå­—å¯¾å¿œ
"""
from typing import List
import MeCab
import pykakasi
import romkan
from languages.base.processor import BaseLanguageProcessor


class JapaneseTextProcessor(BaseLanguageProcessor):
    """æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†"""

    def __init__(self):
        # MeCabåˆæœŸåŒ–
        try:
            self.mecab = MeCab.Tagger("-Owakati")
        except RuntimeError:
            # Fallback to default dictionary
            self.mecab = MeCab.Tagger()

        # pykakasiåˆæœŸåŒ–ï¼ˆæ¼¢å­—â†’ã‹ãªå¤‰æ›ï¼‰
        self.kakasi = pykakasi.kakasi()

    def convert(self, text: str) -> List[str]:
        """
        æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ â†’ ãƒ­ãƒ¼ãƒå­—éŸ³ç´ åˆ—

        Examples:
            >>> processor = JapaneseTextProcessor()
            >>> processor.convert("æ¡œãŒå’²ã„ãŸ")
            ['s', 'a', 'k', 'u', 'r', 'a', 'g', 'a', 's', 'a', 'i', 't', 'a']

        Args:
            text: æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ãƒ­ãƒ¼ãƒå­—éŸ³ç´ ã®ãƒªã‚¹ãƒˆ
        """
        # Step 1: æ¼¢å­— â†’ ã²ã‚‰ãŒãªå¤‰æ›
        kana = self._to_hiragana(text)

        # Step 2: ã²ã‚‰ãŒãª â†’ ãƒ­ãƒ¼ãƒå­—å¤‰æ›
        romaji = romkan.to_roma(kana)

        # Step 3: ãƒ­ãƒ¼ãƒå­— â†’ éŸ³ç´ åˆ†å‰²
        phonemes = self._split_to_phonemes(romaji)

        return phonemes

    def _to_hiragana(self, text: str) -> str:
        """
        æ¼¢å­—æ··ã˜ã‚Šæ–‡ â†’ ã²ã‚‰ãŒãª

        "æ¡œ" â†’ "ã•ãã‚‰"
        """
        result = self.kakasi.convert(text)
        return ''.join([item['hira'] for item in result])

    def _split_to_phonemes(self, romaji: str) -> List[str]:
        """
        ãƒ­ãƒ¼ãƒå­— â†’ éŸ³ç´ åˆ†å‰²

        "konnichiwa" â†’ ['k', 'o', 'N', 'n', 'i', 'ch', 'i', 'w', 'a']

        ç‰¹æ®Šå‡¦ç†:
        - ä¿ƒéŸ³ï¼ˆã£ï¼‰: "tte" â†’ ['t', 'te']ï¼ˆå­éŸ³é‡è¤‡ï¼‰
        - æ’¥éŸ³ï¼ˆã‚“ï¼‰: "n" â†’ 'N'ï¼ˆå‰å¾Œã®æ–‡è„ˆã§åˆ¤å®šï¼‰
        - é•·éŸ³ï¼ˆãƒ¼ï¼‰: "aa" â†’ ['a', 'a']ï¼ˆæ¯éŸ³é‡è¤‡ï¼‰
        """
        phonemes = []
        i = 0

        while i < len(romaji):
            # 3æ–‡å­—éŸ³ç´ ãƒã‚§ãƒƒã‚¯ï¼ˆkya, shaç­‰ï¼‰
            if i + 2 < len(romaji):
                three_char = romaji[i:i+3]
                if three_char in ['kya', 'kyu', 'kyo', 'sha', 'shu', 'sho',
                                  'cha', 'chu', 'cho', 'nya', 'nyu', 'nyo',
                                  'hya', 'hyu', 'hyo', 'mya', 'myu', 'myo',
                                  'rya', 'ryu', 'ryo', 'gya', 'gyu', 'gyo',
                                  'bya', 'byu', 'byo', 'pya', 'pyu', 'pyo']:
                    phonemes.append(three_char)
                    i += 3
                    continue

            # 2æ–‡å­—éŸ³ç´ ãƒã‚§ãƒƒã‚¯ï¼ˆka, shi, chi, tsuç­‰ï¼‰
            if i + 1 < len(romaji):
                two_char = romaji[i:i+2]
                if two_char in ['ka', 'ki', 'ku', 'ke', 'ko', 'sa', 'shi',
                                'su', 'se', 'so', 'ta', 'chi', 'tsu', 'te',
                                'to', 'na', 'ni', 'nu', 'ne', 'no', 'ha',
                                'hi', 'fu', 'he', 'ho', 'ma', 'mi', 'mu',
                                'me', 'mo', 'ya', 'yu', 'yo', 'ra', 'ri',
                                'ru', 're', 'ro', 'wa', 'wo', 'ga', 'gi',
                                'gu', 'ge', 'go', 'za', 'ji', 'zu', 'ze',
                                'zo', 'da', 'di', 'du', 'de', 'do', 'ba',
                                'bi', 'bu', 'be', 'bo', 'pa', 'pi', 'pu',
                                'pe', 'po']:
                    phonemes.append(two_char)
                    i += 2
                    continue

            # æ’¥éŸ³å‡¦ç†ï¼ˆn â†’ Nï¼‰
            if romaji[i] == 'n':
                # æ¬¡ã®æ–‡å­—ãŒæ¯éŸ³ã§ãªã‘ã‚Œã°æ’¥éŸ³
                if i + 1 >= len(romaji) or romaji[i+1] not in 'aiueo':
                    phonemes.append('N')
                    i += 1
                    continue

            # 1æ–‡å­—éŸ³ç´ ï¼ˆæ¯éŸ³a,i,u,e,oï¼‰
            if romaji[i] in 'aiueo':
                phonemes.append(romaji[i])
                i += 1
                continue

            # ä¿ƒéŸ³å‡¦ç†ï¼ˆå­éŸ³é‡è¤‡ â†’ ä¿ƒéŸ³'q'ï¼‰
            if i + 1 < len(romaji) and romaji[i] == romaji[i+1]:
                phonemes.append('q')  # ä¿ƒéŸ³è¨˜å·
                i += 1  # é‡è¤‡å­éŸ³ã®1ã¤ç›®ã‚’ã‚¹ã‚­ãƒƒãƒ—
                continue

            # ãã®ä»–ã®æ–‡å­—ï¼ˆãã®ã¾ã¾è¿½åŠ ï¼‰
            phonemes.append(romaji[i])
            i += 1

        return phonemes
```

#### Step 5: ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…

`languages/ja_JP/engine.py`:
```python
"""
æ—¥æœ¬èªæ­Œå£°åˆæˆã‚¨ãƒ³ã‚¸ãƒ³

è²¬å‹™:
- æ—¥æœ¬èªå°‚ç”¨éŸ³ç´ å¤‰æ›çµ±åˆ
- æ—¥æœ¬èªè¨­å®šç®¡ç†
- BaseSynthesisEngineã®å…·è±¡åŒ–
"""
from typing import List, Dict
import yaml
from pathlib import Path
import json

from core.base_engine import BaseSynthesisEngine
from languages.ja_JP.processor import JapaneseTextProcessor


class JapaneseEngine(BaseSynthesisEngine):
    """æ—¥æœ¬èªæ­Œå£°åˆæˆã‚¨ãƒ³ã‚¸ãƒ³"""

    language_code = "ja_JP"

    def __init__(self):
        super().__init__()

        # è¨­å®šãƒ­ãƒ¼ãƒ‰
        config_path = Path(__file__).parent / "config.yaml"
        with open(config_path, encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
        self.text_processor = JapaneseTextProcessor()

        # éŸ³ç´ è¾æ›¸ãƒ­ãƒ¼ãƒ‰
        phoneme_dict_path = Path(__file__).parent / "phoneme_dict.json"
        with open(phoneme_dict_path, encoding='utf-8') as f:
            phoneme_data = json.load(f)
            self.phoneme_list = phoneme_data["phonemes"]

        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self._load_models()

    def text_to_phonemes(self, text: str) -> List[str]:
        """
        æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ â†’ éŸ³ç´ å¤‰æ›

        Examples:
            >>> engine = JapaneseEngine()
            >>> engine.text_to_phonemes("æ¡œãŒå’²ã")
            ['s', 'a', 'k', 'u', 'r', 'a', 'g', 'a', 's', 'a', 'k', 'u']
        """
        return self.text_processor.convert(text)

    def get_phoneme_dict(self) -> List[str]:
        """æ—¥æœ¬èªéŸ³ç´ è¾æ›¸å–å¾—"""
        return self.phoneme_list

    def _load_models(self):
        """æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰"""
        from utils.hparams import set_hparams, hparams

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        acoustic_config = self.config["model"]["acoustic"] + "/config.yaml"

        # Hparamsãƒ­ãƒ¼ãƒ‰
        set_hparams(acoustic_config, exp_name='ja_JP_synthesis')

        # work_dirè¨­å®š
        hparams['work_dir'] = self.config["model"]["acoustic"]
        hparams['pe_ckpt'] = self.config["model"]["pitch_extractor"]
        hparams['vocoder_ckpt'] = self.config["model"]["vocoder"]

        # è¦ªã‚¯ãƒ©ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        super()._load_models()


# è‡ªå‹•ç™»éŒ²
if __name__ != "__main__":
    from registry.language_registry import language_registry
    language_registry.register(JapaneseEngine.language_code, JapaneseEngine)
```

#### Step 6: è‡ªå‹•ç™»éŒ²è¨­å®š

`languages/ja_JP/__init__.py`:
```python
"""
æ—¥æœ¬èªãƒ—ãƒ©ã‚°ã‚¤ãƒ³è‡ªå‹•ç™»éŒ²

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã‚‹ã¨è‡ªå‹•çš„ã«
LanguageRegistryã«æ—¥æœ¬èªã‚¨ãƒ³ã‚¸ãƒ³ãŒç™»éŒ²ã•ã‚Œã‚‹
"""
from .engine import JapaneseEngine
from registry.language_registry import language_registry

# è‡ªå‹•ç™»éŒ²
language_registry.register(JapaneseEngine.language_code, JapaneseEngine)

__all__ = ['JapaneseEngine']
```

#### Step 7: ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# æ—¥æœ¬èªå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install mecab-python3 unidic-lite pykakasi romkan

# MeCabè¾æ›¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆUbuntuã®å ´åˆï¼‰
sudo apt-get install mecab libmecab-dev mecab-ipadic-utf8
```

#### Step 8: çµ±åˆãƒ†ã‚¹ãƒˆ

`languages/ja_JP/tests/test_japanese_engine.py`:
```python
"""æ—¥æœ¬èªã‚¨ãƒ³ã‚¸ãƒ³çµ±åˆãƒ†ã‚¹ãƒˆ"""
import pytest
from languages.ja_JP.engine import JapaneseEngine


class TestJapaneseEngine:
    """æ—¥æœ¬èªã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    @pytest.fixture
    def engine(self):
        """ã‚¨ãƒ³ã‚¸ãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹"""
        return JapaneseEngine()

    def test_text_to_phonemes_hiragana(self, engine):
        """ã²ã‚‰ãŒãª â†’ éŸ³ç´ å¤‰æ›"""
        phonemes = engine.text_to_phonemes("ã•ãã‚‰")
        assert phonemes == ['s', 'a', 'k', 'u', 'r', 'a']

    def test_text_to_phonemes_kanji(self, engine):
        """æ¼¢å­— â†’ éŸ³ç´ å¤‰æ›"""
        phonemes = engine.text_to_phonemes("æ¡œ")
        assert phonemes == ['s', 'a', 'k', 'u', 'r', 'a']

    def test_text_to_phonemes_mixed(self, engine):
        """æ··åœ¨æ–‡ â†’ éŸ³ç´ å¤‰æ›"""
        phonemes = engine.text_to_phonemes("æ¡œãŒå’²ã")
        assert 's' in phonemes
        assert 'a' in phonemes
        assert 'k' in phonemes

    def test_sokuon(self, engine):
        """ä¿ƒéŸ³å‡¦ç†"""
        phonemes = engine.text_to_phonemes("ãŒã£ã“ã†")
        # "gakkou" â†’ ['g', 'a', 'q', 'k', 'o', 'u']
        assert 'q' in phonemes or phonemes.count('k') > 1

    def test_hatsuon(self, engine):
        """æ’¥éŸ³å‡¦ç†"""
        phonemes = engine.text_to_phonemes("ã•ã‚“ã½")
        # "sanpo" â†’ ['s', 'a', 'N', 'p', 'o']
        assert 'N' in phonemes or 'n' in phonemes
```

**ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ**:
```bash
pytest languages/ja_JP/tests/test_japanese_engine.py -v
```

---

## ã‚³ãƒ¼ãƒ‰è¦ç´„

### Python ã‚¹ã‚¿ã‚¤ãƒ«

**åŸºæº–**: PEP 8 + Google Style Docstrings

```python
# âœ… æ­£ã—ã„ä¾‹
class JapaneseEngine(BaseSynthesisEngine):
    """
    æ—¥æœ¬èªæ­Œå£°åˆæˆã‚¨ãƒ³ã‚¸ãƒ³

    Attributes:
        language_code (str): è¨€èªã‚³ãƒ¼ãƒ‰ "ja_JP"
        text_processor (JapaneseTextProcessor): ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ã‚»ãƒƒã‚µ
        phoneme_list (List[str]): éŸ³ç´ è¾æ›¸

    Examples:
        >>> engine = JapaneseEngine()
        >>> phonemes = engine.text_to_phonemes("ã“ã‚“ã«ã¡ã¯")
        >>> len(phonemes) > 0
        True
    """

    language_code = "ja_JP"

    def __init__(self):
        super().__init__()
        self.text_processor = JapaneseTextProcessor()

    def text_to_phonemes(self, text: str) -> List[str]:
        """
        æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³ç´ åˆ—ã«å¤‰æ›

        Args:
            text: æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ¼¢å­—ãƒ»ã‹ãªæ··åœ¨å¯ï¼‰

        Returns:
            ãƒ­ãƒ¼ãƒå­—éŸ³ç´ ã®ãƒªã‚¹ãƒˆ

        Raises:
            ValueError: ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã®å ´åˆ

        Examples:
            >>> engine.text_to_phonemes("æ¡œ")
            ['s', 'a', 'k', 'u', 'r', 'a']
        """
        if not text:
            raise ValueError("Text cannot be empty")

        return self.text_processor.convert(text)
```

### Type Hints

**å¿…é ˆ**: å…¨ã¦ã®é–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ã«Type hints

```python
from typing import List, Dict, Optional, Union

def synthesize(
    text: str,
    notes: str,
    durations: str,
    speaker_id: Optional[int] = None
) -> bytes:
    """éŸ³å£°åˆæˆ"""
    ...
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
# âœ… æ­£ã—ã„ä¾‹
class LanguageNotSupportedError(Exception):
    """ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„è¨€èªã‚¨ãƒ©ãƒ¼"""
    pass

try:
    engine = language_registry.get_engine("unknown_lang")
except LanguageNotSupportedError as e:
    logger.error(f"Language not supported: {e}")
    raise HTTPException(status_code=400, detail=str(e))
```

---

## ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª

### å˜ä½“ãƒ†ã‚¹ãƒˆ

```python
# tests/test_japanese_processor.py
def test_hiragana_to_phonemes():
    """ã²ã‚‰ãŒãªâ†’éŸ³ç´ å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
    processor = JapaneseTextProcessor()
    result = processor.convert("ã‚ã„ã†ãˆãŠ")
    assert result == ['a', 'i', 'u', 'e', 'o']

def test_kanji_to_phonemes():
    """æ¼¢å­—â†’éŸ³ç´ å¤‰æ›ãƒ†ã‚¹ãƒˆ"""
    processor = JapaneseTextProcessor()
    result = processor.convert("æ—¥æœ¬")
    assert len(result) > 0  # ä½•ã‚‰ã‹ã®éŸ³ç´ ãŒè¿”ã‚‹
```

### çµ±åˆãƒ†ã‚¹ãƒˆ

```python
# tests/test_end_to_end.py
def test_full_synthesis_japanese():
    """æ—¥æœ¬èªå®Œå…¨åˆæˆãƒ†ã‚¹ãƒˆ"""
    engine = JapaneseEngine()

    text = "æ¡œãŒå’²ã"
    notes = "C4 | D4 | E4 | F4"
    durations = "0.5 | 0.5 | 0.5 | 0.5"

    wav = engine.synthesize(text, notes, durations)

    assert len(wav) > 0
    assert isinstance(wav, bytes)
```

---

## ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### DockeråŒ–

`Dockerfile`:
```dockerfile
FROM python:3.11-slim

# ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚
RUN apt-get update && apt-get install -y \
    mecab \
    libmecab-dev \
    mecab-ipadic-utf8 \
    && rm -rf /var/lib/apt/lists/*

# Pythonä¾å­˜é–¢ä¿‚
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
COPY backend/diffsinger_engine /app
WORKDIR /app

CMD ["uvicorn", "api.routes:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

#### 1. MeCabè¾æ›¸ã‚¨ãƒ©ãƒ¼

**ã‚¨ãƒ©ãƒ¼**:
```
RuntimeError: Unable to open MeCab dictionary file
```

**è§£æ±º**:
```bash
# Ubuntu/Debian
sudo apt-get install mecab mecab-ipadic-utf8

# macOS
brew install mecab mecab-ipadic
```

#### 2. éŸ³ç´ å¤‰æ›å¤±æ•—

**ç—‡çŠ¶**: `text_to_phonemes`ãŒç©ºãƒªã‚¹ãƒˆè¿”å´

**è§£æ±º**:
```python
# ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ 
def text_to_phonemes(self, text: str) -> List[str]:
    logger.debug(f"Input text: {text}")
    kana = self._to_hiragana(text)
    logger.debug(f"Converted to kana: {kana}")
    phonemes = self.text_processor.convert(text)
    logger.debug(f"Phonemes: {phonemes}")
    return phonemes
```

---

**ä½œæˆè€…**: Claude Code
**ãƒ¬ãƒ“ãƒ¥ãƒ¼**: æœª
**æ‰¿èª**: æœª
